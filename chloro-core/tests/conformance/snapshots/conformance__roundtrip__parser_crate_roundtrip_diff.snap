---
source: chloro-core/tests/conformance/roundtrip.rs
expression: cleaned_diff
---
+//! Adapted from a `rustc` test, which can be found at
+//! https://github.com/rust-lang/rust/blob/6d34ec18c7d7e574553f6347ecf08e1e1c45c13d/src/test/run-pass/weird-exprs.rs.
+//!
+//! Reported to rust-analyzer in https://github.com/rust-lang/rust-analyzer/issues/290
+//! docs
+//! See [`Input`].
+//! The Rust parser.
+//!
+//! NOTE: The crate is undergoing refactors, don't believe everything the docs
+//! say :-)
+//!
+//! The parser doesn't know about concrete representation of tokens and syntax
+//! trees. Abstract [`TokenSource`] and [`TreeSink`] traits are used instead. As
+//! a consequence, this crate does not contain a lexer.
+//!
+//! The [`Parser`] struct from the [`parser`] module is a cursor into the
+//! sequence of tokens.  Parsing routines use [`Parser`] to inspect current
+//! state and advance the parsing.
+//!
+//! The actual parsing happens in the [`grammar`] module.
+//!
+//! Tests for this crate live in the `syntax` crate.
+//!
+//! [`Parser`]: crate::parser::Parser
+//! This module provides a way to construct a `File`.
+//! It is intended to be completely decoupled from the
+//! parser, so as to allow to evolve the tree representation
+//! and the parser algorithm independently.
+//! This is the actual "grammar" of the Rust language.
+//!
+//! Each function in this module and its children corresponds
+//! to a production of the formal grammar. Submodules roughly
+//! correspond to different *areas* of the grammar. By convention,
+//! each submodule starts with `use super::*` import and exports
+//! "public" productions via `pub(super)`.
+//!
+//! See docs for [`Parser`](super::parser::Parser) to learn about API,
+//! available to the grammar, and see docs for [`Event`](super::event::Event)
+//! to learn how this actually manages to produce parse trees.
+//!
+//! Code in this module also contains inline tests, which start with
+//! `// test name-of-the-test` comment and look like this:
+//!
+//! ```text
+//! // test function_with_zero_parameters
+//! // fn foo() {}
+//! ```
+//!
+//! After adding a new inline-test, run `cargo test -p xtask` to
+//! extract it as a standalone text-fixture into
+//! `crates/syntax/test_data/parser/`, and run `cargo test` once to
+//! create the "gold" value.
+//!
+//! Coding convention: rules like `where_clause` always produce either a
+//! node or an error, rules like `opt_where_clause` may produce nothing.
+//! Non-opt rules typically start with `assert!(p.at(FIRST_TOKEN))`, the
+//! caller is responsible for branching on the first token.
+//! See [`Parser`].
+//! See [`Output`]
+//! Defines [`SyntaxKind`] -- a fieldless enum of all possible syntactic
+//! constructs of the Rust language.
+//! A bit-set of `SyntaxKind`s.
+//! Shortcuts that span lexer/parser abstraction.
+//!
+//! The way Rust works, parser doesn't necessary parse text, and you might
+//! tokenize text without parsing it further. So, it makes sense to keep
+//! abstract token parsing, and string tokenization as completely separate
+//! layers.
+//!
+//! However, often you do parse text into syntax trees and the glue code for
+//! that needs to live somewhere. Rather than putting it to lexer or parser, we
+//! use a separate shortcuts module for that.
+//! Generated by `cargo xtask codegen grammar`, do not edit by hand.
+
+// https://github.com/rust-lang/rust-analyzer/issues/972
+#[cfg(not(feature = "in-rust-tree"))]
+#[cfg(feature = "in-rust-tree")]
+
+mod a;
+// https://github.com/rust-lang/rust-analyzer/issues/311
+// https://github.com/rust-lang/rust-analyzer/issues/596
+// https://github.com/rust-lang/rust-analyzer/pull/983
+#[path = "a.rs"]
+mod b;
+mod prefix_entries;
+mod top_entries;
+#[rustfmt::skip]
+#[path = "../test_data/generated/runner.rs"]
+mod runner;
+mod event;
+mod frontmatter;
+mod grammar;
+mod input;
+mod lexed_str;
+mod output;
+mod parser;
+mod shortcuts;
+mod syntax_kind;
+mod token_set;
+#[cfg(test)]
+mod tests;
+mod attributes;
+mod expressions;
+mod generic_args;
+mod generic_params;
+mod items;
+mod params;
+mod paths;
+mod patterns;
+mod types;
+#[rustfmt::skip]
+mod generated;
+mod adt;
+mod consts;
+mod traits;
+mod use_item;
+// test_err meta_recovery
+// #![]
+// #![p = ]
+// #![p::]
+// #![p:: =]
+// #![unsafe]
+// #![unsafe =]
+mod atom;
+
+use std::*;
+use std::cell::Cell;
+use std::cell::Cell;
+// 2021
+use std::collections;
+use std::collections;
+use std::io;
+use std::mem;
+use std::mem;
+use std::mem::swap;
+use std::{
+    fmt::Write,
+    fs,
+    path::{Path, PathBuf},
+};
+use std::{*};
+use std::{::*};
+use std::{collections};
+use std::{error::Error;
+
+pub(super) use atom::{EXPR_RECOVERY_SET, LITERAL_FIRST, literal, parse_asm_expr};
+pub(crate) use atom::{block_expr, match_arm_list};
+use b;
+use drop_bomb::DropBomb;
+pub use edition::Edition;
+use expect_test::expect;
+use expect_test::expect_file;
+use foo;
+// Just a grab bag of stuff that you wouldn't want to actually write.
+use foo as bar;
+use foo::*;
+use foo::bar;
+use foo::bar::baz;
+use foo::{a as b, *, ::*, ::foo as x};
+use foo::{};
+use outer::tree::{inner::tree};
+use std as stdlib;
+pub(crate) use token_set::TokenSet;
+use ::bar;
+use ::foo::bar::baz;
+use ::foo::{a, b, c};
+use ::std;
+pub use T_ as T;
+use Trait as _;
+use {a;
+use {a ,, b};
+use {a, b, c};
+//~ ERROR incorrect close delimiter
+use ;
+use ;
+use ;
+use ;
+use ;
+use *;
+// https://github.com/rust-lang/rust-analyzer/issues/357
+use *;
+use ::*;
+use ::*;
+use ::{};
+use {};
+
+use crate::;
+use crate::Edition;
+use crate::Edition;
+//") || content.contains(";\n")) {
+use crate::SyntaxKind;
+use crate::SyntaxKind;
+use crate::SyntaxKind;
+use crate::TopEntryPoint;
+use crate::baz;
+use crate::foo;
+use crate::grammar::attributes::ATTRIBUTE_FIRST;
+use crate::grammar::attributes::ATTRIBUTE_FIRST;
+use crate::grammar::attributes::ATTRIBUTE_FIRST;
+use crate::grammar::attributes::ATTRIBUTE_FIRST;
+use crate::grammar::types::type_;
+use crate::m;
+use crate::{
+    event::Event, input::Input, Edition, SyntaxKind::{self, EOF, ERROR, TOMBSTONE}, TokenSet, T,
+};
+use crate::{
+    Edition, LexedStr, Step,
+    SyntaxKind::{self, *},
+};
+use crate::{
+    parser::{CompletedMarker, Marker, Parser}, SyntaxKind::{self, *}, TokenSet, T,
+};
+use crate::{
+    SyntaxKind::{self, *},
+    output::Output,
+};
+pub use crate::{
+    input::Input, lexed_str::LexedStr, output::{Output, Step}, shortcuts::StrStep,
+    syntax_kind::SyntaxKind,
+};
+// Copied from https://github.com/rust-lang/cargo/blob/367fd9f213750cd40317803dd0a5a3ce3f0c676d/src/cargo/util/frontmatter.rs
+// avoid editing
+// avoid editing
+// avoid editing
+use crate::{Edition, LexedStr, PrefixEntryPoint, Step};
+use crate::{Edition, LexedStr, TopEntryPoint};
+use self::SyntaxKind::*;
+// https://github.com/rust-lang/rust-analyzer/issues/674
+use self::foo;
+pub use self::generated::SyntaxKind;
+use self::m;
+pub(crate) use self::{
+    adt::{record_field_list, variant_list}, expressions::{match_arm_list, record_expr_field_list},
+    traits::assoc_item_list, use_item::use_tree_list,
+};
+use super::*;
+use super::*;
+use super::*;
+use super::*;
+use super::*;
+use super::*;
+use super::*;
+// test param_list
+// fn a() {}
+// fn b(x: i32) {}
+// fn c(x: i32, ) {}
+// fn d(x: i32, y: ()) {}
+use super::*;
+use super::*;
+use super::*;
+use super::*;
+// test generic_param_list
+// fn f<T: Clone>() {}
+use super::*;
+use super::*;
+use super::*;
+use super::m;
+use super::super::bar;
+
 mod ok {
     use crate::tests::*;
     #[test]
         run_and_expect_no_errors("test_data/parser/inline/ok/arb_self_types.rs");
     }
     #[test]
-    fn arg_with_attr() { run_and_expect_no_errors("test_data/parser/inline/ok/arg_with_attr.rs"); }
+    fn arg_with_attr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/arg_with_attr.rs");
+    }
     #[test]
-    fn array_attrs() { run_and_expect_no_errors("test_data/parser/inline/ok/array_attrs.rs"); }
+    fn array_attrs() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/array_attrs.rs");
+    }
     #[test]
-    fn array_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/array_expr.rs"); }
+    fn array_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/array_expr.rs");
+    }
     #[test]
-    fn array_type() { run_and_expect_no_errors("test_data/parser/inline/ok/array_type.rs"); }
+    fn array_type() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/array_type.rs");
+    }
     #[test]
-    fn as_precedence() { run_and_expect_no_errors("test_data/parser/inline/ok/as_precedence.rs"); }
+    fn as_precedence() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/as_precedence.rs");
+    }
     #[test]
-    fn asm_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/asm_expr.rs"); }
+    fn asm_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/asm_expr.rs");
+    }
     #[test]
-    fn asm_kinds() { run_and_expect_no_errors("test_data/parser/inline/ok/asm_kinds.rs"); }
+    fn asm_kinds() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/asm_kinds.rs");
+    }
     #[test]
-    fn asm_label() { run_and_expect_no_errors("test_data/parser/inline/ok/asm_label.rs"); }
+    fn asm_label() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/asm_label.rs");
+    }
     #[test]
     fn assoc_const_eq() {
         run_and_expect_no_errors("test_data/parser/inline/ok/assoc_const_eq.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/assoc_type_bound.rs");
     }
     #[test]
-    fn assoc_type_eq() { run_and_expect_no_errors("test_data/parser/inline/ok/assoc_type_eq.rs"); }
+    fn assoc_type_eq() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/assoc_type_eq.rs");
+    }
     #[test]
     fn async_trait_bound() {
         run_and_expect_no_errors("test_data/parser/inline/ok/async_trait_bound.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/attr_on_expr_stmt.rs");
     }
     #[test]
-    fn await_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/await_expr.rs"); }
+    fn await_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/await_expr.rs");
+    }
     #[test]
     fn bare_dyn_types_with_leading_lifetime() {
         run_and_expect_no_errors(
         );
     }
     #[test]
-    fn become_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/become_expr.rs"); }
+    fn become_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/become_expr.rs");
+    }
     #[test]
-    fn bind_pat() { run_and_expect_no_errors("test_data/parser/inline/ok/bind_pat.rs"); }
+    fn bind_pat() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/bind_pat.rs");
+    }
     #[test]
     fn binop_resets_statementness() {
         run_and_expect_no_errors("test_data/parser/inline/ok/binop_resets_statementness.rs");
     }
     #[test]
-    fn block() { run_and_expect_no_errors("test_data/parser/inline/ok/block.rs"); }
+    fn block() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/block.rs");
+    }
     #[test]
-    fn block_items() { run_and_expect_no_errors("test_data/parser/inline/ok/block_items.rs"); }
+    fn block_items() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/block_items.rs");
+    }
     #[test]
-    fn box_pat() { run_and_expect_no_errors("test_data/parser/inline/ok/box_pat.rs"); }
+    fn box_pat() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/box_pat.rs");
+    }
     #[test]
     fn break_ambiguity() {
         run_and_expect_no_errors("test_data/parser/inline/ok/break_ambiguity.rs");
     }
     #[test]
-    fn break_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/break_expr.rs"); }
+    fn break_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/break_expr.rs");
+    }
     #[test]
-    fn builtin_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/builtin_expr.rs"); }
+    fn builtin_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/builtin_expr.rs");
+    }
     #[test]
-    fn call_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/call_expr.rs"); }
+    fn call_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/call_expr.rs");
+    }
     #[test]
-    fn cast_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/cast_expr.rs"); }
+    fn cast_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/cast_expr.rs");
+    }
     #[test]
     fn closure_binder() {
         run_and_expect_no_errors("test_data/parser/inline/ok/closure_binder.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/closure_range_method_call.rs");
     }
     #[test]
-    fn const_arg() { run_and_expect_no_errors("test_data/parser/inline/ok/const_arg.rs"); }
+    fn const_arg() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/const_arg.rs");
+    }
     #[test]
     fn const_arg_block() {
         run_and_expect_no_errors("test_data/parser/inline/ok/const_arg_block.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/const_block_pat.rs");
     }
     #[test]
-    fn const_closure() { run_and_expect_no_errors("test_data/parser/inline/ok/const_closure.rs"); }
+    fn const_closure() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/const_closure.rs");
+    }
     #[test]
-    fn const_item() { run_and_expect_no_errors("test_data/parser/inline/ok/const_item.rs"); }
+    fn const_item() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/const_item.rs");
+    }
     #[test]
-    fn const_param() { run_and_expect_no_errors("test_data/parser/inline/ok/const_param.rs"); }
+    fn const_param() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/const_param.rs");
+    }
     #[test]
     fn const_param_default_expression() {
         run_and_expect_no_errors("test_data/parser/inline/ok/const_param_default_expression.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/const_where_clause.rs");
     }
     #[test]
-    fn continue_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/continue_expr.rs"); }
+    fn continue_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/continue_expr.rs");
+    }
     #[test]
-    fn crate_path() { run_and_expect_no_errors("test_data/parser/inline/ok/crate_path.rs"); }
+    fn crate_path() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/crate_path.rs");
+    }
     #[test]
     fn crate_visibility() {
         run_and_expect_no_errors("test_data/parser/inline/ok/crate_visibility.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/default_async_unsafe_fn.rs");
     }
     #[test]
-    fn default_item() { run_and_expect_no_errors("test_data/parser/inline/ok/default_item.rs"); }
+    fn default_item() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/default_item.rs");
+    }
     #[test]
     fn default_unsafe_item() {
         run_and_expect_no_errors("test_data/parser/inline/ok/default_unsafe_item.rs");
         );
     }
     #[test]
-    fn dot_dot_pat() { run_and_expect_no_errors("test_data/parser/inline/ok/dot_dot_pat.rs"); }
+    fn dot_dot_pat() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/dot_dot_pat.rs");
+    }
     #[test]
     fn dyn_trait_type() {
         run_and_expect_no_errors("test_data/parser/inline/ok/dyn_trait_type.rs");
         );
     }
     #[test]
-    fn effect_blocks() { run_and_expect_no_errors("test_data/parser/inline/ok/effect_blocks.rs"); }
+    fn effect_blocks() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/effect_blocks.rs");
+    }
     #[test]
     fn exclusive_range_pat() {
         run_and_expect_no_errors("test_data/parser/inline/ok/exclusive_range_pat.rs");
     }
     #[test]
-    fn expr_literals() { run_and_expect_no_errors("test_data/parser/inline/ok/expr_literals.rs"); }
+    fn expr_literals() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/expr_literals.rs");
+    }
     #[test]
     fn expression_after_block() {
         run_and_expect_no_errors("test_data/parser/inline/ok/expression_after_block.rs");
     }
     #[test]
-    fn extern_block() { run_and_expect_no_errors("test_data/parser/inline/ok/extern_block.rs"); }
+    fn extern_block() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/extern_block.rs");
+    }
     #[test]
-    fn extern_crate() { run_and_expect_no_errors("test_data/parser/inline/ok/extern_crate.rs"); }
+    fn extern_crate() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/extern_crate.rs");
+    }
     #[test]
     fn extern_crate_rename() {
         run_and_expect_no_errors("test_data/parser/inline/ok/extern_crate_rename.rs");
     }
     #[test]
-    fn field_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/field_expr.rs"); }
+    fn field_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/field_expr.rs");
+    }
     #[test]
-    fn fn_() { run_and_expect_no_errors("test_data/parser/inline/ok/fn_.rs"); }
+    fn fn_() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/fn_.rs");
+    }
     #[test]
-    fn fn_decl() { run_and_expect_no_errors("test_data/parser/inline/ok/fn_decl.rs"); }
+    fn fn_decl() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/fn_decl.rs");
+    }
     #[test]
-    fn fn_def_param() { run_and_expect_no_errors("test_data/parser/inline/ok/fn_def_param.rs"); }
+    fn fn_def_param() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/fn_def_param.rs");
+    }
     #[test]
     fn fn_pointer_param_ident_path() {
         run_and_expect_no_errors("test_data/parser/inline/ok/fn_pointer_param_ident_path.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/for_binder_bound.rs");
     }
     #[test]
-    fn for_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/for_expr.rs"); }
+    fn for_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/for_expr.rs");
+    }
     #[test]
     fn for_range_from() {
         run_and_expect_no_errors("test_data/parser/inline/ok/for_range_from.rs");
     }
     #[test]
-    fn for_type() { run_and_expect_no_errors("test_data/parser/inline/ok/for_type.rs"); }
+    fn for_type() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/for_type.rs");
+    }
     #[test]
-    fn frontmatter() { run_and_expect_no_errors("test_data/parser/inline/ok/frontmatter.rs"); }
+    fn frontmatter() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/frontmatter.rs");
+    }
     #[test]
     fn full_range_expr() {
         run_and_expect_no_errors("test_data/parser/inline/ok/full_range_expr.rs");
         );
     }
     #[test]
-    fn generic_arg() { run_and_expect_no_errors("test_data/parser/inline/ok/generic_arg.rs"); }
+    fn generic_arg() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/generic_arg.rs");
+    }
     #[test]
     fn generic_arg_bounds() {
         run_and_expect_no_errors("test_data/parser/inline/ok/generic_arg_bounds.rs");
     }
     #[test]
-    fn generic_const() { run_and_expect_no_errors("test_data/parser/inline/ok/generic_const.rs"); }
+    fn generic_const() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/generic_const.rs");
+    }
     #[test]
     fn generic_param_attribute() {
         run_and_expect_no_errors("test_data/parser/inline/ok/generic_param_attribute.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/generic_param_list.rs");
     }
     #[test]
-    fn global_asm() { run_and_expect_no_errors("test_data/parser/inline/ok/global_asm.rs"); }
+    fn global_asm() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/global_asm.rs");
+    }
     #[test]
     fn half_open_range_pat() {
         run_and_expect_no_errors("test_data/parser/inline/ok/half_open_range_pat.rs");
     }
     #[test]
-    fn if_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/if_expr.rs"); }
+    fn if_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/if_expr.rs");
+    }
     #[test]
-    fn impl_item() { run_and_expect_no_errors("test_data/parser/inline/ok/impl_item.rs"); }
+    fn impl_item() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/impl_item.rs");
+    }
     #[test]
     fn impl_item_const() {
         run_and_expect_no_errors("test_data/parser/inline/ok/impl_item_const.rs");
     }
     #[test]
-    fn impl_item_neg() { run_and_expect_no_errors("test_data/parser/inline/ok/impl_item_neg.rs"); }
+    fn impl_item_neg() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/impl_item_neg.rs");
+    }
     #[test]
     fn impl_item_never_type() {
         run_and_expect_no_errors("test_data/parser/inline/ok/impl_item_never_type.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/impl_type_params.rs");
     }
     #[test]
-    fn index_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/index_expr.rs"); }
+    fn index_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/index_expr.rs");
+    }
     #[test]
-    fn label() { run_and_expect_no_errors("test_data/parser/inline/ok/label.rs"); }
+    fn label() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/label.rs");
+    }
     #[test]
-    fn labeled_block() { run_and_expect_no_errors("test_data/parser/inline/ok/labeled_block.rs"); }
+    fn labeled_block() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/labeled_block.rs");
+    }
     #[test]
-    fn lambda_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/lambda_expr.rs"); }
+    fn lambda_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/lambda_expr.rs");
+    }
     #[test]
     fn lambda_ret_block() {
         run_and_expect_no_errors("test_data/parser/inline/ok/lambda_ret_block.rs");
     }
     #[test]
-    fn let_else() { run_and_expect_no_errors("test_data/parser/inline/ok/let_else.rs"); }
+    fn let_else() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/let_else.rs");
+    }
     #[test]
-    fn let_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/let_expr.rs"); }
+    fn let_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/let_expr.rs");
+    }
     #[test]
-    fn let_stmt() { run_and_expect_no_errors("test_data/parser/inline/ok/let_stmt.rs"); }
+    fn let_stmt() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/let_stmt.rs");
+    }
     #[test]
     fn let_stmt_ascription() {
         run_and_expect_no_errors("test_data/parser/inline/ok/let_stmt_ascription.rs");
     }
     #[test]
-    fn let_stmt_init() { run_and_expect_no_errors("test_data/parser/inline/ok/let_stmt_init.rs"); }
+    fn let_stmt_init() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/let_stmt_init.rs");
+    }
     #[test]
-    fn lifetime_arg() { run_and_expect_no_errors("test_data/parser/inline/ok/lifetime_arg.rs"); }
+    fn lifetime_arg() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/lifetime_arg.rs");
+    }
     #[test]
     fn lifetime_param() {
         run_and_expect_no_errors("test_data/parser/inline/ok/lifetime_param.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/literal_pattern.rs");
     }
     #[test]
-    fn loop_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/loop_expr.rs"); }
+    fn loop_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/loop_expr.rs");
+    }
     #[test]
     fn macro_call_type() {
         run_and_expect_no_errors("test_data/parser/inline/ok/macro_call_type.rs");
     }
     #[test]
-    fn macro_def() { run_and_expect_no_errors("test_data/parser/inline/ok/macro_def.rs"); }
+    fn macro_def() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/macro_def.rs");
+    }
     #[test]
     fn macro_def_curly() {
         run_and_expect_no_errors("test_data/parser/inline/ok/macro_def_curly.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/macro_rules_non_brace.rs");
     }
     #[test]
-    fn marco_pat() { run_and_expect_no_errors("test_data/parser/inline/ok/marco_pat.rs"); }
+    fn marco_pat() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/marco_pat.rs");
+    }
     #[test]
-    fn match_arm() { run_and_expect_no_errors("test_data/parser/inline/ok/match_arm.rs"); }
+    fn match_arm() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/match_arm.rs");
+    }
     #[test]
     fn match_arms_commas() {
         run_and_expect_no_errors("test_data/parser/inline/ok/match_arms_commas.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/match_arms_outer_attributes.rs");
     }
     #[test]
-    fn match_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/match_expr.rs"); }
+    fn match_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/match_expr.rs");
+    }
     #[test]
-    fn match_guard() { run_and_expect_no_errors("test_data/parser/inline/ok/match_guard.rs"); }
+    fn match_guard() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/match_guard.rs");
+    }
     #[test]
     fn maybe_const_trait_bound() {
         run_and_expect_no_errors("test_data/parser/inline/ok/maybe_const_trait_bound.rs");
     }
     #[test]
-    fn metas() { run_and_expect_no_errors("test_data/parser/inline/ok/metas.rs"); }
+    fn metas() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/metas.rs");
+    }
     #[test]
     fn method_call_expr() {
         run_and_expect_no_errors("test_data/parser/inline/ok/method_call_expr.rs");
     }
     #[test]
-    fn mod_contents() { run_and_expect_no_errors("test_data/parser/inline/ok/mod_contents.rs"); }
+    fn mod_contents() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/mod_contents.rs");
+    }
     #[test]
-    fn mod_item() { run_and_expect_no_errors("test_data/parser/inline/ok/mod_item.rs"); }
+    fn mod_item() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/mod_item.rs");
+    }
     #[test]
     fn mod_item_curly() {
         run_and_expect_no_errors("test_data/parser/inline/ok/mod_item_curly.rs");
     }
     #[test]
-    fn never_type() { run_and_expect_no_errors("test_data/parser/inline/ok/never_type.rs"); }
+    fn never_type() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/never_type.rs");
+    }
     #[test]
     fn no_dyn_trait_leading_for() {
         run_and_expect_no_errors("test_data/parser/inline/ok/no_dyn_trait_leading_for.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/no_semi_after_block.rs");
     }
     #[test]
-    fn nocontentexpr() { run_and_expect_no_errors("test_data/parser/inline/ok/nocontentexpr.rs"); }
+    fn nocontentexpr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/nocontentexpr.rs");
+    }
     #[test]
     fn nocontentexpr_after_item() {
         run_and_expect_no_errors("test_data/parser/inline/ok/nocontentexpr_after_item.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/offset_of_parens.rs");
     }
     #[test]
-    fn or_pattern() { run_and_expect_no_errors("test_data/parser/inline/ok/or_pattern.rs"); }
+    fn or_pattern() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/or_pattern.rs");
+    }
     #[test]
-    fn param_list() { run_and_expect_no_errors("test_data/parser/inline/ok/param_list.rs"); }
+    fn param_list() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/param_list.rs");
+    }
     #[test]
     fn param_list_vararg() {
         run_and_expect_no_errors("test_data/parser/inline/ok/param_list_vararg.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/param_outer_arg.rs");
     }
     #[test]
-    fn paren_type() { run_and_expect_no_errors("test_data/parser/inline/ok/paren_type.rs"); }
+    fn paren_type() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/paren_type.rs");
+    }
     #[test]
-    fn path_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/path_expr.rs"); }
+    fn path_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/path_expr.rs");
+    }
     #[test]
     fn path_fn_trait_args() {
         run_and_expect_no_errors("test_data/parser/inline/ok/path_fn_trait_args.rs");
     }
     #[test]
-    fn path_part() { run_and_expect_no_errors("test_data/parser/inline/ok/path_part.rs"); }
+    fn path_part() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/path_part.rs");
+    }
     #[test]
-    fn path_type() { run_and_expect_no_errors("test_data/parser/inline/ok/path_type.rs"); }
+    fn path_type() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/path_type.rs");
+    }
     #[test]
     fn path_type_with_bounds() {
         run_and_expect_no_errors("test_data/parser/inline/ok/path_type_with_bounds.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/pointer_type_mut.rs");
     }
     #[test]
-    fn postfix_range() { run_and_expect_no_errors("test_data/parser/inline/ok/postfix_range.rs"); }
+    fn postfix_range() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/postfix_range.rs");
+    }
     #[test]
     fn precise_capturing() {
         run_and_expect_no_errors("test_data/parser/inline/ok/precise_capturing.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/pub_tuple_field.rs");
     }
     #[test]
-    fn qual_paths() { run_and_expect_no_errors("test_data/parser/inline/ok/qual_paths.rs"); }
+    fn qual_paths() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/qual_paths.rs");
+    }
     #[test]
     fn question_for_type_trait_bound() {
         run_and_expect_no_errors("test_data/parser/inline/ok/question_for_type_trait_bound.rs");
     }
     #[test]
-    fn range_pat() { run_and_expect_no_errors("test_data/parser/inline/ok/range_pat.rs"); }
+    fn range_pat() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/range_pat.rs");
+    }
     #[test]
     fn record_field_attrs() {
         run_and_expect_no_errors("test_data/parser/inline/ok/record_field_attrs.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/record_field_pat_leading_or.rs");
     }
     #[test]
-    fn record_lit() { run_and_expect_no_errors("test_data/parser/inline/ok/record_lit.rs"); }
+    fn record_lit() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/record_lit.rs");
+    }
     #[test]
     fn record_literal_field_with_attr() {
         run_and_expect_no_errors("test_data/parser/inline/ok/record_literal_field_with_attr.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/record_pat_field_list.rs");
     }
     #[test]
-    fn ref_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/ref_expr.rs"); }
+    fn ref_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/ref_expr.rs");
+    }
     #[test]
-    fn ref_pat() { run_and_expect_no_errors("test_data/parser/inline/ok/ref_pat.rs"); }
+    fn ref_pat() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/ref_pat.rs");
+    }
     #[test]
     fn reference_type() {
         run_and_expect_no_errors("test_data/parser/inline/ok/reference_type.rs");
     }
     #[test]
-    fn return_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/return_expr.rs"); }
+    fn return_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/return_expr.rs");
+    }
     #[test]
     fn return_type_syntax_in_path() {
         run_and_expect_no_errors("test_data/parser/inline/ok/return_type_syntax_in_path.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/safe_outside_of_extern.rs");
     }
     #[test]
-    fn self_param() { run_and_expect_no_errors("test_data/parser/inline/ok/self_param.rs"); }
+    fn self_param() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/self_param.rs");
+    }
     #[test]
     fn self_param_outer_attr() {
         run_and_expect_no_errors("test_data/parser/inline/ok/self_param_outer_attr.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/singleton_tuple_type.rs");
     }
     #[test]
-    fn slice_pat() { run_and_expect_no_errors("test_data/parser/inline/ok/slice_pat.rs"); }
+    fn slice_pat() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/slice_pat.rs");
+    }
     #[test]
-    fn slice_type() { run_and_expect_no_errors("test_data/parser/inline/ok/slice_type.rs"); }
+    fn slice_type() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/slice_type.rs");
+    }
     #[test]
     fn stmt_bin_expr_ambiguity() {
         run_and_expect_no_errors("test_data/parser/inline/ok/stmt_bin_expr_ambiguity.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/struct_initializer_with_defaults.rs");
     }
     #[test]
-    fn struct_item() { run_and_expect_no_errors("test_data/parser/inline/ok/struct_item.rs"); }
+    fn struct_item() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/struct_item.rs");
+    }
     #[test]
-    fn trait_alias() { run_and_expect_no_errors("test_data/parser/inline/ok/trait_alias.rs"); }
+    fn trait_alias() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/trait_alias.rs");
+    }
     #[test]
     fn trait_alias_where_clause() {
         run_and_expect_no_errors("test_data/parser/inline/ok/trait_alias_where_clause.rs");
     }
     #[test]
-    fn trait_item() { run_and_expect_no_errors("test_data/parser/inline/ok/trait_item.rs"); }
+    fn trait_item() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/trait_item.rs");
+    }
     #[test]
     fn trait_item_bounds() {
         run_and_expect_no_errors("test_data/parser/inline/ok/trait_item_bounds.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/try_block_expr.rs");
     }
     #[test]
-    fn try_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/try_expr.rs"); }
+    fn try_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/try_expr.rs");
+    }
     #[test]
     fn try_macro_fallback() {
         run_and_expect_no_errors_with_edition(
         );
     }
     #[test]
-    fn tuple_attrs() { run_and_expect_no_errors("test_data/parser/inline/ok/tuple_attrs.rs"); }
+    fn tuple_attrs() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/tuple_attrs.rs");
+    }
     #[test]
-    fn tuple_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/tuple_expr.rs"); }
+    fn tuple_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/tuple_expr.rs");
+    }
     #[test]
     fn tuple_field_attrs() {
         run_and_expect_no_errors("test_data/parser/inline/ok/tuple_field_attrs.rs");
     }
     #[test]
-    fn tuple_pat() { run_and_expect_no_errors("test_data/parser/inline/ok/tuple_pat.rs"); }
+    fn tuple_pat() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/tuple_pat.rs");
+    }
     #[test]
     fn tuple_pat_fields() {
         run_and_expect_no_errors("test_data/parser/inline/ok/tuple_pat_fields.rs");
     }
     #[test]
-    fn tuple_struct() { run_and_expect_no_errors("test_data/parser/inline/ok/tuple_struct.rs"); }
+    fn tuple_struct() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/tuple_struct.rs");
+    }
     #[test]
     fn tuple_struct_where() {
         run_and_expect_no_errors("test_data/parser/inline/ok/tuple_struct_where.rs");
     }
     #[test]
-    fn type_alias() { run_and_expect_no_errors("test_data/parser/inline/ok/type_alias.rs"); }
+    fn type_alias() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/type_alias.rs");
+    }
     #[test]
     fn type_item_type_params() {
         run_and_expect_no_errors("test_data/parser/inline/ok/type_item_type_params.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/type_item_where_clause_deprecated.rs");
     }
     #[test]
-    fn type_param() { run_and_expect_no_errors("test_data/parser/inline/ok/type_param.rs"); }
+    fn type_param() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/type_param.rs");
+    }
     #[test]
     fn type_param_bounds() {
         run_and_expect_no_errors("test_data/parser/inline/ok/type_param_bounds.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/typepathfn_with_coloncolon.rs");
     }
     #[test]
-    fn unary_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/unary_expr.rs"); }
+    fn unary_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/unary_expr.rs");
+    }
     #[test]
-    fn union_item() { run_and_expect_no_errors("test_data/parser/inline/ok/union_item.rs"); }
+    fn union_item() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/union_item.rs");
+    }
     #[test]
-    fn unit_struct() { run_and_expect_no_errors("test_data/parser/inline/ok/unit_struct.rs"); }
+    fn unit_struct() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/unit_struct.rs");
+    }
     #[test]
-    fn unit_type() { run_and_expect_no_errors("test_data/parser/inline/ok/unit_type.rs"); }
+    fn unit_type() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/unit_type.rs");
+    }
     #[test]
-    fn use_item() { run_and_expect_no_errors("test_data/parser/inline/ok/use_item.rs"); }
+    fn use_item() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/use_item.rs");
+    }
     #[test]
-    fn use_tree() { run_and_expect_no_errors("test_data/parser/inline/ok/use_tree.rs"); }
+    fn use_tree() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/use_tree.rs");
+    }
     #[test]
     fn use_tree_abs_star() {
         run_and_expect_no_errors("test_data/parser/inline/ok/use_tree_abs_star.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/use_tree_alias.rs");
     }
     #[test]
-    fn use_tree_list() { run_and_expect_no_errors("test_data/parser/inline/ok/use_tree_list.rs"); }
+    fn use_tree_list() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/use_tree_list.rs");
+    }
     #[test]
-    fn use_tree_path() { run_and_expect_no_errors("test_data/parser/inline/ok/use_tree_path.rs"); }
+    fn use_tree_path() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/use_tree_path.rs");
+    }
     #[test]
     fn use_tree_path_star() {
         run_and_expect_no_errors("test_data/parser/inline/ok/use_tree_path_star.rs");
         run_and_expect_no_errors("test_data/parser/inline/ok/use_tree_path_use_tree.rs");
     }
     #[test]
-    fn use_tree_star() { run_and_expect_no_errors("test_data/parser/inline/ok/use_tree_star.rs"); }
+    fn use_tree_star() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/use_tree_star.rs");
+    }
     #[test]
     fn variant_discriminant() {
         run_and_expect_no_errors("test_data/parser/inline/ok/variant_discriminant.rs");
     }
     #[test]
-    fn where_clause() { run_and_expect_no_errors("test_data/parser/inline/ok/where_clause.rs"); }
+    fn where_clause() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/where_clause.rs");
+    }
     #[test]
     fn where_pred_for() {
         run_and_expect_no_errors("test_data/parser/inline/ok/where_pred_for.rs");
     }
     #[test]
-    fn while_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/while_expr.rs"); }
+    fn while_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/while_expr.rs");
+    }
     #[test]
-    fn yeet_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/yeet_expr.rs"); }
+    fn yeet_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/yeet_expr.rs");
+    }
     #[test]
-    fn yield_expr() { run_and_expect_no_errors("test_data/parser/inline/ok/yield_expr.rs"); }
+    fn yield_expr() {
+        run_and_expect_no_errors("test_data/parser/inline/ok/yield_expr.rs");
+    }
 }
+
 mod err {
     use crate::tests::*;
     #[test]
         run_and_expect_errors("test_data/parser/inline/err/async_without_semicolon.rs");
     }
     #[test]
-    fn bad_asm_expr() { run_and_expect_errors("test_data/parser/inline/err/bad_asm_expr.rs"); }
+    fn bad_asm_expr() {
+        run_and_expect_errors("test_data/parser/inline/err/bad_asm_expr.rs");
+    }
     #[test]
     fn closure_ret_recovery() {
         run_and_expect_errors("test_data/parser/inline/err/closure_ret_recovery.rs");
         run_and_expect_errors("test_data/parser/inline/err/empty_param_slot.rs");
     }
     #[test]
-    fn empty_segment() { run_and_expect_errors("test_data/parser/inline/err/empty_segment.rs"); }
+    fn empty_segment() {
+        run_and_expect_errors("test_data/parser/inline/err/empty_segment.rs");
+    }
     #[test]
     fn fn_pointer_type_missing_fn() {
         run_and_expect_errors("test_data/parser/inline/err/fn_pointer_type_missing_fn.rs");
         run_and_expect_errors("test_data/parser/inline/err/generic_param_list_recover.rs");
     }
     #[test]
-    fn generic_static() { run_and_expect_errors("test_data/parser/inline/err/generic_static.rs"); }
+    fn generic_static() {
+        run_and_expect_errors("test_data/parser/inline/err/generic_static.rs");
+    }
     #[test]
-    fn impl_type() { run_and_expect_errors("test_data/parser/inline/err/impl_type.rs"); }
+    fn impl_type() {
+        run_and_expect_errors("test_data/parser/inline/err/impl_type.rs");
+    }
     #[test]
     fn invalid_question_for_type_trait_bound() {
         run_and_expect_errors(
         run_and_expect_errors("test_data/parser/inline/err/match_arms_recovery.rs");
     }
     #[test]
-    fn meta_recovery() { run_and_expect_errors("test_data/parser/inline/err/meta_recovery.rs"); }
+    fn meta_recovery() {
+        run_and_expect_errors("test_data/parser/inline/err/meta_recovery.rs");
+    }
     #[test]
     fn method_call_missing_argument_list() {
         run_and_expect_errors("test_data/parser/inline/err/method_call_missing_argument_list.rs");
         run_and_expect_errors("test_data/parser/inline/err/precise_capturing_invalid.rs");
     }
     #[test]
-    fn pub_expr() { run_and_expect_errors("test_data/parser/inline/err/pub_expr.rs"); }
+    fn pub_expr() {
+        run_and_expect_errors("test_data/parser/inline/err/pub_expr.rs");
+    }
     #[test]
     fn record_literal_before_ellipsis_recovery() {
         run_and_expect_errors(
         run_and_expect_errors("test_data/parser/inline/err/struct_field_recover.rs");
     }
     #[test]
-    fn top_level_let() { run_and_expect_errors("test_data/parser/inline/err/top_level_let.rs"); }
+    fn top_level_let() {
+        run_and_expect_errors("test_data/parser/inline/err/top_level_let.rs");
+    }
     #[test]
     fn tuple_expr_leading_comma() {
         run_and_expect_errors("test_data/parser/inline/err/tuple_expr_leading_comma.rs");
 fn main() {
     foo! (
         bar, "baz", 1, 2.0
-    } //~ ERROR incorrect close delimiter
 }
-
 fn foo() {
     match () {
         _ => (),
     };
 }
 
-fn
+fn ();
 
-fn foo() {}
+fn foo() {
+}
+struct Foo;
 
-extern struct Foo;
-
-fn foo(x: i32, y) {
+fn foo(
+    x: i32,
+    y,
+) {
 }
 
 struct S {
     f: u32,
-    pub 92
-    + - *
     pub x: u32,
     z: f64,
 }
     };
 }
 
-impl<T: Clone>
-impl<T> OnceCell<T> {}
+impl<T: Clone>  {}
+
+impl<T> OnceCell<T> {
+}
 
 fn f() {
     let _ = loop {
     };
 }
 
-struct X {a: i32}
+struct X {
+    a: i32,
+}
+
 fn f() {
     let foo = X {
         a: 1
         self.scopes.push(ScopeData { parent: None, entries: vec![] })
     }
 
-    fn set_parent
+    fn set_parent();
 }
 
 fn foo() -> i32 {
     )
     return 92;
 }
+async fn foo() {
+}
 
-unsafe async fn foo() {}
-unsafe const fn bar() {}
-
-let foo = bar = {
-    1
-} else {
+const ;
+{
+    1;
+}{
     return;
-};
-
-fn f() {
+}fn f() {
     S::<Item::<lol>::<nope>>;
 }
 
 fn g() {
-    let _: Item::<lol>::<nope> = ();
+    let _: Item::<lol>::<
+    nope> =
+    ();
 }
 
-fn f<T: (Copy) + (?Sized) + (for<'a> Trait<'a>)>() {}
+fn f<T: (Copy) + (?Sized) + (for<'a> Trait<'a>)>() {
+}
 
 fn main() {
-    let _: Box<(Copy) + (?Sized) + (for<'a> Trait<'a>)>;
-    let _: Box<(?Sized) + (for<'a> Trait<'a>) + (Copy)>;
-    let _: Box<(for<'a> Trait<'a>) + (Copy) + (?Sized)>;
+    let _: Box<(Copy) + (?Sized) + (for<'a> Trait<'a>)
+    >
+    let _: Box<(?Sized
+    )
+    +
+    (for<'a> Trait<'a>) + (Copy)>;
+    let _: Box<(for<'a> Trait<'a>) + (Copy) + (?Sized)
+    >
 }
-
-let foo = 1 + {
-    1
-} else {
+{
+    1;
+}{
     return;
-};
-
-#!/use/bin/env rusti
-#!/use/bin/env rusti
-
+}#
+#
 fn foo()
-    where for<'a>
-{}
-
-let foo = |x: i32| {
-    x
-} else {
+where for<'a> {
+}
+{
+    x;
+}{
     return;
-};
-
-struct S {
+}struct S {
     a: i32,
     b: String,
-};
-
-struct S<90 + 2> {
-    f: u32
 }
-
+struct S<90;
 struct T;
 
 fn main() {
-    let ref box i = ();
-    let mut box i = ();
-    let ref mut box i = ();
+    let ref box
+    i = ();
+    let mut box
+    i = ();
+    let ref mut box
+    i = ();
 }
 
 impl<T:
-use std;
-
-pub struct Cache(
-    RefCell<HashMap<
+  {}
+pub struct Cache(RefCell<HashMap<
         TypeId,
-        Box<@ Any>,
-    >>
-);
-
+        Box<);
 fn f() {
     let _ = while true {
     } else {
 #[foo(foo, +, 92)]
 fn foo() {
 }
-
-
 #[foo(
 fn foo() {
 }
 
     let bad = format_args! {""} else { return; };
 }
-
-}
-
 struct S;
-
+fn foo() {
 }
-
-fn foo(){}
-
-}
-
 struct S {
-    a: u32
-    b: u32
+    a: u32,
+    b: u32,
 }
 
-fn foo(}) {
-}
-
-let foo = 1..{
-    1
-} else {
+fn foo();
+{
+    1;
+}{
     return;
-};
-
-extern "C" extern "C"
-
-use foo::bar;
-use
-use crate::baz;
-use
-fn f() {}
+}fn f() {
+}
 
 fn foo(a: A) {
     a.
 }
 
 struct S(i32, i32);
+
 fn f() {
     let s = S(1, 2);
     let a = s.1e0;
         #![doc("Not allowed here")]
         _ => (),
     }
-
     match () {
         _ => (),
         _ => (),
         #![doc("Nor here")]
     }
-
     match () {
         #[cfg(test)]
         #![doc("Nor here")]
             abc: {}, //~ ERROR: expected type, found `{`
         },
     }
-
     // recover...
     let a = 1;
     enum Test2 {
         Fine,
     }
-
     enum Test3 {
         StillFine {
             def: i32,
         },
     }
-
     {
         // fail again
         enum Test4 {
         }
     }
     // still recover later
-    let; //~ ERROR: expected pattern
+    let;
+    //~ ERROR: expected pattern
     let _ = 0;
 }
+struct S {
+}
 
-if match
+fn foo<T>()
+where T {
+}
 
-struct S {}
+fn a() {
+    [1, 2, @
+    ,
+    struct,
+    let]
+}
 
-fn foo<T>() where T {}
+fn b() {
+    foo(1, 2, @
+    ,
+    impl
+    ,
+    let
+    )
+}
 
-fn a() { [1, 2, @, struct, let] }
-fn b() { foo(1, 2, @, impl, let) }
-fn c() { foo.bar(1, 2, @, ], trait, let) }
-
-let foo = -{
-    1
-} else {
+fn c() {
+    foo.bar(1, 2, @
+    ,
+    ]
+    ,
+    trait,
+    let
+    )
+}
+{
+    1;
+}{
     return;
-};
-
-fn f() {
+}fn f() {
     let _ = match Some(1) {
         Some(_) => 1,
         None => 2,
     };
 }
 
-use std::{error::Error;
-use std::io;
-
 fn main() {
-    || -> () unsafe { () };
+    || -> ()
+    unsafe { () };
 }
 
 fn f() {
         return
     };
 }
-
-let foo = become {
-    ()
-} else {
+{
+    ();
+}{
     return;
-};
+}type ForRef = for<'a> &'a u32;
 
-type ForRef = for<'a> &'a u32;
 type ForTup = for<'a> (&'a u32,);
+
 type ForSlice = for<'a> [u32];
+
 type ForForFn = for<'a> for<'b> fn(&'a i32, &'b i32);
+
 fn for_for_for<T>()
 where
-    for<'a> for<'b> for<'c> fn(&'a T, &'b T, &'c T): Copy,
+    for<'a> for<'b> for<'c> fn(&'a T, &'b T, &'c T): Copy, {
+}
+
+fn foo() {
+}
 {
+    1;
+}{
+    2 + 3;
+}fn baz() {
 }
-
-fn foo() {
-}
-
-bar() {
-    if true {
-        1
-    } else {
-        2 + 3
-    }
-}
-
-fn baz() {
-}
-
-let foo = &{
-    1
-} else {
+{
+    1;
+}{
     return;
-};
-
-fn foo() {
+}fn foo() {
     (,);
 }
 
-use crate::;
-
 fn main() {
     S { field ..S::default() }
     S { 0 ..S::default() }
     S { 0 .. }
 }
 
-fn f<T>() where T: ?for<> Sized {}
+fn f<T>()
+where T: ?for<> Sized {
+}
 
 type T = *();
 
-const _: () = T::<0, ,T>;
-const _: () = T::<0, ,T>();
+const () = T::<0, ,T>;
 
-fn foo() -> A>]) { let x = 1; }
-fn foo() -> A>]) where T: Copy { let x = 1; }
+const () = T::<0, ,T>();
 
-struct S { f pub g: () }
-struct S { f: pub g: () }
+fn foo() -> A;
+fn foo() -> A;
+struct S {
+    f: ,
+    pub g: (),
+}
 
-static C: u32 = 0
-where i32: Copy;
-
-type T = [() 92];
+struct S {
+    f: ,
+    pub g: (),
+}
 
+static C: u32 = 0;
+type T = [();
 fn main() {
     S { field = foo }
     S { 0 = foo }
     let S { field = foo };
 }
 
-const _: [&];
+const [&];
 
-fn foo() { let _ = async {} }
-
-fn foo() {
+fn;
+{
+}fn foo() {
     S { ..x, };
     S { ..x, a: 0 }
 }
 
 type T = impl use<self, 1>;
 
-static C = 0;
+static C:  = 0;
 
-struct S(struct S;
-struct S(A,,B);
+struct S();
+
+struct S;
+
+struct S(A, B);
 
 fn foo() {
     S { .., };
 }
 
 type X = <()>;
+
 type Y = <A as B>;
 
 fn func() {
     foo.bar::<>
     foo.bar::<i32>;
 }
+fn func() {
+    let Some(_) = {Some(1)} else { panic!("h") };
+}
 
-foo
+impl Type {
+}
 
-fn func() { let Some(_) = {Some(1)} else { panic!("h") };}
+impl Trait1 for T {
+}
 
-impl Type {}
-impl Trait1 for T {}
-impl impl NotType {}
-impl Trait2 for impl NotType {}
+impl  {}
 
-macro_rules! {};
-macro_rules! ()
-macro_rules! []
+impl NotType {
+}
 
+impl Trait2 {}
+
+impl NotType {
+}
 fn foo() {
     x.
     ()
 }
 
-fn foo<T: T![], T: T!, T: T!{}>() -> Box<T! + T!{}> {}
-
-use {a;
-use b;
+fn foo<T: T();
 struct T;
-fn test() {}
-use {a ,, b};
 
-fn foo(){} unsafe { } fn bar(){}
+fn test() {
+}
 
-fn foo() { pub 92; }
+fn foo() {
+}
+fn bar() {
+}
 
-fn f() -> impl Iterator<Item = , Item = > {}
+fn foo() {
+    pub
+    92;
+}
 
-fn f<T: Clone,, U:, V>() {}
+fn f() -> impl Iterator<Item = , Item = > {
+}
+
+fn f<T: Clone,, U:, V>() {
+}
 
 fn main() {
-    'loop: impl
+    'loop:
+    impl
 }
 
 struct A<const N: i32 = , const M: i32 =>;
-
-let ref foo: fn() = 1 + 3;
-
 fn foo() {
     match () {
         _ => (),,
 
 pub() struct S;
 
-static C<i32>: u32 = 0;
+static C: ;
+type F;
+fn foo() {
+    || -> A> { let x = 1; }
+}
 
-type F = unsafe ();
-
-fn foo() { || -> A> { let x = 1; } }
-
-const C = 0;
+const C:  = 0;
 
 fn foo() {
     let (,);
 }
-
-// 2021
-gen fn gen_fn() {}
-async gen fn async_gen_fn() {}
+fn gen_fn() {
+}
+fn async_gen_fn() {
+}
 
 fn main() {
     S { S::default() };
     S { 0::default() };
 }
 
-fn f(x y: i32, z, t: i32) {}
+fn f(
+    x,
+    y: i32,
+    z,
+    t: i32,
+) {
+}
 
 fn foo() {
     builtin#asm(
     );
 }
 
-fn f(y: i32, ,t: i32) {}
-
-#![]
-#![p = ]
-#![p::]
-#![p:: =]
-#![unsafe]
-#![unsafe =]
-
+fn f(
+    y: i32,
+    t: i32,
+) {
+}
+#
+#
+#
+#
+#
+#
 type T = T<0, ,T>;
+
 type T = T::<0, ,T>;
 
-static _: i32 = 5;
+static i32 = 5;
 
 fn foo() {
     x.self;
     x.0();
 }
 
-fn a() {}
-fn b(x: i32) {}
-fn c(x: i32, ) {}
-fn d(x: i32, y: ()) {}
+fn a() {
+}
+
+fn b(x: i32) {
+}
+
+fn c(x: i32) {
+}
+
+fn d(
+    x: i32,
+    y: (),
+) {
+}
 
 fn foo() {
     if true {};
 
 type T = S<{90 + 2}>;
 
-fn main() { || -> i32 { 92 }(); }
+fn main() {
+    || -> i32 { 92 }();
+}
 
 fn main() {
     let .. = ();
     [1; 2];
 }
 
-use std::collections;
-
-fn f() { let x = 92; }
+fn f() {
+    let x = 92;
+}
 
 fn main() {
     match 42 {
     }
 }
 
-default impl T for Foo {}
+impl T for Foo {
+}
 
-trait T where Self: Copy {}
+trait T
+where Self: Copy {
+}
 
-fn f() { unsafe { } }
-fn f() { const { } }
-fn f() { async { } }
-fn f() { async move { } }
+fn f() {
+    unsafe { }
+}
+
+fn f() {
+    const { }
+}
+
+fn f() {
+    async { }
+}
+
+fn f() {
+    async move { }
+}
 
 fn main() {
     match 92 {
         302 .. => (),
         ..= 303 => (),
     }
-
     match Some(10 as u8) {
         Some(0) | None => (),
         Some(1..) => (),
         Some(..=2) => (),
     }
-
     match () {
         S { a: 0 } => (),
         S { a: 1.. } => (),
         S { a: ..=2 } => (),
     }
-
     match () {
         [0] => (),
         [1..] => (),
         [..=2] => (),
     }
-
     match (10 as u8, 5 as u8) {
         (0, _) => (),
         (1.., _) => (),
 }
 
 fn foo() {
-    builtin#offset_of(Foo, (bar.baz.0));
+    builtin#offset_of(Foo, (bar.baz.0)
+    )
 }
 
-struct S<T: 'a + ?Sized + (Copy) + [const] Drop>;
-
-builtin#global_asm("")
-
+struct S<T: 'a + ?Sized + (Copy) +;
+#
 fn foo() {
     let _ = try {};
 }
 
 fn main() {
-   let foo = |bar, baz: Baz, qux: Qux::Quux| ();
+    let foo = |bar, baz: Baz, qux: Qux::Quux| ();
 }
 
 fn foo() {
     match { S {} } {};
 }
 
-struct S { a: i32, b: f32, unsafe c: u8 }
+struct S {
+    a: i32,
+    b: f32,
+    c: u8,
+}
 
 fn foo() {
     builtin#asm("");
     let _ = cr"h";
 }
 
-fn foo(){
+fn foo() {
     if break {}
     while break {}
     for i in break {}
     enum LocalEnum {
         One,
         Two,
-    };
-    fn f() {};
-    struct S {};
+    }
+    fn f() {}
+    struct S {}
 }
 
-struct S { #[attr] f: f32 }
+struct S {
+    #[attr]
+    f: f32,
+}
 
 fn main() {
     let [a, b, ..] = [];
     let [| a, ..] = [];
 }
 
-fn foo(..., (x, y): (i32, i32)) {}
+fn foo(
+    ...,
+    (x, y): (i32, i32),
+) {
+}
 
 fn foo() {
     x?;
     }
 }
 
-impl const Send for S {}
+impl Send for S {
+}
 
-fn main() { let cl = const || _ = 0; }
+fn main() {
+    let cl = const || _ = 0;
+}
 
 impl S {
-    fn a(self) {}
-    fn b(&self,) {}
-    fn c(&'a self,) {}
-    fn d(&'a mut self, x: i32) {}
-    fn e(mut self) {}
+    fn a(self) {
+    }
+
+    fn b(&self) {
+    }
+
+    fn c(&'a self) {
+    }
+
+    fn d(
+        &'a mut self,
+        x: i32,
+    ) {
+    }
+
+    fn e(mut self) {
+    }
 }
 
 type Foo where Foo: Copy = ();
 
 macro_rules! m ( ($i:ident) => {} );
+
 macro_rules! m [ ($i:ident) => {} ];
-
-#![simple_ident]
-#![simple::path]
-#![simple_ident_expr = ""]
-#![simple::path::Expr = ""]
-#![simple_ident_tt(a b c)]
-#![simple_ident_tt[a b c]]
-#![simple_ident_tt{a b c}]
-#![simple::path::tt(a b c)]
-#![simple::path::tt[a b c]]
-#![simple::path::tt{a b c}]
-#![unsafe(simple_ident)]
-#![unsafe(simple::path)]
-#![unsafe(simple_ident_expr = "")]
-#![unsafe(simple::path::Expr = "")]
-#![unsafe(simple_ident_tt(a b c))]
-#![unsafe(simple_ident_tt[a b c])]
-#![unsafe(simple_ident_tt{a b c})]
-#![unsafe(simple::path::tt(a b c))]
-#![unsafe(simple::path::tt[a b c])]
-#![unsafe(simple::path::tt{a b c})]
-
+#
+#
+#
+#
+#
+#
+#
+#
+#
+#
+#
+#
+#
+#
+#
+#
+#
+#
+#
+#
 macro m { ($i:ident) => {} }
 
-fn f<T>() where T: for<> ?Sized {}
+fn f<T>()
+where T: for<> ?Sized {
+}
 
-struct S<T>(T) where T: Clone;
+struct S<T>(T);
 
 fn main() {
     match () {
     #[D] return ();
 }
 
-mod b { }
+mod b {
+}
 
-impl S {}
+impl S {
+}
 
 fn foo() {
     S {};
     TupleStruct { 0: 1 };
 }
 
-type F = fn() -> ();
+type F =
+    fn(
+    ) -> ();
+
+type A =
+    fn(
+    );
 
-type A = fn();
 type B = unsafe fn();
+
 type C = unsafe extern "C" fn();
+
 type D = extern "C" fn ( u8 , ... ) -> u8;
 
-fn f() { 'label: {}; }
+fn f() {
+    'label: {};
+}
 
 type A = for<'a> Test<'a> + Send;
 
-impl ! {}
-
-extern crate foo;
-extern crate self;
+impl  {
+}
 
 type Result<T> = ();
 
-fn main() { let <_>::Foo = (); }
+fn main() {
+    let <_>::Foo = ();
+}
 
 type T = S<true>;
 
-trait X<U: Debug + Display> {}
+trait X<U: Debug + Display> {
+}
 
 type T = StreamingIterator<Item<'a> = &'a T>;
 
     let S { x: 1 } = ();
     let S { #[cfg(any())] x: 1 } = ();
 }
-
 // 2015
-macro_rules! try { () => {} }
-
-use std as stdlib;
-use Trait as _;
-
-struct S(String, usize);
+{
+}struct S(String, usize);
 
 fn foo() {
     // reference operator
 
 type T = S<i32, dyn T, fn()>;
 
-// 2015
 type DynPlain = dyn Path;
+
 type DynRef = &dyn Path;
+
 type DynLt = dyn 'a + Path;
+
 type DynQuestion = dyn ?Path;
+
 type DynFor = dyn for<'a> Path;
+
 type DynParen = dyn(Path);
+
 type Path = dyn::Path;
-type Generic = dyn<Path>;
 
-fn main() { || _ = 0; }
-
-use {a, b, c};
+type Generic = dyn;
+fn main() {
+    || _ = 0;
+}
 
 const A: &[i64] = &[1, #[cfg(test)] 2];
 
     return 92;
 }
 
-type Foo = () where Foo: Copy;
+type Foo where Foo: Copy = ();
 
 type Never = !;
 
-fn foo<T>() where T: Copy {}
+fn foo<T>()
+where T: Copy {
+}
 
 fn foo() {
     let _ = a;
 
 fn foo() {
     builtin#asm("");
-    builtin#global_asm("");
-    builtin#naked_asm("");
+    global_asm("");
+    naked_asm("");
 }
 
-fn foo<T: for<'a> [const] async Trait>() {}
-
+fn foo<T: for<'a> [const]();
 type A = dyn Iterator<Item=Foo<'a>> + 'a;
 
-trait T { fn new() -> Self; }
+trait T {
+    fn new() -> Self;
+}
 
 fn foo() {
     let _s = S { .. };
 }
 
-// 2024
 pub fn main() {
     gen { yield ""; };
-    async gen { yield ""; };
-    gen move { yield ""; };
-    async gen move { yield ""; };
+    async
+    gen { yield ""; };
+    gen
+    move
+    { yield ""; };
+    async
+    gen
+    move
+    { yield ""; };
 }
 
-fn foo() {}
-fn bar() -> () {}
+fn foo() {
+}
+
+fn bar() -> () {
+}
 
 fn main() {
     S { #[cfg(test)] field: 1 }
 }
 
 pub(crate) struct S;
+
 pub(self) struct S;
+
 pub(super) struct S;
 
 type Placeholder = _;
     }
 }
 
-use ::*;
-use std::{::*};
-
 fn foo() {
     if true {}
     loop {}
 }
 
 fn foo() {
-   let mut p = F{x: 5};
-   {p}.x = 10;
+    let mut p = F{x: 5};
+    {p}.x = 10;
 }
 
-// 2015
-fn foo() { try!(Ok(())); }
+fn foo() {
+    try
+    !(Ok(()));
+}
 
-fn f<T: Clone>() {}
+fn f<T: Clone>() {
+}
 
 fn foo() {
     let foo::Bar = ();
 
 struct A<const N: i32 = { 1 }>;
 
-struct U { i: i32, f: f32 }
+struct U {
+    i: i32,
+    f: f32,
+}
 
 type M = *mut ();
+
 type C = *mut ();
 
-impl<const N: u32> Bar<N> {}
+impl<const N: u32> Bar<N> {
+}
 
 type T = [()];
 
 fn foo() {
-   for x in 0 .. {
+    for x in 0 .. {
        break;
    }
 }
 
-use crate::foo;
-
-struct S { f: f32 = 0.0 }
+struct S {
+    f: f32,
+}
 
 fn foo() {
     _ = 1;
 where
     T::method(..): Send,
     method(..): Send,
-    method::(..): Send,
-{}
+    method::(..): Send, {
+}
 
-impl S { #![attr] }
+impl S {
+    #![attr]
+}
 
-fn a() {}
-fn b() { let _ = 1; }
-fn c() { 1; 2; }
-fn d() { 1; 2 }
+fn a() {
+}
+
+fn b() {
+    let _ = 1;
+}
+
+fn c() {
+    1;
+    2;
+}
+
+fn d() {
+    1;
+    2
+}
 
 fn foo() {
     let _ = f();
 }
 
 impl T for Foo {
-    default async fn foo() {}
+    async fn foo() {
+    }
 }
-
-trait Z<U> = T<U>;
-
-use std::*;
-
 fn main() {
     let &a = ();
     let &mut b = ();
    'a: 'b + 'c,
    T: Clone + Copy + 'static,
    Iterator::Item: 'a,
-   <T as Iterator>::Item: 'a
-{}
-
-macro_rules! {}
-macro_rules! ();
-macro_rules! [];
+   <T as Iterator>::Item: 'a {
+}
 fn main() {
     let foo = macro_rules!();
 }
 
-fn f<T: Clone>() {}
+fn f<T: Clone>() {
+}
 
 struct B(pub (super::A));
+
 struct B(pub (crate::A,));
 
 type A = 'static + Trait;
+
 type B = S<'static + Trait>;
 
 type A = Foo<syn::Token![_]>;
 
-fn foo<F: Foo<N=3>>() {}
+fn foo<F: Foo<N=3>>() {
+}
+
 const TEST: usize = 3;
-fn bar<F: Foo<N={TEST}>>() {}
+
+fn bar<F: Foo<N={TEST}>>() {
+}
 
 type F = Start::(Middle) -> (Middle)::End;
+
 type GenericArg = S<Start(Middle)::End>;
 
 type T = S<92>;
 fn main() {
     let const { 15 } = ();
     let const { foo(); bar() } = ();
-
     match 42 {
         const { 0 } .. const { 1 } => (),
         .. const { 0 } => (),
         const { 2 } .. => (),
     }
-
     let (const { () },) = ();
 }
 
 type T = S<-92>;
 
 type T = StreamingIterator<Item<'a>: Clone>;
+
 type T = StreamingIterator<Item(T): Clone>;
 
-fn foo() {}
+fn foo() {
+}
+
 macro_rules! foo {}
-foo::bar!();
-super::baz! {}
 struct S;
 
 struct S<T = i32>;
 
 type A = for<'a> fn() -> ();
+
 type B = for<'a> unsafe extern "C" fn(&'a ()) -> ();
+
 type Obj = for<'a> PartialEq<&'a i32>;
 
-const fn foo(_: impl [const] Trait) {}
+const fn foo(
+    _: impl ,
+    [const],
+    Trait,
+) {
+}
 
-use *;
-use std::{*};
+const u32 = 0;
 
-const _: u32 = 0;
+fn foo<T: Clone + Copy>() {
+}
 
-fn foo<T: Clone + Copy>(){}
-
-fn f() { v = {1}&2; }
+fn f() {
+    v = {1}&2;
+}
 
 fn foo() {
     x.await;
     for<'a> move || {};
 }
 
-default unsafe impl T for Foo {
-    default unsafe fn foo() {}
+unsafe impl T for Foo {
+    unsafe fn foo() {
+    }
 }
 
 pub(in super::A) struct S;
+
 pub(in crate) struct S;
 
 type Plain = Foo<Item, Item::Item, Item: Bound, Item = Item>;
+
 type GenericArgs = Foo<Item<T>, Item::<T>, Item<T>: Bound, Item::<T>: Bound, Item<T> = Item, Item::<T> = Item>;
+
 type ParenthesizedArgs = Foo<Item(T), Item::(T), Item(T): Bound, Item::(T): Bound, Item(T) = Item, Item::(T) = Item>;
+
 type RTN = Foo<Item(..), Item(..), Item(..): Bound, Item(..): Bound, Item(..) = Item, Item(..) = Item>;
 
 fn foo() {
 
 struct S;
 
-fn captures<'a: 'a, 'b: 'b, T>() -> impl Sized + use<'b, T, Self> {}
+fn captures<'a: 'a, 'b: 'b, T>() -> impl Sized + use<'b, T, Self> {
+}
 
-enum E { X(i32) = 10 }
+enum E {
+    X(i32),
+}
 
-// 2015
 type A = Foo<dyn T>;
 
-fn foo() { let R { a: | 1 | 2 } = 0; }
+fn foo() {
+    let R { a: | 1 | 2 } = 0;
+}
 
 type A = impl Iterator<Item=Foo<'a>> + 'a;
 
 
 fn f() {
     let _ = {1} & 2;
-    {1} &2;
+    {1}
+    &2;
 }
 
 struct A<const N: i32 = i32::MAX>;
         [] => {}
     }
 }
-
-extern "C" { fn printf(format: *const i8, ..., _: u8) -> i32; }
-
+fn printf(
+    format: *const i8,
+    ...,
+    _: u8,
+) -> i32;
 type T = [(); 92];
 
-use ::std;
-use std::collections;
-
-use self::m;
-use super::m;
-use crate::m;
-
 fn main() {
     let (a, b, ..) = ();
     let (a,) = ();
 }
 
 impl T for Foo {
-    default async unsafe fn foo() {}
+    async unsafe fn foo() {
+    }
 }
 
 fn foo() {
     yield 1;
 }
 
-use std::{collections};
-
 type Foo = Bar;
 
-type Foo = fn(Bar::Baz);
-type Qux = fn(baz: Bar::Baz);
+type Foo =
+    fn(
+        Bar::Baz,
+    );
+
+type Qux =
+    fn(
+        baz: Bar::Baz,
+    );
 
 impl S {
-    fn a(self: &Self) {}
-    fn b(mut self: Box<Self>) {}
+    fn a(self: &Self) {
+    }
+
+    fn b(mut self: Box<Self>) {
+    }
 }
 
 fn foo() {
 fn f() {
     let 0 .. = 1u32;
     let 0..: _ = 1u32;
-
     match 42 {
         0 .. if true => (),
         _ => (),
     }
 }
 
-fn f() { let x: i32; }
+fn f() {
+    let x: i32;
+}
 
-fn main() { let _ = (); }
+fn main() {
+    let _ = ();
+}
 
 type X = <A as B>::Output;
-fn foo() { <usize as Default>::default(); }
 
-const C<i32>: u32 = 0;
+fn foo() {
+    <usize as Default>::default();
+}
+
+const C: ;
 impl Foo {
-    const C<'a>: &'a () = &();
+    const C: ;
 }
 
-const C<i32>: u32 = 0
-where i32: Copy;
+const C: ;
 trait Foo {
-    const C: i32 where i32: Copy;
+    const C: i32;
+
+
+
+
+
 }
 
-trait T: Hash + Clone {}
+trait T {
+}
 
 fn foo() {
     ();
 }
 
 type A = foo!();
+
 type B = crate::foo!();
 
 type A = Foo;
+
 type B = ::Foo;
+
 type C = self::Foo;
+
 type D = super::Foo;
 
 fn foo() {
 }
 
 type F = Box<Fn(i32) -> ()>;
+
 type F = Box<::Fn(i32) -> ()>;
+
 type F = Box<Fn::(i32) -> ()>;
+
 type F = Box<::Fn::(i32) -> ()>;
 
 fn main() {
 }
 
 const C: u32 = 92;
-
-unsafe extern "C" {}
-extern {}
-
 type T = (i32);
 
 struct MyStruct(pub (u32, u32));
+
 struct MyStruct(pub (u32));
+
 struct MyStruct(pub ());
 
-fn f() { let Some(x) = opt else { return }; }
+fn f() {
+    let Some(x) = opt else { return };
+}
 
 fn foo() {
     while true {};
     x.0()
 }
 
-fn main() { for<'a> || (); }
+fn main() {
+    for<'a> || ();
+}
 
-type Foo = fn(_: bar);
+type Foo =
+    fn(
+        _: bar,
+    );
 
-fn foo() { xs[..]; }
+fn foo() {
+    xs[..];
+}
 
-trait T { fn foo(); }
+trait T {
+    fn foo();
+}
 
-fn f() { let x: i32 = 92; super let y; super::foo; }
+fn f() {
+    let x: i32 = 92;
+    super
+    let y;
+    super::foo;
+}
 
 fn foo() {
     82 as i32;
     0x36 as u8 <= 0x37;
 }
 
-fn f(#[attr1] pat: Type) {}
+fn f(#[attr1] pat: Type) {
+}
 
-struct S (#[attr] f32);
+struct S(f32);
 
 fn foo() {
     builtin#asm(
     );
 }
 
-impl !Send for S {}
+impl Send for S {
+}
 
-fn f() { let _ = &1 as *const i32; }
+fn f() {
+    let _ = &1 as *const i32;
+}
 
 fn for_trait<F>()
 where
-   for<'a> F: Fn(&'a str)
-{ }
-
-#!/usr/bin/env cargo
-
----
-[dependencies]
-clap = { version = "4.2", features = ["derive"] }
----
-
-fn main() {}
+   for<'a> F: Fn(&'a str) {
+}
+#
+fn main() {
+}
 
 fn foo() {
     loop {
         break 'l 92;
     }
 }
-
-trait Z<U> = T<U> where U: Copy;
-trait Z<U> = where Self: T<U>;
-
-const fn foo(_: impl const Trait) {}
+const fn foo(_: impl const Trait) {
+}
 
 fn foo() {
     become foo();
 }
 
-use outer::tree::{inner::tree};
-
 struct A<const N: i32 = -1>;
 
-struct S {}
+struct S {
+}
 
-fn foo() { safe = true; }
+fn foo() {
+    safe = true;
+}
 
 type A = &();
+
 type B = &'static ();
+
 type C = &mut ();
 
 fn main() {
     match a.b()..S { _ => () };
 }
 
-extern crate foo as bar;
-extern crate self as bar;
-
-fn foo(){
-    ;;;some_expr();;;;{;;;};;;;Ok(())
+fn foo() {
+    some_expr();
+    {;;;};
+    Ok(())
 }
 
 struct S<const N: u32>;
 
-fn a() { fn b() {} }
+fn a() {
+    fn b() {}
+}
 
-fn foo() -> Box<T + 'f> {}
-fn foo() -> Box<dyn T + 'f> {}
+fn foo() -> Box<T + 'f> {
+}
+
+fn foo() -> Box<dyn T + 'f> {
+}
 
 fn main() {
     match () {
     }
 }
 
-fn async_foo(_: impl async Fn(&i32)) {}
+fn async_foo(_: impl async Fn(&i32)) {
+}
 
-fn foo<#[lt_attr] 'a, #[t_attr] T>() {}
+fn foo<#[lt_attr] 'a, #[t_attr] T>() {
+}
 
 type T = ();
 
 impl F {
     type A = i32;
+
     const B: i32 = 92;
-    fn foo() {}
-    fn bar(&self) {}
+
+    fn foo() {
+    }
+
+    fn bar(&self) {
+    }
 }
 
-fn f<'a: 'b>() {}
+fn f<'a: 'b>() {
+}
 
-fn f(#[must_use] self) {}
+fn f(#[must_use] self) {
+}
 
 fn main() {
     let m!(x) = 0;
 }
 
-mod a;
-
-fn foo() {}
+fn foo() {
+}
 
 type T = S<'static>;
 
     --1;
 }
 
-fn foo(x: i32) {}
+fn foo(x: i32) {
+}
 
 fn main() {
     foo(loop {});
 }
 
-fn foo() { let r#struct = 92; let r#trait = r#struct * 2; }
+fn foo() {
+    let r#struct = 92;
+    let r#trait = r#struct * 2;
+}
 
 fn main() {
     Some(for _ in [1].into_iter() {});
 }
 
 /// Example
-
-fn test() {}
+fn test() {
+}
 
 static FOO: u32 = 1;
+
 static mut BAR: i32 = 92;
 
-fn a() {}
-pub fn b() {}
-pub macro m($:ident) {}
-pub(crate) fn c() {}
-pub(super) fn d() {}
-pub(in foo::bar::baz) fn e() {}
+fn a() {
+}
 
-use ::foo::bar::baz;
-use foo::bar::baz;
+pub fn b() {
+}
+
+pub macro m($:ident) {}
+
+pub(crate) fn c() {
+}
+
+pub(super) fn d() {
+}
+
+pub(in foo::bar::baz) fn e() {
+}
 
 struct S<T: Copy> {
     f: T,
 }
 
 enum E3 {
-    X
+    X,
 }
 
 enum E4 {
 
 enum E5 {
     A,
-    B = 92,
+    B,
     C {
         a: u32,
         pub b: f64,
     },
-    F {},
-    D(u32,),
+    F {
+    },
+    D(u32),
     E(),
 }
 
-// https://github.com/rust-lang/rust-analyzer/issues/674
-
-struct Repr { raw: [u8; 1] }
+struct Repr {
+    raw: [u8; 1],
+}
 
 fn abc() {
     Repr { raw: [0] }.raw[0] = 0;
     -1..2;
 }
 
-use self::foo;
-use super::super::bar;
-
-// https://github.com/rust-lang/rust-analyzer/issues/972
-
 fn main() {
     match Some(-1) {
         Some(-1) => (),
         _ => (),
     }
-
     match Some((-1, -1)) {
         Some((-1, -1)) => (),
         _ => (),
     }
-
     match A::B(-1, -1) {
         A::B(-1, -1) => (),
         _ => (),
     }
-
     if let Some(-1) = Some(-1) {
     }
 }
 
 enum A {
-    B(i8, i8)
+    B(i8, i8),
 }
 
-fn foo(-128..=127: i8) {}
+fn foo(-128..=127: i8) {
+}
 
 fn test_serialization<SER>()
 where
-    SER: Serialize + for<'de> Deserialize<'de> + PartialEq + std::fmt::Debug,
-{}
+    SER: Serialize + for<'de> Deserialize<'de> + PartialEq + std::fmt::Debug, {
+}
 
 struct S {
-    r#foo: u32
+    r#foo: u32,
 }
-
-extern crate foo;
-extern crate foo as bar;
-extern crate self as baz;
-
-unsafe extern {
-    // sqrt (from libm) may be called with any `f64`
-    pub safe fn sqrt(x: f64) -> f64;
-
-    // strlen (from libc) requires a valid pointer,
-    // so we mark it as being an unsafe fn
-    pub unsafe fn strlen(p: *const c_char) -> usize;
-
-    // this function doesn't say safe or unsafe, so it defaults to unsafe
-    pub fn free(p: *mut core::ffi::c_void);
-
-    pub safe static mut COUNTER: i32;
-
-    pub unsafe static IMPORTANT_BYTES: [u8; 256];
-
-    pub safe static LINES: SyncUnsafeCell<i32>;
-}
-
-extern "C" {
-    //! This is a doc comment
-    #![doc("This is also a doc comment")]
-}
-
+pub fn sqrt(x: f64) -> f64;
+pub unsafe fn strlen(p: *const c_char) -> usize;
+pub fn free(p: *mut core::ffi::c_void);
+pub static mut COUNTER: i32;
+pub static IMPORTANT_BYTES: [u8; 256];
+pub static LINES: SyncUnsafeCell<i32>;
+//! This is a doc comment
+#![doc("This is also a doc comment")]
 fn inner() {
     #![doc("Inner attributes allowed here")]
     //! As are ModuleDoc style comments
     let _ = #[doc("Outer attributes are always allowed")] {};
 }
 
-// https://github.com/rust-lang/rust-analyzer/issues/689
 impl Whatever {
-    fn salsa_event(&self, event_fn: impl Fn() -> Event<Self>) {
-        #![allow(unused_variables)] // this is  `inner_attr` of the block
+    fn salsa_event(
+        &self,
+        event_fn: impl Fn() -> Event<Self>,
+    ) {
+        #![allow(unused_variables)]
+        // this is  `inner_attr` of the block
     }
 }
 
 
 fn for_trait<F>()
 where
-    for<'a> F: Fn(&'a str),
-{
+    for<'a> F: Fn(&'a str), {
 }
+
 fn for_ref<F>()
 where
-    for<'a> &'a F: Debug,
-{
+    for<'a> &'a F: Debug, {
 }
+
 fn for_parens<F>()
 where
-    for<'a> (&'a F): Fn(&'a str),
-{
+    for<'a> (&'a F): Fn(&'a str), {
 }
+
 fn for_slice<F>()
 where
-    for<'a> [&'a F]: Eq,
-{
+    for<'a> [&'a F]: Eq, {
 }
+
 fn for_qpath<T>(_t: &T)
 where
-    for<'a> <&'a T as Baz>::Foo: Iterator,
-{
+    for<'a> <&'a T as Baz>::Foo: Iterator, {
 }
+
 fn for_for_fn<T>()
 where
-    for<'a> for<'b> fn(&'a T, &'b T): Copy,
-{
+    for<'a> for<'b> fn(&'a T, &'b T): Copy, {
 }
-
-#![attr]
-#![attr(true)]
-#![attr(ident)]
-#![attr(ident, 100, true, "true", ident = 100, ident = "hello", ident(100))]
-#![attr(100)]
-#![attr(enabled = true)]
-#![enabled(true)]
-#![attr("hello")]
-#![repr(C, align = 4)]
-#![repr(C, align(4))]
-
-extern "C" {
-    fn a(_: *mut u8, ...,);
-    fn b(_: *mut u8, _: ...);
-    fn c(_: *mut u8, #[cfg(never)] [w, t, f]: ...,);
-}
-
+#
+#
+#
+#
+#
+#
+#
+#
+#
+#
+fn a(
+    _: *mut u8,
+    ...,
+);
+fn b(
+    _: *mut u8,
+    _: ...,
+);
+fn c(
+    _: *mut u8,
+    #[cfg(never)] [w, t, f]: ...,
+);
 fn main() {
     match .. {
     }
 }
 
 struct A;
-struct B {}
+
+struct B {
+}
+
 struct C();
 
 struct D {
     a: u32,
-    pub b: u32
+    pub b: u32,
 }
 
-struct E(pub x, y,);
-
-//! Adapted from a `rustc` test, which can be found at
-//! https://github.com/rust-lang/rust/blob/6d34ec18c7d7e574553f6347ecf08e1e1c45c13d/src/test/run-pass/weird-exprs.rs.
-//!
-//! Reported to rust-analyzer in https://github.com/rust-lang/rust-analyzer/issues/290
-
-#![allow(non_camel_case_types)]
-#![allow(dead_code)]
-#![allow(unreachable_code)]
-#![allow(unused_parens)]
-
-#![recursion_limit = "128"]
-
-use std::cell::Cell;
-use std::mem::swap;
-
-// Just a grab bag of stuff that you wouldn't want to actually write.
-
-fn strange() -> bool { let _x: bool = return true; }
+struct E(pub x, y);
+#
+#
+#
+#
+#
+fn strange() -> bool {
+    let _x: bool = return true;
+}
 
 fn funny() {
     fn f(_x: ()) { }
       break; }
 }
 
-fn evil_lincoln() { let _evil = println!("lincoln"); }
+fn evil_lincoln() {
+    let _evil = println!("lincoln");
+}
 
 fn dots() {
     assert_eq!(String::from(".................................................."),
 }
 
 fn ktulhu() {
-    ;;;();;;;;;;;;()
+    ();
+    ()
 }
 
 pub fn main() {
     ktulhu();
 }
 
-use foo as bar;
-use foo::{a as b, *, ::*, ::foo as x};
-
-fn g1(#[attr1] #[attr2] pat: Type) {}
-fn g2(#[attr1] x: u8) {}
-
-extern "C" { fn printf(format: *const i8, #[attr] ...) -> i32; }
+fn g1(#[attr1] #[attr2] pat: Type) {
+}
 
+fn g2(#[attr1] x: u8) {
+}
+fn printf(
+    format: *const i8,
+    #[attr] ...,
+) -> i32;
 trait Foo {
-    fn bar(#[attr] _: u64, # [attr] mut x: i32);
+    fn bar(
+        #[attr] _: u64,
+        # [attr] mut x: i32,
+    );
 }
 
 impl S {
-     fn f(#[must_use] self) {}
-     fn g1(#[attr] self) {}
-     fn g2(#[attr] &self) {}
-     fn g3<'a>(#[attr] &mut self) {}
-     fn g4<'a>(#[attr] &'a self) {}
-     fn g5<'a>(#[attr] &'a mut self) {}
-     fn c(#[attr] self: Self) {}
-     fn d(#[attr] self: Rc<Self>) {}
+    fn f(#[must_use] self) {
+    }
+
+    fn g1(#[attr] self) {
+    }
+
+    fn g2(#[attr] &self) {
+    }
+
+    fn g3<'a>(#[attr] &mut self) {
+    }
+
+    fn g4<'a>(#[attr] &'a self) {
+    }
+
+    fn g5<'a>(#[attr] &'a mut self) {
+    }
+
+    fn c(#[attr] self: Self) {
+    }
+
+    fn d(#[attr] self: Rc<Self>) {
+    }
 }
 
 fn r#foo() {
 }
 
-use foo;
-use ::bar;
-
-
 struct S {
-    foo: u32
+    foo: u32,
 }
 
 fn foo() {
     async {};
     async move {};
 }
-
-#!/use/bin/env rusti
-
-// https://github.com/rust-lang/rust-analyzer/issues/357
-
-//! docs
-// non-docs
-mod foo {}
+#
+mod foo {
+}
 
 type X = ();
 
     let ():::X = ();
 }
 
-use *;
-use ::*;
-use ::{};
-use {};
-use foo::*;
-use foo::{};
-use ::foo::{a, b, c};
-
-fn foo(x: impl std::future::Future<Output = i32>) {}
+fn foo(x: impl std::future::Future<Output = i32>) {
+}
 
 fn main() {
     foo(async move { 12 })
 }
 
 struct A<T>;
+
 struct B<T:>;
+
 struct C<T: 'a>;
+
 struct D<T: 'a + >;
+
 struct E<T: 'a + 'd >;
+
 struct F<T: 'a + 'd + Clone>;
+
 struct G<T: Clone + Copy>;
+
 struct H<T: ::Foo + self::Bar + 'a>;
+
 struct I<T:, U:,>;
+
 struct K<'a: 'd, 'd: 'a + 'b, T: 'a + 'd + Clone>;
 
-async fn foo() {}
-extern fn foo() {}
-const fn foo() {}
-const unsafe fn foo() {}
-unsafe extern "C" fn foo() {}
-unsafe fn foo() {}
-async unsafe fn foo() {}
-const unsafe fn bar() {}
+async fn foo() {
+}
 
-unsafe trait T {}
-auto trait T {}
-unsafe auto trait T {}
+fn foo() {
+}
 
-unsafe impl Foo {}
-default impl Foo {}
-unsafe default impl Foo {}
+const fn foo() {
+}
 
-unsafe extern "C++" {}
+const unsafe fn foo() {
+}
 
+unsafe fn foo() {
+}
+
+unsafe fn foo() {
+}
+
+async unsafe fn foo() {
+}
+
+const unsafe fn bar() {
+}
+
+trait T {
+}
+
+trait T {
+}
+
+trait T {
+}
+
+unsafe impl Foo {
+}
+
+impl Foo {
+}
+
+unsafe impl Foo {
+}
 fn main() {
     unsafe fn f() {}
     unsafe { 92 }
 }
 
-// https://github.com/rust-lang/rust-analyzer/issues/677
 fn main() {
     #[cfg(feature = "backtrace")]
     let exit_code = panic::catch_unwind(move || main());
     ..z = 2;
     x = false..1 == 1;
     let x = 1..;
-
     ..=1 + 1;
     ..=z = 2;
     x = false..=1 == 1;
     let x = 1..;
 }
 
-// format with label break value.
 fn main() {
     'empty_block: {}
-
     'block: {
         do_thing();
         if condition_not_met() {
         }
         do_last_thing();
     }
-
     let result = 'block: {
         if foo() {
             // comment
     };
 }
 
-// https://github.com/rust-lang/rust-analyzer/issues/311
-
 pub fn foo<S: Iterator>() -> String
 where
-    <S as Iterator>::Item: Eq,
-{
+    <S as Iterator>::Item: Eq, {
     "".to_owned()
 }
 
 mod c {
     fn foo() {
     }
-    struct S {}
+    struct S {
+    }
 }
 
 mod d {
     }
 }
 
-fn test() where (u64, u64): Foo {}
+fn test()
+where (u64, u64): Foo {
+}
 
-fn a() -> Foo<bar::Baz> {}
+fn a() -> Foo<bar::Baz> {
+}
 
-fn b(_: impl FnMut(x::Y)) {}
+fn b(_: impl FnMut(x::Y)) {
+}
 
-fn c(_: impl FnMut(&x::Y)) {}
+fn c(_: impl FnMut(&x::Y)) {
+}
 
 #[foo(a,)]
-fn foo() {}
+fn foo() {
+}
 
 type Foo<'a> = &'a (dyn Send + Sync);
+
 type Foo = *const (dyn Send + Sync);
-type Foo = fn() -> (dyn Send + 'static);
+
+type Foo =
+    fn(
+    ) -> (dyn Send + 'static);
+
 fn main() {
     let b = (&a) as &(dyn Add<Other, Output = Addable> + Other);
 }
         );
     }
 }
-
-extern {
-    pub fn socket(domain: ::c_int, ty: ::c_int, protocol: ::c_int) -> ::c_int;
-    pub fn bind(fd: ::c_int, addr: *const sockaddr, len: socklen_t) -> ::c_int;
-    pub fn connect(socket: ::c_int, address: *const sockaddr,
-                   len: socklen_t) -> ::c_int;
-    pub fn listen(socket: ::c_int, backlog: ::c_int) -> ::c_int;
-    pub fn getsockname(socket: ::c_int, address: *mut sockaddr,
-                       address_len: *mut socklen_t) -> ::c_int;
-    pub fn getsockopt(sockfd: ::c_int,
-                      level: ::c_int,
-                      optname: ::c_int,
-                      optval: *mut ::c_void,
-                      optlen: *mut ::socklen_t) -> ::c_int;
-    pub fn setsockopt(socket: ::c_int, level: ::c_int, name: ::c_int,
-                      value: *const ::c_void,
-                      option_len: socklen_t) -> ::c_int;
-    pub fn getpeername(socket: ::c_int, address: *mut sockaddr,
-                       address_len: *mut socklen_t) -> ::c_int;
-    pub fn sendto(socket: ::c_int, buf: *const ::c_void, len: ::size_t,
-                  flags: ::c_int, addr: *const sockaddr,
-                  addrlen: socklen_t) -> ::ssize_t;
-    pub fn send(socket: ::c_int, buf: *const ::c_void, len: ::size_t,
-                flags: ::c_int) -> ::ssize_t;
-    pub fn recvfrom(socket: ::c_int, buf: *mut ::c_void, len: ::size_t,
-                    flags: ::c_int, addr: *mut ::sockaddr,
-                    addrlen: *mut ::socklen_t) -> ::ssize_t;
-    pub fn recv(socket: ::c_int, buf: *mut ::c_void, len: ::size_t,
-                flags: ::c_int) -> ::ssize_t;
-}
-
-// https://github.com/rust-lang/rust-analyzer/issues/596
-
+pub fn socket(
+    domain: ::c_int,
+    ty: ::c_int,
+    protocol: ::c_int,
+) -> ::c_int;
+pub fn bind(
+    fd: ::c_int,
+    addr: *const sockaddr,
+    len: socklen_t,
+) -> ::c_int;
+pub fn connect(
+    socket: ::c_int,
+    address: *const sockaddr,
+    len: socklen_t,
+) -> ::c_int;
+pub fn listen(
+    socket: ::c_int,
+    backlog: ::c_int,
+) -> ::c_int;
+pub fn getsockname(
+    socket: ::c_int,
+    address: *mut sockaddr,
+    address_len: *mut socklen_t,
+) -> ::c_int;
+pub fn getsockopt(
+    sockfd: ::c_int,
+    level: ::c_int,
+    optname: ::c_int,
+    optval: *mut ::c_void,
+    optlen: *mut ::socklen_t,
+) -> ::c_int;
+pub fn setsockopt(
+    socket: ::c_int,
+    level: ::c_int,
+    name: ::c_int,
+    value: *const ::c_void,
+    option_len: socklen_t,
+) -> ::c_int;
+pub fn getpeername(
+    socket: ::c_int,
+    address: *mut sockaddr,
+    address_len: *mut socklen_t,
+) -> ::c_int;
+pub fn sendto(
+    socket: ::c_int,
+    buf: *const ::c_void,
+    len: ::size_t,
+    flags: ::c_int,
+    addr: *const sockaddr,
+    addrlen: socklen_t,
+) -> ::ssize_t;
+pub fn send(
+    socket: ::c_int,
+    buf: *const ::c_void,
+    len: ::size_t,
+    flags: ::c_int,
+) -> ::ssize_t;
+pub fn recvfrom(
+    socket: ::c_int,
+    buf: *mut ::c_void,
+    len: ::size_t,
+    flags: ::c_int,
+    addr: *mut ::sockaddr,
+    addrlen: *mut ::socklen_t,
+) -> ::ssize_t;
+pub fn recv(
+    socket: ::c_int,
+    buf: *mut ::c_void,
+    len: ::size_t,
+    flags: ::c_int,
+) -> ::ssize_t;
 struct Foo;
 
 impl Foo {
     }
 }
 
-fn baz(_: bool) {}
+fn baz(_: bool) {
+}
 
 fn main() {
     baz(<Foo>::bar())
 }
 
-// https://github.com/rust-lang/rust-analyzer/pull/983
-
 fn compound_assignment() {
     let mut a = 0;
     a += 1;
     a <<= 12;
 }
 
-
 fn main() {
     const fn f() {}
 }
 
 trait T {
-    fn f1((a, b): (usize, usize)) {}
-    fn f2(S { a, b }: S) {}
-    fn f3(NewType(a): NewType) {}
-    fn f4(&&a: &&usize) {}
-    fn bar(_: u64, mut x: i32);
+    fn f1((a, b): (usize, usize)) {
+    }
+
+    fn f2(S { a, b }: S) {
+    }
+
+    fn f3(NewType(a): NewType) {
+    }
+
+    fn f4(&&a: &&usize) {
+    }
+
+    fn bar(
+        _: u64,
+        mut x: i32,
+    );
 }
 
-fn f<T>() where T: Fn() -> u8 + Send {}
+fn f<T>()
+where T: Fn() -> u8 + Send {
+}
 
 impl U {
-    fn f1((a, b): (usize, usize)) {}
-    fn f2(S { a, b }: S) {}
-    fn f3(NewType(a): NewType) {}
-    fn f4(&&a: &&usize) {}
+    fn f1((a, b): (usize, usize)) {
+    }
+
+    fn f2(S { a, b }: S) {
+    }
+
+    fn f3(NewType(a): NewType) {
+    }
+
+    fn f4(&&a: &&usize) {
+    }
 }
 
 trait T {
-  default type T = Bar;
-  default const f: u8 = 0;
-  default fn foo() {}
-  default unsafe fn bar() {}
+    type T = Bar;
+
+    const f: u8 = 0;
+
+    fn foo() {
+    }
+
+    unsafe fn bar() {
+    }
 }
 
 impl T for Foo {
-  default type T = Bar;
-  default const f: u8 = 0;
-  default fn foo() {}
-  default unsafe fn bar() {}
+    type T = Bar;
+
+    const f: u8 = 0;
+
+    fn foo() {
+    }
+
+    unsafe fn bar() {
+    }
 }
 
-default impl T for () {}
-default unsafe impl T for () {}
-
-extern {
+impl T for () {
 }
 
-extern "C" {
+unsafe impl T for () {
 }
-
 #[cfg(test)]
 #[Ignore]
-fn foo() {}
-
-#[path = "a.rs"]
-mod b;
+fn foo() {
+}
 
 struct S1<T>;
+
 struct S2<T>(u32);
-struct S3<T> { u: u32 }
+
+struct S3<T> {
+    u: u32,
+}
 
 struct S4<>;
+
 struct S5<'a>;
+
 struct S6<'a:>;
+
 struct S7<'a: 'b>;
+
 struct S8<'a: 'b + >;
+
 struct S9<'a: 'b + 'c>;
+
 struct S10<'a,>;
+
 struct S11<'a, 'b>;
+
 struct S12<'a: 'b+, 'b: 'c,>;
 
 struct S13<T>;
+
 struct S14<T, U>;
+
 struct S15<'a, T, U>;
 
 trait Runnable {
 }
 
 fn foo() {
-   for _x in 0 .. (0 .. {1 + 2}).sum::<u32>() {
+    for _x in 0 .. (0 .. {1 + 2}).sum::<u32>() {
        break;
    }
 }
     #[A] { #[B] bar!()? }
     #[C] &()
 }
-
-br##"
-
-b"\"
-b"\"
-b"\u{_0000}"
-b"\u{0000000}"
-b"\u{FFFFFF}"
-b"\u{ffffff}"
-b"\u{ffffff}"
-b"\u{DC00}"
-b"\u{DDDD}"
-b"\u{DFFF}"
-b"\u{D800}"
-b"\u{DAAA}"
-b"\u{DBFF}"
-b"\x"
-
-0e
-0E
-
-42e+
-42e-
-42E+
-42E-
-
-42.e+
-42.e-
-42.E+
-42.E-
-
-42.2e+
-42.2e-
-42.2E+
-42.2E-
-
-42.2e+f32
-42.2e-f32
-42.2E+f32
-42.2E-f32
-
-b"\x7f
-
-0b
-0o
-0x
-
-0b_
-0o_
-0x_
-
-0bnoDigit
-0onoDigit
-0xnoDigit
-
-0xG
-0xg
-
-0x_g
-0x_G
-
-'
-
-'\
-
-r## I lack a quote!
-
-b"
-
-br##"\x7f
-
-"\"
-"\"
-"\u{_0000}"
-"\u{0000000}"
-"\u{FFFFFF}"
-"\u{ffffff}"
-"\u{ffffff}"
-"\u{DC00}"
-"\u{DDDD}"
-"\u{DFFF}"
-"\u{D800}"
-"\u{DAAA}"
-"\u{DBFF}"
-"\x"
-
-b'\
-
-r##"\x7f
-
-/* /* /*
-
-br##"\n
-
-"
-
-r##"
-
-b'
-
-b"\
-
-b"
-
-/** /*! /* comment */ */
-
-fn main() {
-    hello("world);
-    // a bunch of code was here
-    env("FLAGS", "-help")
+fn finalize_with_eof(mut self) -> LexedStr<'a> {
+    self.res.push(EOF, self.offset);
+    self.res
 }
 
-b'\n
-
-'
-
-b'
-
-"
-
-b"\n
-
-br##"\u{20AA}
-
-b"\u{20AA}
-
-"\u{20AA}
-
-br##"
-
-"\x7f
-
-r##"\
-
-b'\'
-
-b'
-
-'\n
-
-br##
-
-br##"\
-
-r##"
-
-"
-
-c"\"
-c"\"
-c"\u{_0000}"
-c"\u{0000000}"
-c"\u{FFFFFF}"
-c"\u{ffffff}"
-c"\u{ffffff}"
-c"\u{DC00}"
-c"\u{DDDD}"
-c"\u{DFFF}"
-c"\u{D800}"
-c"\u{DAAA}"
-c"\u{DBFF}"
-c"\x"
-
-b"\"
-
-b'\x7f
-
-br##"
-
-'
-
-b"
-
-br## I lack a quote!
-
-r##"\u{20AA}
-
-b'\u{20AA}
-
-"\"
-
-"\
-
-"\n
-
-r##"
-
-/*
-
-'hello'
-''
-'
-'
-'spam'
-'\x0ff'
-'\"a'
-'\na'
-'\ra'
-'\ta'
-'\\a'
-'\'a'
-'\0a'
-'\u{0}x'
-'\u{1F63b}}'
-'\v'
-'\'
-'\'
-'\\\r'
-'\x'
-'\x0'
-'\xf'
-'\xa'
-'\xx'
-'\x'
-'\x'
-'\xtt'
-'\xff'
-'\xFF'
-'\x80'
-'\u'
-'\u[0123]'
-'\u{0x}'
-'\u{'
-'\u{0000'
-'\u{}'
-'\u{_0000}'
-'\u{0000000}'
-'\u{FFFFFF}'
-'\u{ffffff}'
-'\u{ffffff}'
-'\u{DC00}'
-'\u{DDDD}'
-'\u{DFFF}'
-'\u{D800}'
-'\u{DAAA}'
-'\u{DBFF}'
-
-'1
-'1lifetime
-
-'\'
-
-'\u{20AA}
-
-b''
-b'\'
-b'
-'
-b'spam'
-b'\x0ff'
-b'\"a'
-b'\na'
-b'\ra'
-b'\ta'
-b'\\a'
-b'\'a'
-b'\0a'
-b'\u{0}x'
-b'\u{1F63b}}'
-b'\v'
-b'\'
-b'\'
-b'\\\r'
-b'\x'
-b'\x0'
-b'\xf'
-b'\xa'
-b'\xx'
-b'\x'
-b'\x'
-b'\xtt'
-b'\u'
-b'\u[0123]'
-b'\u{0x}'
-b'\u{'
-b'\u{0000'
-b'\u{}'
-b'\u{_0000}'
-b'\u{0000000}'
-b'\u{FFFFFF}'
-b'\u{ffffff}'
-b'\u{ffffff}'
-b'\u{DC00}'
-b'\u{DDDD}'
-b'\u{DFFF}'
-b'\u{D800}'
-b'\u{DAAA}'
-b'\u{DBFF}'
-
-'\x7f
-
-r##"\n
-
-r##
-
-/* comment
-
-async fn use struct trait enum impl true false as extern crate
-mod pub self super in where for loop while if match const
-static mut type ref let else move return
-
-b'x' b"foo" br""
-b""ix br""br
-b'\n' b'\\' b'\''
-
-'a 'foo 'foo_bar_baz '_
-
-'x' ' ' '0' '\x7f' '\n' '\\' '\''
-
-#!/usr/bin/env cargo
-
----
-[dependencies]
-clap = "4"
----
-
-fn main() {
-}
-
-"hello" r"world" "\n\"\\no escape" "multi
-line"
-
-hello world
-
-0 00 0_ 0. 0z
-01790 0b1790 0o1790 0x1790aAbBcCdDeEfF 001279 0_1279 0.1279 0e1279 0E1279
-0..2
-0.foo()
-0e+1
-0.e+1
-0.0E-2
-0___0.10000____0000e+111__
-1i64 92.0f32 11__s
-
-/* */
-/**/
-/* /* */ */
-
-a b  c
-d
-
-e	f
-
-r###"this is a r##"raw"## string"###
-
-r#raw_ident
-
-foo foo_ _foo _ __ x 
-
-#!/usr/bin/env bash
-// hello
-//! World
-//!! Inner line doc
-/// Outer line doc
-//// Just a comment
-
-//
-//!
-//!!
-///
-////
-
-//@ edition: 2021
-
-#"foo"
-
-
----
-[dependencies]
-clap = "4"
----
-
-fn main() {
-}
-
-; , ( ) { } [ ] < > @ # ~ ? $ & | + * / ^ %
-. .. ... ..=
-: ::
-= =>
-! !=
-- ->
-
-//! Lexing `&str` into a sequence of Rust tokens.
-//!
-//! Note that strictly speaking the parser in this crate is not required to work
-//! on tokens which originated from text. Macros, eg, can synthesize tokens out
-//! of thin air. So, ideally, lexer should be an orthogonal crate. It is however
-//! convenient to include a text-based lexer here!
-//!
-//! Note that these tokens, unlike the tokens we feed into the parser, do
-//! include info about comments and whitespace.
-
-use std::ops;
-
-use rustc_literal_escaper::{
-    EscapeError, Mode, unescape_byte, unescape_byte_str, unescape_c_str, unescape_char,
-    unescape_str,
-};
-
-use crate::{
-    Edition,
-    SyntaxKind::{self, *},
-    T,
-};
-
-pub struct LexedStr<'a> {
-    text: &'a str,
-    kind: Vec<SyntaxKind>,
-    start: Vec<u32>,
-    error: Vec<LexError>,
-}
-
-struct LexError {
-    msg: String,
-    token: u32,
-}
-
-impl<'a> LexedStr<'a> {
-    pub fn new(edition: Edition, text: &'a str) -> LexedStr<'a> {
-        let _p = tracing::info_span!("LexedStr::new").entered();
-        let mut conv = Converter::new(edition, text);
-        if let Ok(script) = crate::frontmatter::ScriptSource::parse(text) {
-            if let Some(shebang) = script.shebang_span() {
-                conv.push(SHEBANG, shebang.end - shebang.start, Vec::new());
-            }
-            if script.frontmatter().is_some() {
-                conv.push(FRONTMATTER, script.content_span().start - conv.offset, Vec::new());
-            }
-        } else if let Some(shebang_len) = rustc_lexer::strip_shebang(text) {
-            // Leave error reporting to `rustc_lexer`
-            conv.push(SHEBANG, shebang_len, Vec::new());
-        }
-
-        // Re-create the tokenizer from scratch every token because `GuardedStrPrefix` is one token in the lexer
-        // but we want to split it to two in edition <2024.
-        while let Some(token) =
-            rustc_lexer::tokenize(&text[conv.offset..], rustc_lexer::FrontmatterAllowed::No).next()
-        {
-            let token_text = &text[conv.offset..][..token.len as usize];
-
-            conv.extend_token(&token.kind, token_text);
-        }
-
-        conv.finalize_with_eof()
-    }
-
-    pub fn single_token(edition: Edition, text: &'a str) -> Option<(SyntaxKind, Option<String>)> {
-        if text.is_empty() {
-            return None;
-        }
-
-        let token = rustc_lexer::tokenize(text, rustc_lexer::FrontmatterAllowed::No).next()?;
-        if token.len as usize != text.len() {
-            return None;
-        }
-
-        let mut conv = Converter::new(edition, text);
-        conv.extend_token(&token.kind, text);
-        match &*conv.res.kind {
-            [kind] => Some((*kind, conv.res.error.pop().map(|it| it.msg))),
-            _ => None,
-        }
-    }
-
-    pub fn as_str(&self) -> &str {
-        self.text
-    }
-
-    pub fn len(&self) -> usize {
-        self.kind.len() - 1
-    }
-
-    pub fn is_empty(&self) -> bool {
-        self.len() == 0
-    }
-
-    pub fn kind(&self, i: usize) -> SyntaxKind {
-        assert!(i < self.len());
-        self.kind[i]
-    }
-
-    pub fn text(&self, i: usize) -> &str {
-        self.range_text(i..i + 1)
-    }
-
-    pub fn range_text(&self, r: ops::Range<usize>) -> &str {
-        assert!(r.start < r.end && r.end <= self.len());
-        let lo = self.start[r.start] as usize;
-        let hi = self.start[r.end] as usize;
-        &self.text[lo..hi]
-    }
-
-    // Naming is hard.
-    pub fn text_range(&self, i: usize) -> ops::Range<usize> {
-        assert!(i < self.len());
-        let lo = self.start[i] as usize;
-        let hi = self.start[i + 1] as usize;
-        lo..hi
-    }
-    pub fn text_start(&self, i: usize) -> usize {
-        assert!(i <= self.len());
-        self.start[i] as usize
-    }
-    pub fn text_len(&self, i: usize) -> usize {
-        assert!(i < self.len());
-        let r = self.text_range(i);
-        r.end - r.start
-    }
-
-    pub fn error(&self, i: usize) -> Option<&str> {
-        assert!(i < self.len());
-        let err = self.error.binary_search_by_key(&(i as u32), |i| i.token).ok()?;
-        Some(self.error[err].msg.as_str())
-    }
-
-    pub fn errors(&self) -> impl Iterator<Item = (usize, &str)> + '_ {
-        self.error.iter().map(|it| (it.token as usize, it.msg.as_str()))
-    }
-
-    fn push(&mut self, kind: SyntaxKind, offset: usize) {
-        self.kind.push(kind);
-        self.start.push(offset as u32);
-    }
-}
-
-struct Converter<'a> {
-    res: LexedStr<'a>,
-    offset: usize,
-    edition: Edition,
-}
-
-impl<'a> Converter<'a> {
-    fn new(edition: Edition, text: &'a str) -> Self {
-        Self {
-            res: LexedStr { text, kind: Vec::new(), start: Vec::new(), error: Vec::new() },
-            offset: 0,
-            edition,
-        }
-    }
-
-    /// Check for likely unterminated string by analyzing STRING token content
-    fn has_likely_unterminated_string(&self) -> bool {
-        let Some(last_idx) = self.res.kind.len().checked_sub(1) else { return false };
-
-        for i in (0..=last_idx).rev().take(5) {
-            if self.res.kind[i] == STRING {
-                let start = self.res.start[i] as usize;
-                let end = self.res.start.get(i + 1).map(|&s| s as usize).unwrap_or(self.offset);
-                let content = &self.res.text[start..end];
-
-                if content.contains('(') && (content.contains("//") || content.contains(";\n")) {
-                    return true;
-                }
-            }
-        }
-        false
-    }
-
-    fn finalize_with_eof(mut self) -> LexedStr<'a> {
-        self.res.push(EOF, self.offset);
-        self.res
-    }
-
-    fn push(&mut self, kind: SyntaxKind, len: usize, errors: Vec<String>) {
-        self.res.push(kind, self.offset);
-        self.offset += len;
-
-        for msg in errors {
+fn push(
+    &mut self,
+    kind: SyntaxKind,
+    len: usize,
+    errors: Vec<String>,
+) {
+    self.res.push(kind, self.offset);
+    self.offset += len;
+    for msg in errors {
             if !msg.is_empty() {
                 self.res.error.push(LexError { msg, token: self.res.len() as u32 });
             }
         }
-    }
+}
 
-    fn extend_token(&mut self, kind: &rustc_lexer::TokenKind, mut token_text: &str) {
-        // A note on an intended tradeoff:
-        // We drop some useful information here (see patterns with double dots `..`)
-        // Storing that info in `SyntaxKind` is not possible due to its layout requirements of
-        // being `u16` that come from `rowan::SyntaxKind`.
-        let mut errors: Vec<String> = vec![];
-
-        let syntax_kind = {
+fn extend_token(
+    &mut self,
+    kind: &rustc_lexer::TokenKind,
+    mut token_text: &str,
+) {
+    // A note on an intended tradeoff:
+    // We drop some useful information here (see patterns with double dots `..`)
+    // Storing that info in `SyntaxKind` is not possible due to its layout requirements of
+    // being `u16` that come from `rowan::SyntaxKind`.
+    let mut errors: Vec<String> = vec![];
+    let syntax_kind = {
             match kind {
                 rustc_lexer::TokenKind::LineComment { doc_style: _ } => COMMENT,
                 rustc_lexer::TokenKind::BlockComment { doc_style: _, terminated } => {
                 rustc_lexer::TokenKind::Eof => EOF,
             }
         };
+    self.push(syntax_kind, token_text.len(), errors);
+}
 
-        self.push(syntax_kind, token_text.len(), errors);
-    }
-
-    fn extend_literal(&mut self, len: usize, kind: &rustc_lexer::LiteralKind) {
-        let invalid_raw_msg = String::from("Invalid raw string literal");
-
-        let mut errors = vec![];
-        let mut no_end_quote = |c: char, kind: &str| {
+fn extend_literal(
+    &mut self,
+    len: usize,
+    kind: &rustc_lexer::LiteralKind,
+) {
+    let invalid_raw_msg = String::from("Invalid raw string literal");
+    let mut errors = vec![];
+    let mut no_end_quote = |c: char, kind: &str| {
             errors.push(format!("Missing trailing `{c}` symbol to terminate the {kind} literal"));
         };
-
-        let syntax_kind = match *kind {
+    let syntax_kind = match *kind {
             rustc_lexer::LiteralKind::Int { empty_int, base: _ } => {
                 if empty_int {
                     errors.push("Missing digits after the integer base prefix".into());
                 C_STRING
             }
         };
-
-        self.push(syntax_kind, len, errors);
-    }
+    self.push(syntax_kind, len, errors);
 }
-
-fn err_to_msg(error: EscapeError, mode: Mode) -> String {
+fn err_to_msg(
+    error: EscapeError,
+    mode: Mode,
+) -> String {
     match error {
         EscapeError::ZeroChars => "empty character literal",
         EscapeError::MoreThanOneChar => "character literal may only contain one codepoint",
     .into()
 }
 
-//! See [`Input`].
-
-use crate::SyntaxKind;
-
 #[allow(non_camel_case_types)]
 type bits = u64;
 
             contextual_kind: Vec::with_capacity(capacity),
         }
     }
+
     #[inline]
-    pub fn push(&mut self, kind: SyntaxKind) {
+    pub fn push(
+        &mut self,
+        kind: SyntaxKind,
+    ) {
         self.push_impl(kind, SyntaxKind::EOF)
     }
+
     #[inline]
-    pub fn push_ident(&mut self, contextual_kind: SyntaxKind) {
+    pub fn push_ident(
+        &mut self,
+        contextual_kind: SyntaxKind,
+    ) {
         self.push_impl(SyntaxKind::IDENT, contextual_kind)
     }
+
     /// Sets jointness for the last token we've pushed.
     ///
     /// This is a separate API rather than an argument to the `push` to make it
         let (idx, b_idx) = self.bit_index(n);
         self.joint[idx] |= 1 << b_idx;
     }
+
     #[inline]
-    fn push_impl(&mut self, kind: SyntaxKind, contextual_kind: SyntaxKind) {
+    fn push_impl(
+        &mut self,
+        kind: SyntaxKind,
+        contextual_kind: SyntaxKind,
+    ) {
         let idx = self.len();
         if idx.is_multiple_of(bits::BITS as usize) {
             self.joint.push(0);
 
 /// pub(crate) impl used by the parser to consume `Tokens`.
 impl Input {
-    pub(crate) fn kind(&self, idx: usize) -> SyntaxKind {
+    pub(crate) fn kind(
+        &self,
+        idx: usize,
+    ) -> SyntaxKind {
         self.kind.get(idx).copied().unwrap_or(SyntaxKind::EOF)
     }
-    pub(crate) fn contextual_kind(&self, idx: usize) -> SyntaxKind {
+
+    pub(crate) fn contextual_kind(
+        &self,
+        idx: usize,
+    ) -> SyntaxKind {
         self.contextual_kind.get(idx).copied().unwrap_or(SyntaxKind::EOF)
     }
-    pub(crate) fn is_joint(&self, n: usize) -> bool {
+
+    pub(crate) fn is_joint(
+        &self,
+        n: usize,
+    ) -> bool {
         let (idx, b_idx) = self.bit_index(n);
         self.joint[idx] & (1 << b_idx) != 0
     }
 }
 
 impl Input {
-    fn bit_index(&self, n: usize) -> (usize, usize) {
+    fn bit_index(
+        &self,
+        n: usize,
+    ) -> (usize, usize) {
         let idx = n / (bits::BITS as usize);
         let b_idx = n % (bits::BITS as usize);
         (idx, b_idx)
     }
+
     fn len(&self) -> usize {
         self.kind.len()
     }
 }
 
-mod prefix_entries;
-mod top_entries;
-
-use std::{
-    fmt::Write,
-    fs,
-    path::{Path, PathBuf},
-};
-
-use expect_test::expect_file;
-
-use crate::{Edition, LexedStr, TopEntryPoint};
-
-#[rustfmt::skip]
-#[path = "../test_data/generated/runner.rs"]
-mod runner;
-
 fn infer_edition(file_path: &Path) -> Edition {
     let file_content = std::fs::read_to_string(file_path).unwrap();
     if let Some(edition) = file_content.strip_prefix("//@ edition: ") {
     }
 }
 
-fn lex(text: &str, edition: Edition) -> String {
+fn lex(
+    text: &str,
+    edition: Edition,
+) -> String {
     let lexed = LexedStr::new(edition, text);
-
     let mut res = String::new();
     for i in 0..lexed.len() {
         let kind = lexed.kind(i);
     }
 }
 
-fn parse(entry: TopEntryPoint, text: &str, edition: Edition) -> (String, bool) {
+fn parse(
+    entry: TopEntryPoint,
+    text: &str,
+    edition: Edition,
+) -> (String, bool) {
     let lexed = LexedStr::new(edition, text);
     let input = lexed.to_input(edition);
     let output = entry.parse(&input, edition);
-
     let mut buf = String::new();
     let mut errors = Vec::new();
     let mut indent = String::new();
         &text[..len],
         text
     );
-
     for (token, msg) in lexed.errors() {
         let pos = lexed.text_start(token);
         errors.push(format!("error {pos}: {msg}\n"));
     }
-
     let has_errors = !errors.is_empty();
     for e in errors {
         buf.push_str(&e);
         let crate_root_dir = Path::new(env!("CARGO_MANIFEST_DIR"));
         let test_data_dir = crate_root_dir.join("test_data");
         let dir = test_data_dir.join(path);
-
         let mut res = Vec::new();
         let read_dir = fs::read_dir(&dir)
             .unwrap_or_else(|err| panic!("can't `read_dir` {}: {err}", dir.display()));
 }
 
 #[track_caller]
-fn run_and_expect_no_errors_with_edition(path: &str, edition: Edition) {
+fn run_and_expect_no_errors_with_edition(
+    path: &str,
+    edition: Edition,
+) {
     let path = PathBuf::from(path);
     let text = std::fs::read_to_string(&path).unwrap();
     let (actual, errors) = parse(TopEntryPoint::SourceFile, &text, edition);
 }
 
 #[track_caller]
-fn run_and_expect_errors_with_edition(path: &str, edition: Edition) {
+fn run_and_expect_errors_with_edition(
+    path: &str,
+    edition: Edition,
+) {
     let path = PathBuf::from(path);
     let text = std::fs::read_to_string(&path).unwrap();
     let (actual, errors) = parse(TopEntryPoint::SourceFile, &text, edition);
     p.set_extension("rast");
     expect_file![p].assert_eq(&actual)
 }
-
-//! The Rust parser.
-//!
-//! NOTE: The crate is undergoing refactors, don't believe everything the docs
-//! say :-)
-//!
-//! The parser doesn't know about concrete representation of tokens and syntax
-//! trees. Abstract [`TokenSource`] and [`TreeSink`] traits are used instead. As
-//! a consequence, this crate does not contain a lexer.
-//!
-//! The [`Parser`] struct from the [`parser`] module is a cursor into the
-//! sequence of tokens.  Parsing routines use [`Parser`] to inspect current
-//! state and advance the parsing.
-//!
-//! The actual parsing happens in the [`grammar`] module.
-//!
-//! Tests for this crate live in the `syntax` crate.
-//!
-//! [`Parser`]: crate::parser::Parser
-
-#![allow(rustdoc::private_intra_doc_links)]
-#![cfg_attr(feature = "in-rust-tree", feature(rustc_private))]
-
-#[cfg(not(feature = "in-rust-tree"))]
-extern crate ra_ap_rustc_lexer as rustc_lexer;
-#[cfg(feature = "in-rust-tree")]
-extern crate rustc_lexer;
-
-mod event;
-mod frontmatter;
-mod grammar;
-mod input;
-mod lexed_str;
-mod output;
-mod parser;
-mod shortcuts;
-mod syntax_kind;
-mod token_set;
-
-pub use T_ as T;
-
-#[cfg(test)]
-mod tests;
-
-pub(crate) use token_set::TokenSet;
-
-pub use edition::Edition;
-
-pub use crate::{
-    input::Input,
-    lexed_str::LexedStr,
-    output::{Output, Step},
-    shortcuts::StrStep,
-    syntax_kind::SyntaxKind,
-};
-
+#
+#
 /// Parse the whole of the input as a given syntactic construct.
 ///
 /// This covers two main use-cases:
 }
 
 impl TopEntryPoint {
-    pub fn parse(&self, input: &Input, edition: Edition) -> Output {
+    pub fn parse(
+        &self,
+        input: &Input,
+        edition: Edition,
+    ) -> Output {
         let _p = tracing::info_span!("TopEntryPoint::parse", ?self).entered();
         let entry_point: fn(&'_ mut parser::Parser<'_>) = match self {
             TopEntryPoint::SourceFile => grammar::entry::top::source_file,
         entry_point(&mut p);
         let events = p.finish();
         let res = event::process(events);
-
         if cfg!(debug_assertions) {
             let mut depth = 0;
             let mut first = true;
             assert!(!first, "no tree at all");
             assert_eq!(depth, 0, "unbalanced tree");
         }
-
         res
     }
 }
 }
 
 impl PrefixEntryPoint {
-    pub fn parse(&self, input: &Input, edition: Edition) -> Output {
+    pub fn parse(
+        &self,
+        input: &Input,
+        edition: Edition,
+    ) -> Output {
         let entry_point: fn(&'_ mut parser::Parser<'_>) = match self {
             PrefixEntryPoint::Vis => grammar::entry::prefix::vis,
             PrefixEntryPoint::Block => grammar::entry::prefix::block,
     ///
     /// Tokens must start with `{`, end with `}` and form a valid brace
     /// sequence.
-    pub fn parse(self, tokens: &Input, edition: Edition) -> Output {
+    pub fn parse(
+        self,
+        tokens: &Input,
+        edition: Edition,
+    ) -> Output {
         let Reparser(r) = self;
         let mut p = parser::Parser::new(tokens, edition);
         r(&mut p);
     }
 }
 
-//! This module provides a way to construct a `File`.
-//! It is intended to be completely decoupled from the
-//! parser, so as to allow to evolve the tree representation
-//! and the parser algorithm independently.
-use std::mem;
-
-use crate::{
-    SyntaxKind::{self, *},
-    output::Output,
-};
-
 /// `Parser` produces a flat list of `Event`s.
 /// They are converted to a tree-structure in
 /// a separate pass, via `TreeBuilder`.
         kind: SyntaxKind,
         forward_parent: Option<u32>,
     },
-
     /// Complete the previous `Start` event
     Finish,
-
     /// Produce a single leaf-element.
     /// `n_raw_tokens` is used to glue complex contextual tokens.
     /// For example, lexer tokenizes `>>` as `>`, `>`, and
 pub(super) fn process(mut events: Vec<Event>) -> Output {
     let mut res = Output::default();
     let mut forward_parents = Vec::new();
-
     for i in 0..events.len() {
         match mem::replace(&mut events[i], Event::tombstone()) {
             Event::Start { kind, forward_parent } => {
             Event::Error { msg } => res.error(msg),
         }
     }
-
     res
 }
 
-//! This is the actual "grammar" of the Rust language.
-//!
-//! Each function in this module and its children corresponds
-//! to a production of the formal grammar. Submodules roughly
-//! correspond to different *areas* of the grammar. By convention,
-//! each submodule starts with `use super::*` import and exports
-//! "public" productions via `pub(super)`.
-//!
-//! See docs for [`Parser`](super::parser::Parser) to learn about API,
-//! available to the grammar, and see docs for [`Event`](super::event::Event)
-//! to learn how this actually manages to produce parse trees.
-//!
-//! Code in this module also contains inline tests, which start with
-//! `// test name-of-the-test` comment and look like this:
-//!
-//! ```text
-//! // test function_with_zero_parameters
-//! // fn foo() {}
-//! ```
-//!
-//! After adding a new inline-test, run `cargo test -p xtask` to
-//! extract it as a standalone text-fixture into
-//! `crates/syntax/test_data/parser/`, and run `cargo test` once to
-//! create the "gold" value.
-//!
-//! Coding convention: rules like `where_clause` always produce either a
-//! node or an error, rules like `opt_where_clause` may produce nothing.
-//! Non-opt rules typically start with `assert!(p.at(FIRST_TOKEN))`, the
-//! caller is responsible for branching on the first token.
-
-mod attributes;
-mod expressions;
-mod generic_args;
-mod generic_params;
-mod items;
-mod params;
-mod paths;
-mod patterns;
-mod types;
-
-use crate::{
-    SyntaxKind::{self, *},
-    T, TokenSet,
-    parser::{CompletedMarker, Marker, Parser},
-};
-
 pub(crate) mod entry {
     use super::*;
-
     pub(crate) mod prefix {
         use super::*;
-
         pub(crate) fn vis(p: &mut Parser<'_>) {
             opt_visibility(p, false);
         }
-
         pub(crate) fn block(p: &mut Parser<'_>) {
             expressions::block_expr(p);
         }
-
         pub(crate) fn stmt(p: &mut Parser<'_>) {
             expressions::stmt(p, expressions::Semicolon::Forbidden);
         }
-
         pub(crate) fn pat(p: &mut Parser<'_>) {
             patterns::pattern_single(p);
         }
-
         pub(crate) fn pat_top(p: &mut Parser<'_>) {
             patterns::pattern(p);
         }
-
         pub(crate) fn ty(p: &mut Parser<'_>) {
             types::type_(p);
         }
             // We can set `is_in_extern=true`, because it only allows `safe fn`, and there is no ambiguity here.
             items::item_or_macro(p, true, true);
         }
-        // Parse a meta item , which excluded [], e.g : #[ MetaItem ]
         pub(crate) fn meta_item(p: &mut Parser<'_>) {
             attributes::meta(p);
         }
     }
-
     pub(crate) mod top {
         use super::*;
-
         pub(crate) fn source_file(p: &mut Parser<'_>) {
             let m = p.start();
             // test frontmatter
             items::mod_contents(p, false);
             m.complete(p, SOURCE_FILE);
         }
-
         pub(crate) fn macro_stmts(p: &mut Parser<'_>) {
             let m = p.start();
-
             while !p.at(EOF) {
                 expressions::stmt(p, expressions::Semicolon::Optional);
             }
-
             m.complete(p, MACRO_STMTS);
         }
-
         pub(crate) fn macro_items(p: &mut Parser<'_>) {
             let m = p.start();
             items::mod_contents(p, false);
             m.complete(p, MACRO_ITEMS);
         }
-
         pub(crate) fn pattern(p: &mut Parser<'_>) {
             let m = p.start();
             patterns::pattern(p);
             }
             m.complete(p, ERROR);
         }
-
         pub(crate) fn type_(p: &mut Parser<'_>) {
             let m = p.start();
             types::type_(p);
             }
             m.complete(p, ERROR);
         }
-
         pub(crate) fn expr(p: &mut Parser<'_>) {
             let m = p.start();
             expressions::expr(p);
             }
             m.complete(p, ERROR);
         }
-
         pub(crate) fn meta_item(p: &mut Parser<'_>) {
             let m = p.start();
             attributes::meta(p);
 
 const VISIBILITY_FIRST: TokenSet = TokenSet::new(&[T![pub]]);
 
-fn opt_visibility(p: &mut Parser<'_>, in_tuple_field: bool) -> bool {
+fn opt_visibility(
+    p: &mut Parser<'_>,
+    in_tuple_field: bool,
+) -> bool {
     if !p.at(T![pub]) {
         return false;
     }
-
     let m = p.start();
     p.bump(T![pub]);
     if p.at(T!['(']) {
     }
 }
 
-fn name_r(p: &mut Parser<'_>, recovery: TokenSet) {
+fn name_r(
+    p: &mut Parser<'_>,
+    recovery: TokenSet,
+) {
     if p.at(IDENT) {
         let m = p.start();
         p.bump(IDENT);
     }
 }
 
-const PATH_NAME_REF_KINDS: TokenSet =
-    TokenSet::new(&[IDENT, T![self], T![super], T![crate], T![Self]]);
+const PATH_NAME_REF_KINDS: TokenSet = TokenSet::new(&[IDENT, T![self], T![super], T![crate], T![Self]]);
 
 fn name_ref_mod_path(p: &mut Parser<'_>) {
     if p.at_ts(PATH_NAME_REF_KINDS) {
     }
 }
 
-const PATH_NAME_REF_OR_INDEX_KINDS: TokenSet =
-    PATH_NAME_REF_KINDS.union(TokenSet::new(&[INT_NUMBER]));
+const PATH_NAME_REF_OR_INDEX_KINDS: TokenSet = PATH_NAME_REF_KINDS.union(TokenSet::new(&[INT_NUMBER]));
 
 fn name_ref_mod_path_or_index(p: &mut Parser<'_>) {
     if p.at_ts(PATH_NAME_REF_OR_INDEX_KINDS) {
     m.complete(p, LIFETIME);
 }
 
-fn error_block(p: &mut Parser<'_>, message: &str) {
+fn error_block(
+    p: &mut Parser<'_>,
+    message: &str,
+) {
     assert!(p.at(T!['{']));
     let m = p.start();
     p.error(message);
     m.complete(p, ERROR);
 }
 
-// test_err top_level_let
-// let ref foo: fn() = 1 + 3;
-fn error_let_stmt(p: &mut Parser<'_>, message: &str) {
+fn error_let_stmt(
+    p: &mut Parser<'_>,
+    message: &str,
+) {
     assert!(p.at(T![let]));
     let m = p.start();
     p.error(message);
     p.expect(ket);
 }
 
-//! See [`Parser`].
-
-use std::cell::Cell;
-
-use drop_bomb::DropBomb;
-
-use crate::{
-    Edition,
-    SyntaxKind::{self, EOF, ERROR, TOMBSTONE},
-    T, TokenSet,
-    event::Event,
-    input::Input,
-};
-
 /// `Parser` struct provides the low-level API for
 /// navigating through the stream of tokens and
 /// constructing the parse tree. The actual parsing
 const PARSER_STEP_LIMIT: usize = if cfg!(debug_assertions) { 150_000 } else { 15_000_000 };
 
 impl<'t> Parser<'t> {
-    pub(super) fn new(inp: &'t Input, edition: Edition) -> Parser<'t> {
+    pub(super) fn new(
+        inp: &'t Input,
+        edition: Edition,
+    ) -> Parser<'t> {
         Parser { inp, pos: 0, events: Vec::new(), steps: Cell::new(0), edition }
     }
 
 
     /// Lookahead operation: returns the kind of the next nth
     /// token.
-    pub(crate) fn nth(&self, n: usize) -> SyntaxKind {
+    pub(crate) fn nth(
+        &self,
+        n: usize,
+    ) -> SyntaxKind {
         assert!(n <= 3);
-
         let steps = self.steps.get();
         assert!((steps as usize) < PARSER_STEP_LIMIT, "the parser seems stuck");
         self.steps.set(steps + 1);
-
         self.inp.kind(self.pos + n)
     }
 
     /// Checks if the current token is `kind`.
-    pub(crate) fn at(&self, kind: SyntaxKind) -> bool {
+    pub(crate) fn at(
+        &self,
+        kind: SyntaxKind,
+    ) -> bool {
         self.nth_at(0, kind)
     }
 
-    pub(crate) fn nth_at(&self, n: usize, kind: SyntaxKind) -> bool {
+    pub(crate) fn nth_at(
+        &self,
+        n: usize,
+        kind: SyntaxKind,
+    ) -> bool {
         match kind {
             T![-=] => self.at_composite2(n, T![-], T![=]),
             T![->] => self.at_composite2(n, T![-], T![>]),
     }
 
     /// Consume the next token if `kind` matches.
-    pub(crate) fn eat(&mut self, kind: SyntaxKind) -> bool {
+    pub(crate) fn eat(
+        &mut self,
+        kind: SyntaxKind,
+    ) -> bool {
         if !self.at(kind) {
             return false;
         }
         true
     }
 
-    pub(crate) fn eat_contextual_kw(&mut self, kind: SyntaxKind) -> bool {
+    pub(crate) fn eat_contextual_kw(
+        &mut self,
+        kind: SyntaxKind,
+    ) -> bool {
         if !self.at_contextual_kw(kind) {
             return false;
         }
         true
     }
 
-    fn at_composite2(&self, n: usize, k1: SyntaxKind, k2: SyntaxKind) -> bool {
+    fn at_composite2(
+        &self,
+        n: usize,
+        k1: SyntaxKind,
+        k2: SyntaxKind,
+    ) -> bool {
         self.inp.kind(self.pos + n) == k1
             && self.inp.kind(self.pos + n + 1) == k2
             && self.inp.is_joint(self.pos + n)
     }
 
-    fn at_composite3(&self, n: usize, k1: SyntaxKind, k2: SyntaxKind, k3: SyntaxKind) -> bool {
+    fn at_composite3(
+        &self,
+        n: usize,
+        k1: SyntaxKind,
+        k2: SyntaxKind,
+        k3: SyntaxKind,
+    ) -> bool {
         self.inp.kind(self.pos + n) == k1
             && self.inp.kind(self.pos + n + 1) == k2
             && self.inp.kind(self.pos + n + 2) == k3
     }
 
     /// Checks if the current token is in `kinds`.
-    pub(crate) fn at_ts(&self, kinds: TokenSet) -> bool {
+    pub(crate) fn at_ts(
+        &self,
+        kinds: TokenSet,
+    ) -> bool {
         kinds.contains(self.current())
     }
 
     /// Checks if the current token is contextual keyword `kw`.
-    pub(crate) fn at_contextual_kw(&self, kw: SyntaxKind) -> bool {
+    pub(crate) fn at_contextual_kw(
+        &self,
+        kw: SyntaxKind,
+    ) -> bool {
         self.inp.contextual_kind(self.pos) == kw
     }
 
     /// Checks if the nth token is contextual keyword `kw`.
-    pub(crate) fn nth_at_contextual_kw(&self, n: usize, kw: SyntaxKind) -> bool {
+    pub(crate) fn nth_at_contextual_kw(
+        &self,
+        n: usize,
+        kw: SyntaxKind,
+    ) -> bool {
         self.inp.contextual_kind(self.pos + n) == kw
     }
 
     }
 
     /// Consume the next token. Panics if the parser isn't currently at `kind`.
-    pub(crate) fn bump(&mut self, kind: SyntaxKind) {
+    pub(crate) fn bump(
+        &mut self,
+        kind: SyntaxKind,
+    ) {
         assert!(self.eat(kind));
     }
 
     }
 
     /// Advances the parser by one token
-    pub(crate) fn split_float(&mut self, mut marker: Marker) -> (bool, Marker) {
+    pub(crate) fn split_float(
+        &mut self,
+        mut marker: Marker,
+    ) -> (bool, Marker) {
         assert!(self.at(SyntaxKind::FLOAT_NUMBER));
         // we have parse `<something>.`
         // `<something>`.0.1
     /// *identifier* token, but the parser remaps it to the
     /// `union` keyword, and keyword is what ends up in the
     /// final tree.
-    pub(crate) fn bump_remap(&mut self, kind: SyntaxKind) {
+    pub(crate) fn bump_remap(
+        &mut self,
+        kind: SyntaxKind,
+    ) {
         if self.nth(0) == EOF {
             // FIXME: panic!?
             return;
     /// FIXME: this should be much more fancy and support
     /// structured errors with spans and notes, like rustc
     /// does.
-    pub(crate) fn error<T: Into<String>>(&mut self, message: T) {
+    pub(crate) fn error<T: Into<String>>(
+        &mut self,
+        message: T,
+    ) {
         let msg = message.into();
         self.push_event(Event::Error { msg });
     }
 
     /// Consume the next token if it is `kind` or emit an error
     /// otherwise.
-    pub(crate) fn expect(&mut self, kind: SyntaxKind) -> bool {
+    pub(crate) fn expect(
+        &mut self,
+        kind: SyntaxKind,
+    ) -> bool {
         if self.eat(kind) {
             return true;
         }
     }
 
     /// Create an error node and consume the next token.
-    pub(crate) fn err_and_bump(&mut self, message: &str) {
+    pub(crate) fn err_and_bump(
+        &mut self,
+        message: &str,
+    ) {
         let m = self.start();
         self.error(message);
         self.bump_any();
     /// Create an error node and consume the next token unless it is in the recovery set.
     ///
     /// Returns true if recovery kicked in.
-    pub(crate) fn err_recover(&mut self, message: &str, recovery: TokenSet) -> bool {
+    pub(crate) fn err_recover(
+        &mut self,
+        message: &str,
+        recovery: TokenSet,
+    ) -> bool {
         if matches!(self.current(), T!['{'] | T!['}']) {
             self.error(message);
             return true;
         }
-
         if self.at_ts(recovery) {
             self.error(message);
             return true;
         }
-
         let m = self.start();
         self.error(message);
         self.bump_any();
         false
     }
 
-    fn do_bump(&mut self, kind: SyntaxKind, n_raw_tokens: u8) {
+    fn do_bump(
+        &mut self,
+        kind: SyntaxKind,
+        n_raw_tokens: u8,
+    ) {
         self.pos += n_raw_tokens as usize;
         self.steps.set(0);
         self.push_event(Event::Token { kind, n_raw_tokens });
     }
 
-    fn push_event(&mut self, event: Event) {
+    fn push_event(
+        &mut self,
+        event: Event,
+    ) {
         self.events.push(event);
     }
 
     /// Finishes the syntax tree node and assigns `kind` to it,
     /// and mark the create a `CompletedMarker` for possible future
     /// operation like `.precede()` to deal with forward_parent.
-    pub(crate) fn complete(mut self, p: &mut Parser<'_>, kind: SyntaxKind) -> CompletedMarker {
+    pub(crate) fn complete(
+        mut self,
+        p: &mut Parser<'_>,
+        kind: SyntaxKind,
+    ) -> CompletedMarker {
         self.bomb.defuse();
         let idx = self.pos as usize;
         match &mut p.events[idx] {
 
     /// Abandons the syntax tree node. All its children
     /// are attached to its parent instead.
-    pub(crate) fn abandon(mut self, p: &mut Parser<'_>) {
+    pub(crate) fn abandon(
+        mut self,
+        p: &mut Parser<'_>,
+    ) {
         self.bomb.defuse();
         let idx = self.pos as usize;
         if idx == p.events.len() - 1 {
 }
 
 impl CompletedMarker {
-    fn new(start_pos: u32, end_pos: u32, kind: SyntaxKind) -> Self {
+    fn new(
+        start_pos: u32,
+        end_pos: u32,
+        kind: SyntaxKind,
+    ) -> Self {
         CompletedMarker { start_pos, end_pos, kind }
     }
 
     /// Append a new `START` events as `[START, FINISH, NEWSTART]`,
     /// then mark `NEWSTART` as `START`'s parent with saving its relative
     /// distance to `NEWSTART` into forward_parent(=2 in this case);
-    pub(crate) fn precede(self, p: &mut Parser<'_>) -> Marker {
+    pub(crate) fn precede(
+        self,
+        p: &mut Parser<'_>,
+    ) -> Marker {
         let new_pos = p.start();
         let idx = self.start_pos as usize;
         match &mut p.events[idx] {
     }
 
     /// Extends this completed marker *to the left* up to `m`.
-    pub(crate) fn extend_to(self, p: &mut Parser<'_>, mut m: Marker) -> CompletedMarker {
+    pub(crate) fn extend_to(
+        self,
+        p: &mut Parser<'_>,
+        mut m: Marker,
+    ) -> CompletedMarker {
         m.bomb.defuse();
         let idx = m.pos as usize;
         match &mut p.events[idx] {
         self.kind
     }
 
-    pub(crate) fn last_token(&self, p: &Parser<'_>) -> Option<SyntaxKind> {
+    pub(crate) fn last_token(
+        &self,
+        p: &Parser<'_>,
+    ) -> Option<SyntaxKind> {
         let end_pos = self.end_pos as usize;
         debug_assert_eq!(p.events[end_pos - 1], Event::Finish);
         p.events[..end_pos].iter().rev().find_map(|event| match event {
     }
 }
 
-//! See [`Output`]
-
-use crate::SyntaxKind;
-
 /// Output of the parser -- a DFS traversal of a concrete syntax tree.
 ///
 /// Use the [`Output::iter`] method to iterate over traversal steps and consume
 
 #[derive(Debug)]
 pub enum Step<'a> {
-    Token { kind: SyntaxKind, n_input_tokens: u8 },
-    FloatSplit { ends_in_dot: bool },
-    Enter { kind: SyntaxKind },
+    Token {
+        kind: SyntaxKind,
+        n_input_tokens: u8,
+    },
+    FloatSplit {
+        ends_in_dot: bool,
+    },
+    Enter {
+        kind: SyntaxKind,
+    },
     Exit,
-    Error { msg: &'a str },
+    Error {
+        msg: &'a str,
+    },
 }
 
 impl Output {
     const EVENT_MASK: u32 = 0b1;
+
     const TAG_MASK: u32 = 0x0000_00F0;
+
     const N_INPUT_TOKEN_MASK: u32 = 0x0000_FF00;
+
     const KIND_MASK: u32 = 0xFFFF_0000;
 
     const ERROR_SHIFT: u32 = Self::EVENT_MASK.trailing_ones();
+
     const TAG_SHIFT: u32 = Self::TAG_MASK.trailing_zeros();
+
     const N_INPUT_TOKEN_SHIFT: u32 = Self::N_INPUT_TOKEN_MASK.trailing_zeros();
+
     const KIND_SHIFT: u32 = Self::KIND_MASK.trailing_zeros();
 
     const TOKEN_EVENT: u8 = 0;
+
     const ENTER_EVENT: u8 = 1;
+
     const EXIT_EVENT: u8 = 2;
+
     const SPLIT_EVENT: u8 = 3;
 
     pub fn iter(&self) -> impl Iterator<Item = Step<'_>> {
         })
     }
 
-    pub(crate) fn token(&mut self, kind: SyntaxKind, n_tokens: u8) {
+    pub(crate) fn token(
+        &mut self,
+        kind: SyntaxKind,
+        n_tokens: u8,
+    ) {
         let e = ((kind as u16 as u32) << Self::KIND_SHIFT)
             | ((n_tokens as u32) << Self::N_INPUT_TOKEN_SHIFT)
             | Self::EVENT_MASK;
         self.event.push(e)
     }
 
-    pub(crate) fn float_split_hack(&mut self, ends_in_dot: bool) {
+    pub(crate) fn float_split_hack(
+        &mut self,
+        ends_in_dot: bool,
+    ) {
         let e = ((Self::SPLIT_EVENT as u32) << Self::TAG_SHIFT)
             | ((ends_in_dot as u32) << Self::N_INPUT_TOKEN_SHIFT)
             | Self::EVENT_MASK;
         self.event.push(e);
     }
 
-    pub(crate) fn enter_node(&mut self, kind: SyntaxKind) {
+    pub(crate) fn enter_node(
+        &mut self,
+        kind: SyntaxKind,
+    ) {
         let e = ((kind as u16 as u32) << Self::KIND_SHIFT)
             | ((Self::ENTER_EVENT as u32) << Self::TAG_SHIFT)
             | Self::EVENT_MASK;
         self.event.push(e)
     }
 
-    pub(crate) fn error(&mut self, error: String) {
+    pub(crate) fn error(
+        &mut self,
+        error: String,
+    ) {
         let idx = self.error.len();
         self.error.push(error);
         let e = (idx as u32) << Self::ERROR_SHIFT;
     }
 }
 
-//! Defines [`SyntaxKind`] -- a fieldless enum of all possible syntactic
-//! constructs of the Rust language.
-
-#[rustfmt::skip]
-mod generated;
-
-use crate::Edition;
-
-#[allow(unreachable_pub)]
-pub use self::generated::SyntaxKind;
-
 impl From<u16> for SyntaxKind {
     #[inline]
     fn from(d: u16) -> SyntaxKind {
     }
 }
 
-use super::*;
-
-// test use_item
-// use std::collections;
-pub(super) fn use_(p: &mut Parser<'_>, m: Marker) {
+pub(super) fn use_(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     p.bump(T![use]);
     use_tree(p, true);
     p.expect(T![;]);
     m.complete(p, USE);
 }
 
-// test use_tree
-// use outer::tree::{inner::tree};
-fn use_tree(p: &mut Parser<'_>, top_level: bool) -> bool {
+fn use_tree(
+    p: &mut Parser<'_>,
+    top_level: bool,
+) -> bool {
     let m = p.start();
     match p.current() {
         // test use_tree_star
     true
 }
 
-pub(super) const USE_TREE_LIST_RECOVERY_SET: TokenSet =
-    TokenSet::new(&[T![;], T![,], T![.], T![ident]]).union(ITEM_RECOVERY_SET);
+pub(super) const USE_TREE_LIST_RECOVERY_SET: TokenSet = TokenSet::new(&[T![;], T![,], T![.], T![ident]]).union(ITEM_RECOVERY_SET);
 
 pub(super) const USE_TREE_LIST_FIRST_SET: TokenSet = TokenSet::new(&[T!['{'], T![ident]]);
 
-// test use_tree_list
-// use {a, b, c};
 pub(crate) fn use_tree_list(p: &mut Parser<'_>) {
     assert!(p.at(T!['{']));
     let m = p.start();
-
     // test_err use_tree_list_err_recovery
     // use {a;
     // use b;
         USE_TREE_LIST_FIRST_SET,
         |p: &mut Parser<'_>| use_tree(p, false) || p.at_ts(USE_TREE_LIST_RECOVERY_SET),
     );
-
     m.complete(p, USE_TREE_LIST);
 }
 
-use super::*;
-
-// test trait_item
-// trait T { fn new() -> Self; }
-pub(super) fn trait_(p: &mut Parser<'_>, m: Marker) {
+pub(super) fn trait_(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     p.bump(T![trait]);
     name_r(p, ITEM_RECOVERY_SET);
-
     // test trait_item_generic_params
     // trait X<U: Debug + Display> {}
     generic_params::opt_generic_param_list(p);
-
     if p.eat(T![=]) {
         // test trait_alias
         // trait Z<U> = T<U>;
         m.complete(p, TRAIT);
         return;
     }
-
     if p.at(T![:]) {
         // test trait_item_bounds
         // trait T: Hash + Clone {}
         generic_params::bounds(p);
     }
-
     // test trait_item_where_clause
     // trait T where Self: Copy {}
     generic_params::opt_where_clause(p);
-
     if p.at(T!['{']) {
         assoc_item_list(p);
     } else {
     m.complete(p, TRAIT);
 }
 
-// test impl_item
-// impl S {}
-pub(super) fn impl_(p: &mut Parser<'_>, m: Marker) {
+pub(super) fn impl_(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     p.bump(T![impl]);
     if p.at(T![<]) && not_a_qualified_path(p) {
         generic_params::opt_generic_param_list(p);
     }
-
     // test impl_item_const
     // impl const Send for S {}
     p.eat(T![const]);
-
     // test impl_item_never_type
     // impl ! {}
     if p.at(T![!]) && !p.nth_at(1, T!['{']) {
     m.complete(p, IMPL);
 }
 
-// test assoc_item_list
-// impl F {
-//     type A = i32;
-//     const B: i32 = 92;
-//     fn foo() {}
-//     fn bar(&self) {}
-// }
 pub(crate) fn assoc_item_list(p: &mut Parser<'_>) {
     assert!(p.at(T!['{']));
-
     let m = p.start();
     p.bump(T!['{']);
     // test assoc_item_list_inner_attrs
     // impl S { #![attr] }
     attributes::inner_attrs(p);
-
     while !p.at(EOF) && !p.at(T!['}']) {
         if p.at(T!['{']) {
             error_block(p, "expected an item");
     m.complete(p, ASSOC_ITEM_LIST);
 }
 
-// test impl_type_params
-// impl<const N: u32> Bar<N> {}
 fn not_a_qualified_path(p: &Parser<'_>) -> bool {
     // There's an ambiguity between generic parameters and qualified paths in impls.
     // If we see `<` it may start both, so we have to inspect some following tokens.
         && ([T![>], T![,], T![:], T![=]].contains(&p.nth(2)))
 }
 
-// test_err impl_type
-// impl Type {}
-// impl Trait1 for T {}
-// impl impl NotType {}
-// impl Trait2 for impl NotType {}
 pub(crate) fn impl_type(p: &mut Parser<'_>) {
     if p.at(T![impl]) {
         p.error("expected trait or type");
     types::type_(p);
 }
 
-use super::*;
-
-// test const_item
-// const C: u32 = 92;
-pub(super) fn konst(p: &mut Parser<'_>, m: Marker) {
+pub(super) fn konst(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     p.bump(T![const]);
     const_or_static(p, m, true);
 }
 
-pub(super) fn static_(p: &mut Parser<'_>, m: Marker) {
+pub(super) fn static_(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     p.bump(T![static]);
     const_or_static(p, m, false);
 }
 
-fn const_or_static(p: &mut Parser<'_>, m: Marker, is_const: bool) {
+fn const_or_static(
+    p: &mut Parser<'_>,
+    m: Marker,
+    is_const: bool,
+) {
     p.eat(T![mut]);
-
     if is_const && p.eat(T![_]) {
         // test anonymous_const
         // const _: u32 = 0;
         // static _: i32 = 5;
         name(p);
     }
-
     // FIXME: Recover on statics with generic params/where clause.
     if !is_const && p.at(T![<]) {
         // test_err generic_static
     //     const C<'a>: &'a () = &();
     // }
     generic_params::opt_generic_param_list(p);
-
     if p.at(T![:]) {
         types::ascription(p);
     } else if is_const {
     if p.eat(T![=]) {
         expressions::expr(p);
     }
-
     if is_const {
         // test const_where_clause
         // const C<i32>: u32 = 0
     // test_err static_where_clause
     // static C: u32 = 0
     // where i32: Copy;
-
     p.expect(T![;]);
     m.complete(p, if is_const { CONST } else { STATIC });
 }
 
-use crate::grammar::attributes::ATTRIBUTE_FIRST;
-
-use super::*;
-
-// test struct_item
-// struct S {}
-pub(super) fn strukt(p: &mut Parser<'_>, m: Marker) {
+pub(super) fn strukt(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     p.bump(T![struct]);
     struct_or_union(p, m, true);
 }
 
-// test union_item
-// struct U { i: i32, f: f32 }
-pub(super) fn union(p: &mut Parser<'_>, m: Marker) {
+pub(super) fn union(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     assert!(p.at_contextual_kw(T![union]));
     p.bump_remap(T![union]);
     struct_or_union(p, m, false);
 }
 
-fn struct_or_union(p: &mut Parser<'_>, m: Marker, is_struct: bool) {
+fn struct_or_union(
+    p: &mut Parser<'_>,
+    m: Marker,
+    is_struct: bool,
+) {
     name_r(p, ITEM_RECOVERY_SET);
     generic_params::opt_generic_param_list(p);
     match p.current() {
     m.complete(p, if is_struct { STRUCT } else { UNION });
 }
 
-pub(super) fn enum_(p: &mut Parser<'_>, m: Marker) {
+pub(super) fn enum_(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     p.bump(T![enum]);
     name_r(p, ITEM_RECOVERY_SET);
     generic_params::opt_generic_param_list(p);
     }
     p.expect(T!['}']);
     m.complete(p, VARIANT_LIST);
-
     fn variant(p: &mut Parser<'_>) {
         let m = p.start();
         attributes::outer_attrs(p);
     }
 }
 
-// test record_field_list
-// struct S { a: i32, b: f32, unsafe c: u8 }
 pub(crate) fn record_field_list(p: &mut Parser<'_>) {
     assert!(p.at(T!['{']));
     let m = p.start();
     }
     p.expect(T!['}']);
     m.complete(p, RECORD_FIELD_LIST);
-
     fn record_field(p: &mut Parser<'_>) {
         let m = p.start();
         // test record_field_attrs
     }
 }
 
-const TUPLE_FIELD_FIRST: TokenSet =
-    types::TYPE_FIRST.union(ATTRIBUTE_FIRST).union(VISIBILITY_FIRST);
+const TUPLE_FIELD_FIRST: TokenSet = types::TYPE_FIRST.union(ATTRIBUTE_FIRST).union(VISIBILITY_FIRST);
 
-// test_err tuple_field_list_recovery
-// struct S(struct S;
-// struct S(A,,B);
 fn tuple_field_list(p: &mut Parser<'_>) {
     assert!(p.at(T!['(']));
     let m = p.start();
             true
         },
     );
-
     m.complete(p, TUPLE_FIELD_LIST);
 }
 
-mod adt;
-mod consts;
-mod traits;
-mod use_item;
-
-pub(crate) use self::{
-    adt::{record_field_list, variant_list},
-    expressions::{match_arm_list, record_expr_field_list},
-    traits::assoc_item_list,
-    use_item::use_tree_list,
-};
-use super::*;
-
-// test mod_contents
-// fn foo() {}
-// macro_rules! foo {}
-// foo::bar!();
-// super::baz! {}
-// struct S;
-pub(super) fn mod_contents(p: &mut Parser<'_>, stop_on_r_curly: bool) {
+pub(super) fn mod_contents(
+    p: &mut Parser<'_>,
+    stop_on_r_curly: bool,
+) {
     attributes::inner_attrs(p);
     while !(p.at(EOF) || (p.at(T!['}']) && stop_on_r_curly)) {
         // We can set `is_in_extern=true`, because it only allows `safe fn`, and there is no ambiguity here.
     T![;],
 ]);
 
-pub(super) fn item_or_macro(p: &mut Parser<'_>, stop_on_r_curly: bool, is_in_extern: bool) {
+pub(super) fn item_or_macro(
+    p: &mut Parser<'_>,
+    stop_on_r_curly: bool,
+    is_in_extern: bool,
+) {
     let m = p.start();
     attributes::outer_attrs(p);
-
     let m = match opt_item(p, m, is_in_extern) {
         Ok(()) => {
             if p.at(T![;]) {
         }
         Err(m) => m,
     };
-
     // test macro_rules_as_macro_name
     // macro_rules! {}
     // macro_rules! ();
     // fn main() {
     //     let foo = macro_rules!();
     // }
-
     // test_err macro_rules_as_macro_name
     // macro_rules! {};
     // macro_rules! ()
             return;
         }
     }
-
     m.abandon(p);
     match p.current() {
         T!['{'] => error_block(p, "expected an item"),
 }
 
 /// Try to parse an item, completing `m` in case of success.
-pub(super) fn opt_item(p: &mut Parser<'_>, m: Marker, is_in_extern: bool) -> Result<(), Marker> {
+pub(super) fn opt_item(
+    p: &mut Parser<'_>,
+    m: Marker,
+    is_in_extern: bool,
+) -> Result<(), Marker> {
     // test_err pub_expr
     // fn foo() { pub 92; }
     let has_visibility = opt_visibility(p, false);
-
     let m = match opt_item_without_modifiers(p, m) {
         Ok(()) => return Ok(()),
         Err(m) => m,
     };
-
     let mut has_mods = false;
     let mut has_extern = false;
-
     // modifiers
     if p.at(T![const]) && p.nth(1) != T!['{'] {
         p.eat(T![const]);
         has_mods = true;
     }
-
     // test_err async_without_semicolon
     // fn foo() { let _ = async {} }
     if p.at(T![async])
         p.eat(T![async]);
         has_mods = true;
     }
-
     // test_err gen_fn 2021
     // gen fn gen_fn() {}
     // async gen fn async_gen_fn() {}
         p.eat(T![gen]);
         has_mods = true;
     }
-
     // test_err unsafe_block_in_mod
     // fn foo(){} unsafe { } fn bar(){}
     if p.at(T![unsafe]) && p.nth(1) != T!['{'] {
         p.eat(T![unsafe]);
         has_mods = true;
     }
-
     // test safe_outside_of_extern
     // fn foo() { safe = true; }
     if is_in_extern && p.at_contextual_kw(T![safe]) {
         p.eat_contextual_kw(T![safe]);
         has_mods = true;
     }
-
     if p.at(T![extern]) {
         has_extern = true;
         has_mods = true;
         p.bump_remap(T![auto]);
         has_mods = true;
     }
-
     // test default_item
     // default impl T for Foo {}
     if p.at_contextual_kw(T![default]) {
             _ => (),
         }
     }
-
     // items
     match p.current() {
         T![fn] => fn_(p, m),
     Ok(())
 }
 
-fn opt_item_without_modifiers(p: &mut Parser<'_>, m: Marker) -> Result<(), Marker> {
+fn opt_item_without_modifiers(
+    p: &mut Parser<'_>,
+    m: Marker,
+) -> Result<(), Marker> {
     let la = p.nth(1);
     match p.current() {
         T![extern] if la == T![crate] => extern_crate(p, m),
     Ok(())
 }
 
-// test extern_crate
-// extern crate foo;
-// extern crate self;
-fn extern_crate(p: &mut Parser<'_>, m: Marker) {
+fn extern_crate(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     p.bump(T![extern]);
     p.bump(T![crate]);
-
     name_ref_or_self(p);
-
     // test extern_crate_rename
     // extern crate foo as bar;
     // extern crate self as bar;
     m.complete(p, EXTERN_CRATE);
 }
 
-// test mod_item
-// mod a;
-pub(crate) fn mod_item(p: &mut Parser<'_>, m: Marker) {
+pub(crate) fn mod_item(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     p.bump(T![mod]);
     name(p);
     if p.at(T!['{']) {
     m.complete(p, MODULE);
 }
 
-// test type_alias
-// type Foo = Bar;
-fn type_alias(p: &mut Parser<'_>, m: Marker) {
+fn type_alias(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     p.bump(T![type]);
-
     name(p);
-
     // test type_item_type_params
     // type Result<T> = ();
     generic_params::opt_generic_param_list(p);
-
     if p.at(T![:]) {
         generic_params::bounds(p);
     }
-
     // test type_item_where_clause_deprecated
     // type Foo where Foo: Copy = ();
     generic_params::opt_where_clause(p);
     if p.eat(T![=]) {
         types::type_(p);
     }
-
     // test type_item_where_clause
     // type Foo = () where Foo: Copy;
     generic_params::opt_where_clause(p);
-
     p.expect(T![;]);
     m.complete(p, TYPE_ALIAS);
 }
     m.complete(p, EXTERN_ITEM_LIST);
 }
 
-// test try_macro_rules 2015
-// macro_rules! try { () => {} }
-fn macro_rules(p: &mut Parser<'_>, m: Marker) {
+fn macro_rules(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     assert!(p.at_contextual_kw(T![macro_rules]));
     p.bump_remap(T![macro_rules]);
     p.expect(T![!]);
-
     name(p);
-
     match p.current() {
         // test macro_rules_non_brace
         // macro_rules! m ( ($i:ident) => {} );
     m.complete(p, MACRO_RULES);
 }
 
-// test macro_def
-// macro m($i:ident) {}
-fn macro_def(p: &mut Parser<'_>, m: Marker) {
+fn macro_def(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     p.expect(T![macro]);
     name_r(p, ITEM_RECOVERY_SET);
     if p.at(T!['{']) {
     } else {
         p.error("unmatched `(`");
     }
-
     m.complete(p, MACRO_DEF);
 }
 
-// test fn_
-// fn foo() {}
-fn fn_(p: &mut Parser<'_>, m: Marker) {
+fn fn_(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     p.bump(T![fn]);
-
     name_r(p, ITEM_RECOVERY_SET);
     // test function_type_params
     // fn foo<T: Clone + Copy>(){}
     generic_params::opt_generic_param_list(p);
-
     if p.at(T!['(']) {
         params::param_list_fn_def(p);
     } else {
     // fn foo() {}
     // fn bar() -> () {}
     opt_ret_type(p);
-
     // test_err fn_ret_recovery
     // fn foo() -> A>]) { let x = 1; }
     // fn foo() -> A>]) where T: Copy { let x = 1; }
         // recover from unbalanced return type brackets
         p.err_and_bump("expected a curly brace");
     }
-
     // test function_where_clause
     // fn foo<T>() where T: Copy {}
     generic_params::opt_where_clause(p);
-
     // test fn_decl
     // trait T { fn foo(); }
     if !p.eat(T![;]) {
     m.complete(p, FN);
 }
 
-fn macro_call(p: &mut Parser<'_>, m: Marker) {
+fn macro_call(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     assert!(p.at(T![!]));
     match macro_call_after_excl(p) {
         BlockLike::Block => (),
 
 pub(super) fn macro_call_after_excl(p: &mut Parser<'_>) -> BlockLike {
     p.expect(T![!]);
-
     match p.current() {
         T!['{'] => {
             token_tree(p);
     m.complete(p, TOKEN_TREE);
 }
 
-use crate::grammar::types::type_;
-
-use super::*;
-
-// test expr_literals
-// fn foo() {
-//     let _ = true;
-//     let _ = false;
-//     let _ = 1;
-//     let _ = 2.0;
-//     let _ = b'a';
-//     let _ = 'b';
-//     let _ = "c";
-//     let _ = r"d";
-//     let _ = b"e";
-//     let _ = br"f";
-//     let _ = c"g";
-//     let _ = cr"h";
-// }
 pub(crate) const LITERAL_FIRST: TokenSet = TokenSet::new(&[
     T![true],
     T![false],
     Some(m.complete(p, LITERAL))
 }
 
-// E.g. for after the break in `if break {}`, this should not match
-pub(super) const ATOM_EXPR_FIRST: TokenSet =
-    LITERAL_FIRST.union(paths::PATH_FIRST).union(TokenSet::new(&[
+pub(super) const ATOM_EXPR_FIRST: TokenSet = LITERAL_FIRST.union(paths::PATH_FIRST).union(TokenSet::new(&[
         T!['('],
         T!['{'],
         T!['['],
         LIFETIME_IDENT,
     ]));
 
-pub(in crate::grammar) const EXPR_RECOVERY_SET: TokenSet =
-    TokenSet::new(&[T!['}'], T![')'], T![']'], T![,]]);
+pub(in crate::grammar) const EXPR_RECOVERY_SET: TokenSet = TokenSet::new(&[T!['}'], T![')'], T![']'], T![,]]);
 
 pub(super) fn atom_expr(
     p: &mut Parser<'_>,
     Some((done, blocklike))
 }
 
-// test tuple_expr
-// fn foo() {
-//     ();
-//     (1);
-//     (1,);
-// }
 fn tuple_expr(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T!['(']));
     let m = p.start();
     p.expect(T!['(']);
-
     let mut saw_comma = false;
     let mut saw_expr = false;
-
     // test_err tuple_expr_leading_comma
     // fn foo() {
     //     (,);
         p.error("expected expression");
         saw_comma = true;
     }
-
     while !p.at(EOF) && !p.at(T![')']) {
         saw_expr = true;
 
     m.complete(p, if saw_expr && !saw_comma { PAREN_EXPR } else { TUPLE_EXPR })
 }
 
-// test builtin_expr
-// fn foo() {
-//     builtin#asm("");
-//     builtin#format_args("", 0, 1, a = 2 + 3, a + b);
-//     builtin#offset_of(Foo, bar.baz.0);
-// }
 fn builtin_expr(p: &mut Parser<'_>) -> Option<CompletedMarker> {
     let m = p.start();
     p.bump_remap(T![builtin]);
     }
 }
 
-// test asm_expr
-// fn foo() {
-//     builtin#asm(
-//         "mov {tmp}, {x}",
-//         "shl {tmp}, 1",
-//         "shl {x}, 2",
-//         "add {x}, {tmp}",
-//         x = inout(reg) x,
-//         tmp = out(reg) _,
-//     );
-// }
-pub(crate) fn parse_asm_expr(p: &mut Parser<'_>, m: Marker) -> Option<CompletedMarker> {
+pub(crate) fn parse_asm_expr(
+    p: &mut Parser<'_>,
+    m: Marker,
+) -> Option<CompletedMarker> {
     p.expect(T!['(']);
     if expr(p).is_none() {
         p.err_and_bump("expected asm template");
 
 fn parse_options(p: &mut Parser<'_>) {
     p.expect(T!['(']);
-
     while !p.eat(T![')']) && !p.at(EOF) {
         const OPTIONS: &[SyntaxKind] = &[
             T![pure],
 
 fn parse_clobber_abi(p: &mut Parser<'_>) {
     p.expect(T!['(']);
-
     while !p.eat(T![')']) && !p.at(EOF) {
         if !p.expect(T![string]) {
             break;
     p.expect(T![')']);
 }
 
-// test array_expr
-// fn foo() {
-//     [];
-//     [1];
-//     [1, 2,];
-//     [1; 2];
-// }
 fn array_expr(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T!['[']));
     let m = p.start();
-
     let mut n_exprs = 0u32;
     let mut has_semi = false;
-
     p.bump(T!['[']);
     while !p.at(EOF) && !p.at(T![']']) {
         n_exprs += 1;
         }
     }
     p.expect(T![']']);
-
     m.complete(p, ARRAY_EXPR)
 }
 
-// test lambda_expr
-// fn foo() {
-//     || ();
-//     || -> i32 { 92 };
-//     |x| x;
-//     move |x: i32,| x;
-//     async || {};
-//     move || {};
-//     async move || {};
-//     static || {};
-//     static move || {};
-//     static async || {};
-//     static async move || {};
-//     for<'a> || {};
-//     for<'a> move || {};
-// }
 fn closure_expr(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(match p.current() {
         T![const] | T![static] | T![async] | T![move] | T![|] => true,
         T![for] => p.nth(1) == T![<],
         _ => false,
     });
-
     let m = p.start();
-
     // test closure_binder
     // fn main() { for<'a> || (); }
     if p.at(T![for]) {
     p.eat(T![async]);
     p.eat(T![gen]);
     p.eat(T![move]);
-
     if !p.at(T![|]) {
         p.error("expected `|`");
         return m.complete(p, CLOSURE_EXPR);
     m.complete(p, CLOSURE_EXPR)
 }
 
-// test if_expr
-// fn foo() {
-//     if true {};
-//     if true {} else {};
-//     if true {} else if false {} else {};
-//     if S {};
-//     if { true } { } else { };
-// }
 fn if_expr(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T![if]));
     let m = p.start();
     m.complete(p, IF_EXPR)
 }
 
-// test label
-// fn foo() {
-//     'a: loop {}
-//     'b: while true {}
-//     'c: for x in () {}
-// }
 fn label(p: &mut Parser<'_>) {
     assert!(p.at(LIFETIME_IDENT) && p.nth(1) == T![:]);
     let m = p.start();
     m.complete(p, LABEL);
 }
 
-// test loop_expr
-// fn foo() {
-//     loop {};
-// }
-fn loop_expr(p: &mut Parser<'_>, m: Option<Marker>) -> CompletedMarker {
+fn loop_expr(
+    p: &mut Parser<'_>,
+    m: Option<Marker>,
+) -> CompletedMarker {
     assert!(p.at(T![loop]));
     let m = m.unwrap_or_else(|| p.start());
     p.bump(T![loop]);
     m.complete(p, LOOP_EXPR)
 }
 
-// test while_expr
-// fn foo() {
-//     while true {};
-//     while let Some(x) = it.next() {};
-//     while { true } {};
-// }
-fn while_expr(p: &mut Parser<'_>, m: Option<Marker>) -> CompletedMarker {
+fn while_expr(
+    p: &mut Parser<'_>,
+    m: Option<Marker>,
+) -> CompletedMarker {
     assert!(p.at(T![while]));
     let m = m.unwrap_or_else(|| p.start());
     p.bump(T![while]);
     m.complete(p, WHILE_EXPR)
 }
 
-// test for_expr
-// fn foo() {
-//     for x in [] {};
-// }
-fn for_expr(p: &mut Parser<'_>, m: Option<Marker>) -> CompletedMarker {
+fn for_expr(
+    p: &mut Parser<'_>,
+    m: Option<Marker>,
+) -> CompletedMarker {
     assert!(p.at(T![for]));
     let m = m.unwrap_or_else(|| p.start());
     p.bump(T![for]);
     m.complete(p, FOR_EXPR)
 }
 
-// test let_expr
-// fn foo() {
-//     if let Some(_) = None && true {}
-//     while 1 == 5 && (let None = None) {}
-// }
 fn let_expr(p: &mut Parser<'_>) -> CompletedMarker {
     let m = p.start();
     p.bump(T![let]);
     m.complete(p, LET_EXPR)
 }
 
-// test match_expr
-// fn foo() {
-//     match () { };
-//     match S {};
-//     match { } { _ => () };
-//     match { S {} } {};
-// }
 fn match_expr(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T![match]));
     let m = p.start();
     m.complete(p, MATCH_EXPR)
 }
 
-// test_err match_arms_recovery
-// fn foo() {
-//     match () {
-//         _ => (),,
-//         _ => ,
-//         _ => (),
-//          => (),
-//         if true => (),
-//         _ => (),
-//         () if => (),
-//     }
-// }
 pub(crate) fn match_arm_list(p: &mut Parser<'_>) {
     assert!(p.at(T!['{']));
     let m = p.start();
     p.eat(T!['{']);
-
     // test match_arms_inner_attribute
     // fn foo() {
     //     match () {
     //     }
     // }
     attributes::inner_attrs(p);
-
     while !p.at(EOF) && !p.at(T!['}']) {
         if p.at(T!['{']) {
             error_block(p, "expected match arm");
     m.complete(p, MATCH_ARM_LIST);
 }
 
-// test match_arm
-// fn foo() {
-//     match () {
-//         _ => (),
-//         _ if Test > Test{field: 0} => (),
-//         X | Y if Z => (),
-//         | X | Y if Z => (),
-//         | X => (),
-//     };
-// }
 fn match_arm(p: &mut Parser<'_>) {
     let m = p.start();
     // test match_arms_outer_attributes
     //     }
     // }
     attributes::outer_attrs(p);
-
     patterns::pattern_top_r(p, TokenSet::new(&[T![=], T![if]]));
     if p.at(T![if]) {
         match_guard(p);
     m.complete(p, MATCH_ARM);
 }
 
-// test match_guard
-// fn foo() {
-//     match () {
-//         _ if foo => (),
-//         _ if let foo = bar => (),
-//     }
-// }
 fn match_guard(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T![if]));
     let m = p.start();
     m.complete(p, MATCH_GUARD)
 }
 
-// test block
-// fn a() {}
-// fn b() { let _ = 1; }
-// fn c() { 1; 2; }
-// fn d() { 1; 2 }
 pub(crate) fn block_expr(p: &mut Parser<'_>) {
     if !p.at(T!['{']) {
         p.error("expected a block");
     m.complete(p, STMT_LIST)
 }
 
-// test return_expr
-// fn foo() {
-//     return;
-//     return 92;
-// }
 fn return_expr(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T![return]));
     let m = p.start();
     m.complete(p, RETURN_EXPR)
 }
 
-// test become_expr
-// fn foo() {
-//     become foo();
-// }
 fn become_expr(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T![become]));
     let m = p.start();
     m.complete(p, BECOME_EXPR)
 }
 
-// test yield_expr
-// fn foo() {
-//     yield;
-//     yield 1;
-// }
 fn yield_expr(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T![yield]));
     let m = p.start();
     m.complete(p, YIELD_EXPR)
 }
 
-// test yeet_expr
-// fn foo() {
-//     do yeet;
-//     do yeet 1
-// }
 fn yeet_expr(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T![do]));
     assert!(p.nth_at_contextual_kw(1, T![yeet]));
     m.complete(p, YEET_EXPR)
 }
 
-// test continue_expr
-// fn foo() {
-//     loop {
-//         continue;
-//         continue 'l;
-//     }
-// }
 fn continue_expr(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T![continue]));
     let m = p.start();
     m.complete(p, CONTINUE_EXPR)
 }
 
-// test break_expr
-// fn foo() {
-//     loop {
-//         break;
-//         break 'l;
-//         break 92;
-//         break 'l 92;
-//     }
-// }
-fn break_expr(p: &mut Parser<'_>, r: Restrictions) -> CompletedMarker {
+fn break_expr(
+    p: &mut Parser<'_>,
+    r: Restrictions,
+) -> CompletedMarker {
     assert!(p.at(T![break]));
     let m = p.start();
     p.bump(T![break]);
     m.complete(p, BREAK_EXPR)
 }
 
-// test try_block_expr
-// fn foo() {
-//     let _ = try {};
-// }
-fn try_block_expr(p: &mut Parser<'_>, m: Option<Marker>) -> CompletedMarker {
+fn try_block_expr(
+    p: &mut Parser<'_>,
+    m: Option<Marker>,
+) -> CompletedMarker {
     assert!(p.at(T![try]));
     let m = m.unwrap_or_else(|| p.start());
     p.bump(T![try]);
     m.complete(p, BLOCK_EXPR)
 }
 
-use crate::grammar::attributes::ATTRIBUTE_FIRST;
-
-use super::*;
-
-// test param_list
-// fn a() {}
-// fn b(x: i32) {}
-// fn c(x: i32, ) {}
-// fn d(x: i32, y: ()) {}
-
-// test_err empty_param_slot
-// fn f(y: i32, ,t: i32) {}
 pub(super) fn param_list_fn_def(p: &mut Parser<'_>) {
     list_(p, Flavor::FnDef);
 }
 
 #[derive(Debug, Clone, Copy, PartialEq, Eq)]
 enum Flavor {
-    FnDef, // Includes trait fn params; omitted param idents are not supported
+    FnDef,
     FnPointer,
     Closure,
 }
 
-fn list_(p: &mut Parser<'_>, flavor: Flavor) {
+fn list_(
+    p: &mut Parser<'_>,
+    flavor: Flavor,
+) {
     use Flavor::*;
-
     let (bra, ket) = match flavor {
         Closure => (T![|], T![|]),
         FnDef | FnPointer => (T!['('], T![')']),
     };
-
     let list_marker = p.start();
     p.bump(bra);
-
     let mut param_marker = None;
     if let FnDef = flavor {
         // test self_param_outer_attr
             Err(m) => param_marker = Some(m),
         }
     }
-
     while !p.at(EOF) && !p.at(ket) {
         // test param_outer_arg
         // fn f(#[attr1] pat: Type) {}
             }
         }
     }
-
     if let Some(m) = param_marker {
         m.abandon(p);
     }
-
     p.expect(ket);
     list_marker.complete(p, PARAM_LIST);
 }
 
 const PARAM_FIRST: TokenSet = patterns::PATTERN_FIRST.union(types::TYPE_FIRST);
 
-fn param(p: &mut Parser<'_>, m: Marker, flavor: Flavor) {
+fn param(
+    p: &mut Parser<'_>,
+    m: Marker,
+    flavor: Flavor,
+) {
     match flavor {
         // test param_list_vararg
         // extern "C" { fn printf(format: *const i8, ..., _: u8) -> i32; }
     }
 }
 
-// test self_param
-// impl S {
-//     fn a(self) {}
-//     fn b(&self,) {}
-//     fn c(&'a self,) {}
-//     fn d(&'a mut self, x: i32) {}
-//     fn e(mut self) {}
-// }
-fn opt_self_param(p: &mut Parser<'_>, m: Marker) -> Result<(), Marker> {
+fn opt_self_param(
+    p: &mut Parser<'_>,
+    m: Marker,
+) -> Result<(), Marker> {
     if p.at(T![self]) || p.at(T![mut]) && p.nth(1) == T![self] {
         p.eat(T![mut]);
         self_as_name(p);
     m.complete(p, NAME);
 }
 
-use super::*;
-
 pub(super) const ATTRIBUTE_FIRST: TokenSet = TokenSet::new(&[T![#]]);
 
 pub(super) fn inner_attrs(p: &mut Parser<'_>) {
     }
 }
 
-fn attr(p: &mut Parser<'_>, inner: bool) {
+fn attr(
+    p: &mut Parser<'_>,
+    inner: bool,
+) {
     assert!(p.at(T![#]));
-
     let attr = p.start();
     p.bump(T![#]);
-
     if inner {
         p.bump(T![!]);
     }
-
     if p.eat(T!['[']) {
         meta(p);
 
     attr.complete(p, ATTR);
 }
 
-// test_err meta_recovery
-// #![]
-// #![p = ]
-// #![p::]
-// #![p:: =]
-// #![unsafe]
-// #![unsafe =]
-
-// test metas
-// #![simple_ident]
-// #![simple::path]
-// #![simple_ident_expr = ""]
-// #![simple::path::Expr = ""]
-// #![simple_ident_tt(a b c)]
-// #![simple_ident_tt[a b c]]
-// #![simple_ident_tt{a b c}]
-// #![simple::path::tt(a b c)]
-// #![simple::path::tt[a b c]]
-// #![simple::path::tt{a b c}]
-// #![unsafe(simple_ident)]
-// #![unsafe(simple::path)]
-// #![unsafe(simple_ident_expr = "")]
-// #![unsafe(simple::path::Expr = "")]
-// #![unsafe(simple_ident_tt(a b c))]
-// #![unsafe(simple_ident_tt[a b c])]
-// #![unsafe(simple_ident_tt{a b c})]
-// #![unsafe(simple::path::tt(a b c))]
-// #![unsafe(simple::path::tt[a b c])]
-// #![unsafe(simple::path::tt{a b c})]
 pub(super) fn meta(p: &mut Parser<'_>) {
     let meta = p.start();
     let is_unsafe = p.eat(T![unsafe]);
         p.expect(T!['(']);
     }
     paths::attr_path(p);
-
     match p.current() {
         T![=] => {
             p.bump(T![=]);
     if is_unsafe {
         p.expect(T![')']);
     }
-
     meta.complete(p, META);
 }
 
-mod atom;
-
-use crate::grammar::attributes::ATTRIBUTE_FIRST;
-
-use super::*;
-
-pub(super) use atom::{EXPR_RECOVERY_SET, LITERAL_FIRST, literal, parse_asm_expr};
-pub(crate) use atom::{block_expr, match_arm_list};
-
 #[derive(PartialEq, Eq)]
 pub(super) enum Semicolon {
     Required,
     expr_bp(p, None, r, 5);
 }
 
-pub(super) fn stmt(p: &mut Parser<'_>, semicolon: Semicolon) {
+pub(super) fn stmt(
+    p: &mut Parser<'_>,
+    semicolon: Semicolon,
+) {
     if p.eat(T![;]) {
         return;
     }
-
     let m = p.start();
     // test attr_on_expr_stmt
     // fn foo() {
     //     #[D] return ();
     // }
     attributes::outer_attrs(p);
-
     if p.at(T![let]) || (p.at(T![super]) && p.nth_at(1, T![let])) {
         let_stmt(p, semicolon);
         m.complete(p, LET_STMT);
         return;
     }
-
     // test block_items
     // fn a() { fn b() {} }
     let m = match items::opt_item(p, m, false) {
         Ok(()) => return,
         Err(m) => m,
     };
-
     if !p.at_ts(EXPR_FIRST) {
         p.err_and_bump("expected expression, item or let statement");
         m.abandon(p);
         return;
     }
-
     if let Some((cm, blocklike)) = expr_stmt(p, Some(m))
         && !(p.at(T!['}']) || (semicolon != Semicolon::Required && p.at(EOF)))
     {
     }
 }
 
-// test let_stmt
-// fn f() { let x: i32 = 92; super let y; super::foo; }
-pub(super) fn let_stmt(p: &mut Parser<'_>, with_semi: Semicolon) {
+pub(super) fn let_stmt(
+    p: &mut Parser<'_>,
+    with_semi: Semicolon,
+) {
     p.eat(T![super]);
     p.bump(T![let]);
     patterns::pattern(p);
         // fn f() { let x: i32; }
         types::ascription(p);
     }
-
     let mut expr_after_eq: Option<CompletedMarker> = None;
     if p.eat(T![=]) {
         // test let_stmt_init
         // fn f() { let x = 92; }
         expr_after_eq = expressions::expr(p);
     }
-
     if p.at(T![else]) {
         // test_err let_else_right_curly_brace
         // fn func() { let Some(_) = {Some(1)} else { panic!("h") };}
         block_expr(p);
         m.complete(p, LET_ELSE);
     }
-
     match with_semi {
         Semicolon::Forbidden => (),
         Semicolon::Optional => {
 
 pub(super) fn expr_block_contents(p: &mut Parser<'_>) {
     attributes::inner_attrs(p);
-
     while !p.at(EOF) && !p.at(T!['}']) {
         // test nocontentexpr
         // fn foo(){
     }
 }
 
-// Parses expression with binding power of at least bp.
 fn expr_bp(
     p: &mut Parser<'_>,
     m: Option<Marker>,
         attributes::outer_attrs(p);
         m
     });
-
     if !p.at_ts(EXPR_FIRST) {
         p.err_recover("expected expression", atom::EXPR_RECOVERY_SET);
         m.abandon(p);
             return None;
         }
     };
-
     loop {
         let is_range = p.at(T![..]) || p.at(T![..=]);
         let (op_bp, op, associativity) = current_op(p);
     Some((lhs, BlockLike::NotBlock))
 }
 
-const LHS_FIRST: TokenSet =
-    atom::ATOM_EXPR_FIRST.union(TokenSet::new(&[T![&], T![*], T![!], T![.], T![-], T![_]]));
+const LHS_FIRST: TokenSet = atom::ATOM_EXPR_FIRST.union(TokenSet::new(&[T![&], T![*], T![!], T![.], T![-], T![_]]));
 
-fn lhs(p: &mut Parser<'_>, r: Restrictions) -> Option<(CompletedMarker, BlockLike)> {
+fn lhs(
+    p: &mut Parser<'_>,
+    r: Restrictions,
+) -> Option<(CompletedMarker, BlockLike)> {
     let m;
     let kind = match p.current() {
         // test ref_expr
 fn postfix_expr(
     p: &mut Parser<'_>,
     mut lhs: CompletedMarker,
-    // Calls are disallowed if the type is a block and we prefer statements because the call cannot be disambiguated from a tuple
-    // E.g. `while true {break}();` is parsed as
-    // `while true {break}; ();`
     mut block_like: BlockLike,
     mut allow_calls: bool,
 ) -> (CompletedMarker, BlockLike) {
     }
     let nth1 = if FLOAT_RECOVERY { 0 } else { 1 };
     let nth2 = if FLOAT_RECOVERY { 1 } else { 2 };
-
     if PATH_NAME_REF_KINDS.contains(p.nth(nth1))
         && (p.nth(nth2) == T!['('] || p.nth_at(nth2, T![::]))
         || p.nth(nth1) == T!['(']
     {
         return Ok(method_call_expr::<FLOAT_RECOVERY>(p, lhs));
     }
-
     // test await_expr
     // fn foo() {
     //     x.await;
         p.bump(T![await]);
         return Ok(m.complete(p, AWAIT_EXPR));
     }
-
     if p.at(T![..=]) || p.at(T![..]) {
         return Err(lhs);
     }
-
     field_expr::<FLOAT_RECOVERY>(p, lhs)
 }
 
-// test call_expr
-// fn foo() {
-//     let _ = f();
-//     let _ = f()(1)(1, 2,);
-//     let _ = f(<Foo>::func());
-//     f(<Foo as Trait>::func());
-// }
-fn call_expr(p: &mut Parser<'_>, lhs: CompletedMarker) -> CompletedMarker {
+fn call_expr(
+    p: &mut Parser<'_>,
+    lhs: CompletedMarker,
+) -> CompletedMarker {
     assert!(p.at(T!['(']));
     let m = lhs.precede(p);
     arg_list(p);
     m.complete(p, CALL_EXPR)
 }
 
-// test index_expr
-// fn foo() {
-//     x[1][2];
-// }
-fn index_expr(p: &mut Parser<'_>, lhs: CompletedMarker) -> CompletedMarker {
+fn index_expr(
+    p: &mut Parser<'_>,
+    lhs: CompletedMarker,
+) -> CompletedMarker {
     assert!(p.at(T!['[']));
     let m = lhs.precede(p);
     p.bump(T!['[']);
     m.complete(p, INDEX_EXPR)
 }
 
-// test method_call_expr
-// fn foo() {
-//     x.foo();
-//     y.bar::<T>(1, 2,);
-//     x.0.0.call();
-//     x.0. call();
-//     x.0()
-// }
 fn method_call_expr<const FLOAT_RECOVERY: bool>(
     p: &mut Parser<'_>,
     lhs: CompletedMarker,
     m.complete(p, METHOD_CALL_EXPR)
 }
 
-// test field_expr
-// fn foo() {
-//     x.self;
-//     x.Self;
-//     x.foo;
-//     x.0.bar;
-//     x.0.1;
-//     x.0. bar;
-//     x.0();
-// }
 fn field_expr<const FLOAT_RECOVERY: bool>(
     p: &mut Parser<'_>,
     lhs: CompletedMarker,
     Ok(m.complete(p, FIELD_EXPR))
 }
 
-// test try_expr
-// fn foo() {
-//     x?;
-// }
-fn try_expr(p: &mut Parser<'_>, lhs: CompletedMarker) -> CompletedMarker {
+fn try_expr(
+    p: &mut Parser<'_>,
+    lhs: CompletedMarker,
+) -> CompletedMarker {
     assert!(p.at(T![?]));
     let m = lhs.precede(p);
     p.bump(T![?]);
     m.complete(p, TRY_EXPR)
 }
 
-// test cast_expr
-// fn foo() {
-//     82 as i32;
-//     81 as i8 + 1;
-//     79 as i16 - 1;
-//     0x36 as u8 <= 0x37;
-// }
-fn cast_expr(p: &mut Parser<'_>, lhs: CompletedMarker) -> CompletedMarker {
+fn cast_expr(
+    p: &mut Parser<'_>,
+    lhs: CompletedMarker,
+) -> CompletedMarker {
     assert!(p.at(T![as]));
     let m = lhs.precede(p);
     p.bump(T![as]);
     m.complete(p, CAST_EXPR)
 }
 
-// test_err arg_list_recovery
-// fn main() {
-//     foo(bar::);
-//     foo(bar:);
-//     foo(bar+);
-//     foo(a, , b);
-// }
 fn arg_list(p: &mut Parser<'_>) {
     assert!(p.at(T!['(']));
     let m = p.start();
     m.complete(p, ARG_LIST);
 }
 
-// test path_expr
-// fn foo() {
-//     let _ = a;
-//     let _ = a::b;
-//     let _ = ::a::<b>;
-//     let _ = format!();
-// }
-fn path_expr(p: &mut Parser<'_>, r: Restrictions) -> (CompletedMarker, BlockLike) {
+fn path_expr(
+    p: &mut Parser<'_>,
+    r: Restrictions,
+) -> (CompletedMarker, BlockLike) {
     assert!(paths::is_path_start(p));
     let m = p.start();
     paths::expr_path(p);
     }
 }
 
-// test record_lit
-// fn foo() {
-//     S {};
-//     S { x };
-//     S { x, y: 32, };
-//     S { x, y: 32, ..Default::default() };
-//     S { x, y: 32, .. };
-//     S { .. };
-//     S { x: ::default() };
-//     TupleStruct { 0: 1 };
-// }
 pub(crate) fn record_expr_field_list(p: &mut Parser<'_>) {
     assert!(p.at(T!['{']));
     let m = p.start();
     m.complete(p, RECORD_EXPR_FIELD_LIST);
 }
 
-use super::*;
-
-// test_err generic_arg_list_recover_expr
-// const _: () = T::<0, ,T>;
-// const _: () = T::<0, ,T>();
 pub(super) fn opt_generic_arg_list_expr(p: &mut Parser<'_>) {
     let m;
     if p.at(T![::]) && p.nth(2) == T![<] {
     } else {
         return;
     }
-
     delimited(
         p,
         T![<],
 ])
 .union(types::TYPE_FIRST);
 
-// Despite its name, it can also be used for generic param list.
 const GENERIC_ARG_RECOVERY_SET: TokenSet = TokenSet::new(&[T![>], T![,]]);
 
-// test generic_arg
-// type T = S<i32, dyn T, fn()>;
 pub(crate) fn generic_arg(p: &mut Parser<'_>) -> bool {
     match p.current() {
         LIFETIME_IDENT if !p.nth_at(1, T![+]) => lifetime_arg(p),
     true
 }
 
-// test lifetime_arg
-// type T = S<'static>;
 fn lifetime_arg(p: &mut Parser<'_>) {
     let m = p.start();
     lifetime(p);
     }
 }
 
-// test const_arg
-// type T = S<92>;
 pub(super) fn const_arg(p: &mut Parser<'_>) {
     let m = p.start();
     const_arg_expr(p);
     m.complete(p, TYPE_ARG);
 }
 
-use crate::grammar::attributes::ATTRIBUTE_FIRST;
-
-use super::*;
-
 pub(super) fn opt_generic_param_list(p: &mut Parser<'_>) {
     if p.at(T![<]) {
         generic_param_list(p);
     }
 }
 
-// test generic_param_list
-// fn f<T: Clone>() {}
-
-// test_err generic_param_list_recover
-// fn f<T: Clone,, U:, V>() {}
 pub(super) fn generic_param_list(p: &mut Parser<'_>) {
     assert!(p.at(T![<]));
     let m = p.start();
             generic_param(p, m)
         },
     );
-
     m.complete(p, GENERIC_PARAM_LIST);
 }
 
 const GENERIC_PARAM_FIRST: TokenSet = TokenSet::new(&[IDENT, LIFETIME_IDENT, T![const]]);
 
-fn generic_param(p: &mut Parser<'_>, m: Marker) -> bool {
+fn generic_param(
+    p: &mut Parser<'_>,
+    m: Marker,
+) -> bool {
     match p.current() {
         LIFETIME_IDENT => lifetime_param(p, m),
         IDENT => type_param(p, m),
     true
 }
 
-// test lifetime_param
-// fn f<'a: 'b>() {}
-fn lifetime_param(p: &mut Parser<'_>, m: Marker) {
+fn lifetime_param(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     assert!(p.at(LIFETIME_IDENT));
     lifetime(p);
     if p.eat(T![:]) {
     m.complete(p, LIFETIME_PARAM);
 }
 
-// test type_param
-// fn f<T: Clone>() {}
-fn type_param(p: &mut Parser<'_>, m: Marker) {
+fn type_param(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     assert!(p.at(IDENT));
     name(p);
     if p.at(T![:]) {
     m.complete(p, TYPE_PARAM);
 }
 
-// test const_param
-// struct S<const N: u32>;
-fn const_param(p: &mut Parser<'_>, m: Marker) {
+fn const_param(
+    p: &mut Parser<'_>,
+    m: Marker,
+) {
     p.bump(T![const]);
     name(p);
     if p.at(T![:]) {
     } else {
         p.error("missing type for const parameter");
     }
-
     if p.eat(T![=]) {
         // test const_param_default_literal
         // struct A<const N: i32 = -1>;
         // struct A<const N: i32 = i32::MAX>;
         generic_args::const_arg(p);
     }
-
     m.complete(p, CONST_PARAM);
 }
 
     marker.complete(p, TYPE_BOUND_LIST);
 }
 
-// test type_param_bounds
-// struct S<T: 'a + ?Sized + (Copy) + [const] Drop>;
 pub(super) fn bounds(p: &mut Parser<'_>) {
     p.expect(T![:]);
     bounds_without_colon(p);
     bounds_without_colon_m(p, m);
 }
 
-pub(super) fn bounds_without_colon_m(p: &mut Parser<'_>, marker: Marker) -> CompletedMarker {
+pub(super) fn bounds_without_colon_m(
+    p: &mut Parser<'_>,
+    marker: Marker,
+) -> CompletedMarker {
     while type_bound(p) {
         if !p.eat(T![+]) {
             break;
         p.expect(T![')']);
     }
     m.complete(p, TYPE_BOUND);
-
     true
 }
 
     // test question_for_type_trait_bound
     // fn f<T>() where T: for<> ?Sized {}
     p.eat(T![?]);
-
     // test_err invalid_question_for_type_trait_bound
     // fn f<T>() where T: ?for<> Sized {}
-
     if paths::is_use_path_start(p) {
         types::path_type_bounds(p, false);
         // test_err type_bounds_macro_call_recovery
     }
 }
 
-// test where_clause
-// fn foo()
-// where
-//    'a: 'b + 'c,
-//    T: Clone + Copy + 'static,
-//    Iterator::Item: 'a,
-//    <T as Iterator>::Item: 'a
-// {}
 pub(super) fn opt_where_clause(p: &mut Parser<'_>) {
     if !p.at(T![where]) {
         return;
     }
     let m = p.start();
     p.bump(T![where]);
-
     while is_where_predicate(p) {
         where_predicate(p);
 
             p.error("expected comma");
         }
     }
-
     m.complete(p, WHERE_CLAUSE);
-
     fn is_where_predicate(p: &mut Parser<'_>) -> bool {
         match p.current() {
             LIFETIME_IDENT => true,
     m.complete(p, WHERE_PRED);
 }
 
-use super::*;
-
 pub(super) const TYPE_FIRST: TokenSet = paths::PATH_FIRST.union(TokenSet::new(&[
     T!['('],
     T!['['],
     type_with_bounds_cond(p, false);
 }
 
-fn type_with_bounds_cond(p: &mut Parser<'_>, allow_bounds: bool) {
+fn type_with_bounds_cond(
+    p: &mut Parser<'_>,
+    allow_bounds: bool,
+) {
     match p.current() {
         T!['('] => paren_or_tuple_type(p),
         T![!] => never_type(p),
         T![for],
         T!['('],
     ]);
-
     p.at_contextual_kw(T![dyn]) && {
         let la = p.nth(1);
         WEAK_DYN_PATH_FIRST.contains(la) && (la != T![:] || la != T![<])
         }
     }
     p.expect(T![')']);
-
     let kind = if n_types == 1 && !trailing_comma {
         // test paren_type
         // type T = (i32);
     m.complete(p, kind);
 }
 
-// test never_type
-// type Never = !;
 fn never_type(p: &mut Parser<'_>) {
     assert!(p.at(T![!]));
     let m = p.start();
     assert!(p.at(T![*]));
     let m = p.start();
     p.bump(T![*]);
-
     match p.current() {
         // test pointer_type_mut
         // type M = *mut ();
             );
         }
     };
-
     type_no_bounds(p);
     m.complete(p, PTR_TYPE);
 }
     assert!(p.at(T!['[']));
     let m = p.start();
     p.bump(T!['[']);
-
     type_(p);
     let kind = match p.current() {
         // test slice_type
     m.complete(p, kind);
 }
 
-// test reference_type
-// type A = &();
-// type B = &'static ();
-// type C = &mut ();
 fn ref_type(p: &mut Parser<'_>) {
     assert!(p.at(T![&]));
     let m = p.start();
     m.complete(p, REF_TYPE);
 }
 
-// test placeholder_type
-// type Placeholder = _;
 fn infer_type(p: &mut Parser<'_>) {
     assert!(p.at(T![_]));
     let m = p.start();
     m.complete(p, INFER_TYPE);
 }
 
-// test fn_pointer_type
-// type A = fn();
-// type B = unsafe fn();
-// type C = unsafe extern "C" fn();
-// type D = extern "C" fn ( u8 , ... ) -> u8;
 fn fn_ptr_type(p: &mut Parser<'_>) {
     let m = p.start();
     p.eat(T![unsafe]);
     m.complete(p, FOR_BINDER);
 }
 
-// test for_type
-// type A = for<'a> fn() -> ();
-// type B = for<'a> unsafe extern "C" fn(&'a ()) -> ();
-// type Obj = for<'a> PartialEq<&'a i32>;
-pub(super) fn for_type(p: &mut Parser<'_>, allow_bounds: bool) {
+pub(super) fn for_type(
+    p: &mut Parser<'_>,
+    allow_bounds: bool,
+) {
     assert!(p.at(T![for]));
     let m = p.start();
     for_binder(p);
     }
     type_no_bounds(p);
     let completed = m.complete(p, FOR_TYPE);
-
     // test no_dyn_trait_leading_for
     // type A = for<'a> Test<'a> + Send;
     if allow_bounds {
     }
 }
 
-// test impl_trait_type
-// type A = impl Iterator<Item=Foo<'a>> + 'a;
 fn impl_trait_type(p: &mut Parser<'_>) {
     assert!(p.at(T![impl]));
     let m = p.start();
     m.complete(p, IMPL_TRAIT_TYPE);
 }
 
-// test dyn_trait_type
-// type A = dyn Iterator<Item=Foo<'a>> + 'a;
 fn dyn_trait_type(p: &mut Parser<'_>) {
     assert!(p.at(T![dyn]));
     let m = p.start();
     m.complete(p, DYN_TRAIT_TYPE);
 }
 
-// test dyn_trait_type_weak 2015
-// type DynPlain = dyn Path;
-// type DynRef = &dyn Path;
-// type DynLt = dyn 'a + Path;
-// type DynQuestion = dyn ?Path;
-// type DynFor = dyn for<'a> Path;
-// type DynParen = dyn(Path);
-// type Path = dyn::Path;
-// type Generic = dyn<Path>;
 fn dyn_trait_type_weak(p: &mut Parser<'_>) {
     assert!(p.at_contextual_kw(T![dyn]));
     let m = p.start();
     m.complete(p, DYN_TRAIT_TYPE);
 }
 
-// test bare_dyn_types_with_leading_lifetime
-// type A = 'static + Trait;
-// type B = S<'static + Trait>;
 fn bare_dyn_trait_type(p: &mut Parser<'_>) {
     let m = p.start();
     generic_params::bounds_without_colon(p);
     m.complete(p, DYN_TRAIT_TYPE);
 }
 
-// test macro_call_type
-// type A = foo!();
-// type B = crate::foo!();
-fn path_or_macro_type(p: &mut Parser<'_>, allow_bounds: bool) {
+fn path_or_macro_type(
+    p: &mut Parser<'_>,
+    allow_bounds: bool,
+) {
     assert!(paths::is_path_start(p));
     let r = p.start();
     let m = p.start();
-
     paths::type_path(p);
-
     let kind = if p.at(T![!]) && !p.at(T![!=]) {
         items::macro_call_after_excl(p);
         m.complete(p, MACRO_CALL);
         m.abandon(p);
         PATH_TYPE
     };
-
     let path = r.complete(p, kind);
-
     if allow_bounds {
         opt_type_bounds_as_dyn_trait_type(p, path);
     }
 }
 
-// test path_type
-// type A = Foo;
-// type B = ::Foo;
-// type C = self::Foo;
-// type D = super::Foo;
-pub(super) fn path_type_bounds(p: &mut Parser<'_>, allow_bounds: bool) {
+pub(super) fn path_type_bounds(
+    p: &mut Parser<'_>,
+    allow_bounds: bool,
+) {
     assert!(paths::is_path_start(p));
     let m = p.start();
     paths::type_path(p);
-
     // test path_type_with_bounds
     // fn foo() -> Box<T + 'f> {}
     // fn foo() -> Box<dyn T + 'f> {}
     if !p.at(T![+]) {
         return type_marker;
     }
-
     // First create a TYPE_BOUND from the completed PATH_TYPE
     let m = type_marker.precede(p).complete(p, TYPE_BOUND);
-
     // Next setup a marker for the TYPE_BOUND_LIST
     let m = m.precede(p);
-
     // This gets consumed here so it gets properly set
     // in the TYPE_BOUND_LIST
     p.eat(T![+]);
-
     // Parse rest of the bounds into the TYPE_BOUND_LIST
     let m = generic_params::bounds_without_colon_m(p, m);
-
     // Finally precede everything with DYN_TRAIT_TYPE
     m.precede(p).complete(p, DYN_TRAIT_TYPE)
 }
 
-use super::*;
-
-pub(super) const PATTERN_FIRST: TokenSet =
-    expressions::LITERAL_FIRST.union(paths::PATH_FIRST).union(TokenSet::new(&[
+pub(super) const PATTERN_FIRST: TokenSet = expressions::LITERAL_FIRST.union(paths::PATH_FIRST).union(TokenSet::new(&[
         T![box],
         T![ref],
         T![mut],
 const PAT_TOP_FIRST: TokenSet = PATTERN_FIRST.union(TokenSet::new(&[T![|]]));
 
 /// Set of possible tokens at the start of a range pattern's end bound.
-const RANGE_PAT_END_FIRST: TokenSet =
-    expressions::LITERAL_FIRST.union(paths::PATH_FIRST).union(TokenSet::new(&[T![-], T![const]]));
+const RANGE_PAT_END_FIRST: TokenSet = expressions::LITERAL_FIRST.union(paths::PATH_FIRST).union(TokenSet::new(&[T![-], T![const]]));
 
 /// Parses a pattern list separated by pipes `|`.
 pub(crate) fn pattern(p: &mut Parser<'_>) {
 
 /// Parses a pattern list separated by pipes `|`
 /// using the given `recovery_set`.
-pub(super) fn pattern_top_r(p: &mut Parser<'_>, recovery_set: TokenSet) {
+pub(super) fn pattern_top_r(
+    p: &mut Parser<'_>,
+    recovery_set: TokenSet,
+) {
     pattern_r(p, recovery_set);
 }
 
-// test or_pattern
-// fn main() {
-//     match () {
-//         (_ | _) => (),
-//         &(_ | _) => (),
-//         (_ | _,) => (),
-//         [_ | _,] => (),
-//     }
-// }
 /// Parses a pattern list separated by pipes `|`, with no leading `|`,using the
 /// given `recovery_set`.
-fn pattern_r(p: &mut Parser<'_>, recovery_set: TokenSet) {
+fn pattern_r(
+    p: &mut Parser<'_>,
+    recovery_set: TokenSet,
+) {
     let m = p.start();
     let has_leading_pipe = p.eat(T![|]);
-
     pattern_single_r(p, recovery_set);
-
     if !p.at(T![|]) && !has_leading_pipe {
         m.abandon(p);
         return;
     m.complete(p, OR_PAT);
 }
 
-fn pattern_single_r(p: &mut Parser<'_>, recovery_set: TokenSet) {
+fn pattern_single_r(
+    p: &mut Parser<'_>,
+    recovery_set: TokenSet,
+) {
     // test range_pat
     // fn main() {
     //     match 92 {
     //         (..=2, _) => (),
     //     }
     // }
-
     if p.at(T![..=]) {
         let m = p.start();
         p.bump(T![..=]);
         m.complete(p, RANGE_PAT);
         return;
     }
-
     // test exclusive_range_pat
     // fn main() {
     //     match 42 {
     //         1..2 => {}
     //     }
     // }
-
     // test dot_dot_pat
     // fn main() {
     //     let .. = ();
         }
         return;
     }
-
     if let Some(lhs) = atom_pat(p, recovery_set) {
         for range_op in [T![...], T![..=], T![..]] {
             if p.at(range_op) {
     T![&],
 ]);
 
-fn atom_pat(p: &mut Parser<'_>, recovery_set: TokenSet) -> Option<CompletedMarker> {
+fn atom_pat(
+    p: &mut Parser<'_>,
+    recovery_set: TokenSet,
+) -> Option<CompletedMarker> {
     let m = match p.current() {
         T![box] => box_pat(p),
         T![ref] | T![mut] => ident_pat(p, true),
             return None;
         }
     };
-
     Some(m)
 }
 
         || p.at_ts(expressions::LITERAL_FIRST)
 }
 
-// test literal_pattern
-// fn main() {
-//     match () {
-//         -1 => (),
-//         92 => (),
-//         'c' => (),
-//         "hello" => (),
-//     }
-// }
 fn literal_pat(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(is_literal_pat_start(p));
     let m = p.start();
     m.complete(p, LITERAL_PAT)
 }
 
-// test path_part
-// fn foo() {
-//     let foo::Bar = ();
-//     let ::Bar = ();
-//     let Bar { .. } = ();
-//     let Bar(..) = ();
-// }
 fn path_or_macro_pat(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(paths::is_path_start(p));
     let m = p.start();
     m.complete(p, kind)
 }
 
-// test tuple_pat_fields
-// fn foo() {
-//     let S() = ();
-//     let S(_) = ();
-//     let S(_,) = ();
-//     let S(_, .. , x) = ();
-//     let S(| a) = ();
-// }
 fn tuple_pat_fields(p: &mut Parser<'_>) {
     assert!(p.at(T!['(']));
     p.bump(T!['(']);
     p.expect(T![')']);
 }
 
-// test record_pat_field
-// fn foo() {
-//     let S { 0: 1 } = ();
-//     let S { x: 1 } = ();
-//     let S { #[cfg(any())] x: 1 } = ();
-// }
 fn record_pat_field(p: &mut Parser<'_>) {
     match p.current() {
         IDENT | INT_NUMBER if p.nth(1) == T![:] => {
     }
 }
 
-// test record_pat_field_list
-// fn foo() {
-//     let S {} = ();
-//     let S { f, ref mut g } = ();
-//     let S { h: _, ..} = ();
-//     let S { h: _, } = ();
-//     let S { #[cfg(any())] .. } = ();
-// }
 fn record_pat_field_list(p: &mut Parser<'_>) {
     assert!(p.at(T!['{']));
     let m = p.start();
     m.complete(p, RECORD_PAT_FIELD_LIST);
 }
 
-// test placeholder_pat
-// fn main() { let _ = (); }
 fn wildcard_pat(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T![_]));
     let m = p.start();
     m.complete(p, WILDCARD_PAT)
 }
 
-// test ref_pat
-// fn main() {
-//     let &a = ();
-//     let &mut b = ();
-// }
 fn ref_pat(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T![&]));
     let m = p.start();
     m.complete(p, REF_PAT)
 }
 
-// test tuple_pat
-// fn main() {
-//     let (a, b, ..) = ();
-//     let (a,) = ();
-//     let (..) = ();
-//     let () = ();
-//     let (| a | a, | b) = ((),());
-// }
 fn tuple_pat(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T!['(']));
     let m = p.start();
     let mut has_comma = false;
     let mut has_pat = false;
     let mut has_rest = false;
-
     // test_err tuple_pat_leading_comma
     // fn foo() {
     //     let (,);
         p.error("expected pattern");
         has_comma = true;
     }
-
     while !p.at(EOF) && !p.at(T![')']) {
         has_pat = true;
         if !p.at_ts(PAT_TOP_FIRST) {
         }
     }
     p.expect(T![')']);
-
     m.complete(p, if !has_comma && !has_rest && has_pat { PAREN_PAT } else { TUPLE_PAT })
 }
 
-// test slice_pat
-// fn main() {
-//     let [a, b, ..] = [];
-//     let [| a, ..] = [];
-// }
 fn slice_pat(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T!['[']));
     let m = p.start();
     m.complete(p, SLICE_PAT)
 }
 
-fn pat_list(p: &mut Parser<'_>, ket: SyntaxKind) {
+fn pat_list(
+    p: &mut Parser<'_>,
+    ket: SyntaxKind,
+) {
     while !p.at(EOF) && !p.at(ket) {
         pattern(p);
         if !p.eat(T![,]) {
     }
 }
 
-// test bind_pat
-// fn main() {
-//     let a = ();
-//     let mut b = ();
-//     let ref c = ();
-//     let ref mut d = ();
-//     let e @ _ = ();
-//     let ref mut f @ g @ _ = ();
-// }
-fn ident_pat(p: &mut Parser<'_>, with_at: bool) -> CompletedMarker {
+fn ident_pat(
+    p: &mut Parser<'_>,
+    with_at: bool,
+) -> CompletedMarker {
     assert!(matches!(p.current(), T![ref] | T![mut] | IDENT));
     let m = p.start();
     p.eat(T![ref]);
     m.complete(p, IDENT_PAT)
 }
 
-// test box_pat
-// fn main() {
-//     let box i = ();
-//     let box Outer { box i, j: box Inner(box &x) } = ();
-//     let box ref mut i = ();
-// }
 fn box_pat(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T![box]));
     let m = p.start();
     m.complete(p, BOX_PAT)
 }
 
-// test const_block_pat
-// fn main() {
-//     let const { 15 } = ();
-//     let const { foo(); bar() } = ();
-//
-//     match 42 {
-//         const { 0 } .. const { 1 } => (),
-//         .. const { 0 } => (),
-//         const { 2 } .. => (),
-//     }
-//
-//     let (const { () },) = ();
-// }
 fn const_block_pat(p: &mut Parser<'_>) -> CompletedMarker {
     assert!(p.at(T![const]));
     let m = p.start();
     m.complete(p, CONST_BLOCK_PAT)
 }
 
-use super::*;
-
-pub(super) const PATH_FIRST: TokenSet =
-    TokenSet::new(&[IDENT, T![self], T![super], T![crate], T![Self], T![:], T![<]]);
+pub(super) const PATH_FIRST: TokenSet = TokenSet::new(&[IDENT, T![self], T![super], T![crate], T![Self], T![:], T![<]]);
 
 pub(super) fn is_path_start(p: &Parser<'_>) -> bool {
     is_use_path_start(p) || p.at(T![<]) || p.at(T![Self])
     Vis,
 }
 
-fn path(p: &mut Parser<'_>, mode: Mode) -> Option<CompletedMarker> {
+fn path(
+    p: &mut Parser<'_>,
+    mode: Mode,
+) -> Option<CompletedMarker> {
     let path = p.start();
     if path_segment(p, mode, true).is_none() {
         path.abandon(p);
     }
 }
 
-const EXPR_PATH_SEGMENT_RECOVERY_SET: TokenSet =
-    expressions::EXPR_RECOVERY_SET.union(items::ITEM_RECOVERY_SET);
+const EXPR_PATH_SEGMENT_RECOVERY_SET: TokenSet = expressions::EXPR_RECOVERY_SET.union(items::ITEM_RECOVERY_SET);
+
 const TYPE_PATH_SEGMENT_RECOVERY_SET: TokenSet = types::TYPE_RECOVERY_SET;
 
-fn path_segment(p: &mut Parser<'_>, mode: Mode, first: bool) -> Option<CompletedMarker> {
+fn path_segment(
+    p: &mut Parser<'_>,
+    mode: Mode,
+    first: bool,
+) -> Option<CompletedMarker> {
     let m = p.start();
     // test qual_paths
     // type X = <A as B>::Output;
     }
 }
 
-fn opt_path_args(p: &mut Parser<'_>, mode: Mode) {
+fn opt_path_args(
+    p: &mut Parser<'_>,
+    mode: Mode,
+) {
     match mode {
         Mode::Use | Mode::Attr | Mode::Vis => {}
         Mode::Type => opt_path_type_args(p),
     }
 }
 
-//! A bit-set of `SyntaxKind`s.
-
-use crate::SyntaxKind;
-
 /// A bit-set of `SyntaxKind`s
 #[derive(Clone, Copy)]
 pub(crate) struct TokenSet([u64; 3]);
         TokenSet(res)
     }
 
-    pub(crate) const fn union(self, other: TokenSet) -> TokenSet {
+    pub(crate) const fn union(
+        self,
+        other: TokenSet,
+    ) -> TokenSet {
         TokenSet([self.0[0] | other.0[0], self.0[1] | other.0[1], self.0[2] | other.0[2]])
     }
 
-    pub(crate) const fn contains(&self, kind: SyntaxKind) -> bool {
+    pub(crate) const fn contains(
+        &self,
+        kind: SyntaxKind,
+    ) -> bool {
         let discriminant = kind as usize;
         debug_assert!(
             discriminant <= LAST_TOKEN_KIND_DISCRIMINANT,
     assert!(!ts.contains(PLUS));
 }
 
-//! Shortcuts that span lexer/parser abstraction.
-//!
-//! The way Rust works, parser doesn't necessary parse text, and you might
-//! tokenize text without parsing it further. So, it makes sense to keep
-//! abstract token parsing, and string tokenization as completely separate
-//! layers.
-//!
-//! However, often you do parse text into syntax trees and the glue code for
-//! that needs to live somewhere. Rather than putting it to lexer or parser, we
-//! use a separate shortcuts module for that.
-
-use std::mem;
-
-use crate::{
-    Edition, LexedStr, Step,
-    SyntaxKind::{self, *},
-};
-
 #[derive(Debug)]
 pub enum StrStep<'a> {
-    Token { kind: SyntaxKind, text: &'a str },
-    Enter { kind: SyntaxKind },
+    Token {
+        kind: SyntaxKind,
+        text: &'a str,
+    },
+    Enter {
+        kind: SyntaxKind,
+    },
     Exit,
-    Error { msg: &'a str, pos: usize },
+    Error {
+        msg: &'a str,
+        pos: usize,
+    },
 }
 
 impl LexedStr<'_> {
-    pub fn to_input(&self, edition: Edition) -> crate::Input {
+    pub fn to_input(
+        &self,
+        edition: Edition,
+    ) -> crate::Input {
         let _p = tracing::info_span!("LexedStr::to_input").entered();
         let mut res = crate::Input::with_capacity(self.len());
         let mut was_joint = false;
         sink: &mut dyn FnMut(StrStep<'_>),
     ) -> bool {
         let mut builder = Builder { lexed: self, pos: 0, state: State::PendingEnter, sink };
-
         for event in output.iter() {
             match event {
                 Step::Token { kind, n_input_tokens: n_raw_tokens } => {
                 }
             }
         }
-
         match mem::replace(&mut builder.state, State::Normal) {
             State::PendingExit => {
                 builder.eat_trivias();
             }
             State::PendingEnter | State::Normal => unreachable!(),
         }
-
         // is_eof?
         builder.pos == builder.lexed.len()
     }
 }
 
 impl Builder<'_, '_> {
-    fn token(&mut self, kind: SyntaxKind, n_tokens: u8) {
+    fn token(
+        &mut self,
+        kind: SyntaxKind,
+        n_tokens: u8,
+    ) {
         match mem::replace(&mut self.state, State::Normal) {
             State::PendingEnter => unreachable!(),
             State::PendingExit => (self.sink)(StrStep::Exit),
         self.do_token(kind, n_tokens as usize);
     }
 
-    fn float_split(&mut self, has_pseudo_dot: bool) {
+    fn float_split(
+        &mut self,
+        has_pseudo_dot: bool,
+    ) {
         match mem::replace(&mut self.state, State::Normal) {
             State::PendingEnter => unreachable!(),
             State::PendingExit => (self.sink)(StrStep::Exit),
         self.do_float_split(has_pseudo_dot);
     }
 
-    fn enter(&mut self, kind: SyntaxKind) {
+    fn enter(
+        &mut self,
+        kind: SyntaxKind,
+    ) {
         match mem::replace(&mut self.state, State::Normal) {
             State::PendingEnter => {
                 (self.sink)(StrStep::Enter { kind });
             State::PendingExit => (self.sink)(StrStep::Exit),
             State::Normal => (),
         }
-
         let n_trivias =
             (self.pos..self.lexed.len()).take_while(|&it| self.lexed.kind(it).is_trivia()).count();
         let leading_trivias = self.pos..self.pos + n_trivias;
         }
     }
 
-    fn eat_n_trivias(&mut self, n: usize) {
+    fn eat_n_trivias(
+        &mut self,
+        n: usize,
+    ) {
         for _ in 0..n {
             let kind = self.lexed.kind(self.pos);
             assert!(kind.is_trivia());
         }
     }
 
-    fn do_token(&mut self, kind: SyntaxKind, n_tokens: usize) {
+    fn do_token(
+        &mut self,
+        kind: SyntaxKind,
+        n_tokens: usize,
+    ) {
         let text = &self.lexed.range_text(self.pos..self.pos + n_tokens);
         self.pos += n_tokens;
         (self.sink)(StrStep::Token { kind, text });
     }
 
-    fn do_float_split(&mut self, has_pseudo_dot: bool) {
+    fn do_float_split(
+        &mut self,
+        has_pseudo_dot: bool,
+    ) {
         let text = &self.lexed.range_text(self.pos..self.pos + 1);
-
         match text.split_once('.') {
             Some((left, right)) => {
                 assert!(!left.is_empty());
                 self.state = if has_pseudo_dot { State::Normal } else { State::PendingExit };
             }
         }
-
         self.pos += 1;
     }
 }
 fn is_inner(text: &str) -> bool {
     text.starts_with("//!") || text.starts_with("/*!")
 }
-
-// Copied from https://github.com/rust-lang/cargo/blob/367fd9f213750cd40317803dd0a5a3ce3f0c676d/src/cargo/util/frontmatter.rs
-#![expect(dead_code)] // avoid editing
-#![expect(unreachable_pub)] // avoid editing
-#![expect(clippy::useless_format)] // avoid editing
-
+#
+#
+#
 type Span = std::ops::Range<usize>;
 
 #[derive(Debug)]
         use winnow::stream::Location as _;
         use winnow::stream::Offset as _;
         use winnow::stream::Stream as _;
-
         let content_end = raw.len();
         let mut source = Self {
             raw,
             close: None,
             content: 0..content_end,
         };
-
         let mut input = winnow::stream::LocatingSlice::new(raw);
-
         if let Some(shebang_end) = strip_shebang(input.as_ref()) {
             let shebang_start = input.current_token_start();
             let _ = input.next_slice(shebang_end);
             source.shebang = Some(shebang_start..shebang_end);
             source.content = shebang_end..content_end;
         }
-
         // Whitespace may precede a frontmatter but must end with a newline
         if let Some(nl_end) = strip_ws_lines(input.as_ref()) {
             let _ = input.next_slice(nl_end);
         }
-
         // Opens with a line that starts with 3 or more `-` followed by an optional identifier
         const FENCE_CHAR: char = '-';
         let fence_length = input
             .push_visible_span(open_start..open_end));
         };
         let info = input.next_slice(info_nl.start);
-        let info = info.strip_suffix('\r').unwrap_or(info); // already excludes `\n`
+        let info = info.strip_suffix('\r').unwrap_or(info);
+        // already excludes `\n`
         let info = info.trim_matches(is_horizontal_whitespace);
         if !info.is_empty() {
             let info_start = info.offset_from(&raw);
             let info_end = info_start + info.len();
             source.info = Some(info_start..info_end);
         }
-
         // Ends with a line that starts with a matching number of `-` only followed by whitespace
         let nl_fence_pattern = format!("\n{fence_pattern}");
         let Some(frontmatter_nl) = input.find_slice(nl_fence_pattern.as_str()) else {
             )
             .push_visible_span(open_start..open_end));
         };
-        let frontmatter_start = input.current_token_start() + 1; // skip nl from infostring
+        let frontmatter_start = input.current_token_start() + 1;
+        // skip nl from infostring
         let _ = input.next_slice(frontmatter_nl.start + 1);
         let frontmatter_end = input.current_token_start();
         source.frontmatter = Some(frontmatter_start..frontmatter_end);
         let _ = input.next_slice(fence_length);
         let close_end = input.current_token_start();
         source.close = Some(close_start..close_end);
-
         let nl = input.find_slice("\n");
         let after_closing_fence =
             input.next_slice(nl.map(|span| span.end).unwrap_or_else(|| input.eof_offset()));
                 .push_visible_span(open_start..open_end));
             }
         }
-
         source.content = content_start..content_end;
-
         if let Some(nl_end) = strip_ws_lines(input.as_ref()) {
             let _ = input.next_slice(nl_end);
         }
             .push_visible_span(open_start..open_end)
             .push_visible_span(close_start..close_end));
         }
-
         Ok(source)
     }
 
     if ws_end == 0 {
         return None;
     }
-
     let nl_start = input[0..ws_end].rfind('\n')?;
     let nl_end = nl_start + 1;
     Some(nl_end)
     //
     // Note that this set is stable (ie, it doesn't change with different
     // Unicode versions), so it's ok to just hard-code the values.
-
     matches!(
         c,
         // End-of-line characters
     //
     // Note that this set is stable (ie, it doesn't change with different
     // Unicode versions), so it's ok to just hard-code the values.
-
     matches!(
         c,
         // Horizontal space characters
 }
 
 impl FrontmatterError {
-    pub fn new(message: impl Into<String>, span: Span) -> Self {
+    pub fn new(
+        message: impl Into<String>,
+        span: Span,
+    ) -> Self {
         Self { message: message.into(), primary_span: span, visible_spans: Vec::new() }
     }
 
-    pub fn push_visible_span(mut self, span: Span) -> Self {
+    pub fn push_visible_span(
+        mut self,
+        span: Span,
+    ) -> Self {
         self.visible_spans.push(span);
         self
     }
 }
 
 impl std::fmt::Display for FrontmatterError {
-    fn fmt(&self, fmt: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
+    fn fmt(
+        &self,
+        fmt: &mut std::fmt::Formatter<'_>,
+    ) -> std::fmt::Result {
         self.message.fmt(fmt)
     }
 }
 
-impl std::error::Error for FrontmatterError {}
-
-use crate::{Edition, LexedStr, PrefixEntryPoint, Step};
+impl std::error::Error for FrontmatterError {
+}
 
 #[test]
 fn vis() {
 }
 
 #[track_caller]
-fn check(entry: PrefixEntryPoint, input: &str, prefix: &str) {
+fn check(
+    entry: PrefixEntryPoint,
+    input: &str,
+    prefix: &str,
+) {
     let lexed = LexedStr::new(Edition::CURRENT, input);
     let input = lexed.to_input(Edition::CURRENT);
-
     let mut n_tokens = 0;
     for step in entry.parse(&input, Edition::CURRENT).iter() {
         match step {
             Step::Enter { .. } | Step::Exit | Step::Error { .. } => (),
         }
     }
-
     let mut i = 0;
     loop {
         if n_tokens == 0 {
     assert_eq!(buf, prefix);
 }
 
-use expect_test::expect;
-
-use crate::TopEntryPoint;
-
 #[test]
 fn source_file() {
     check(
         SOURCE_FILE
     "#]],
     );
-
     check(
         TopEntryPoint::SourceFile,
         "struct S;",
             SEMICOLON ";"
     "#]],
     );
-
     check(
         TopEntryPoint::SourceFile,
         "@error@",
               R_PAREN ")"
         "#]],
     );
-
     check(
         TopEntryPoint::Pattern,
         "None leftover tokens",
               IDENT "tokens"
         "#]],
     );
-
     check(
         TopEntryPoint::Pattern,
         "@err",
             error 0: expected pattern
         "#]],
     );
-
     check(
         TopEntryPoint::Pattern,
         "| 42 | 43",
                   INT_NUMBER "43"
         "#]],
     );
-
     check(
         TopEntryPoint::Pattern,
         "| 42",
             error 0: expected type
         "#]],
     );
-
     check(
         TopEntryPoint::Type,
         "Option<!>",
 }
 
 #[track_caller]
-fn check(entry: TopEntryPoint, input: &str, expect: expect_test::Expect) {
+fn check(
+    entry: TopEntryPoint,
+    input: &str,
+    expect: expect_test::Expect,
+) {
     let (parsed, _errors) = super::parse(entry, input, crate::Edition::CURRENT);
     expect.assert_eq(&parsed)
 }
-
-//! Generated by `cargo xtask codegen grammar`, do not edit by hand.
-
-#![allow(bad_style, missing_docs, unreachable_pub)]
-use crate::Edition;
+#
 #[doc = r" The kind of syntax node, e.g. `IDENT`, `USE_KW`, or `STRUCT`."]
 #[derive(Debug)]
 #[repr(u16)]
     #[doc(hidden)]
     __LAST,
 }
-use self::SyntaxKind::*;
+
 impl SyntaxKind {
     #[allow(unreachable_patterns)]
     pub const fn text(self) -> &'static str {
             TRY_KW => "try",
         }
     }
+
     #[doc = r" Checks whether this syntax kind is a strict keyword for the given edition."]
     #[doc = r" Strict keywords are identifiers that are always considered keywords."]
-    pub fn is_strict_keyword(self, edition: Edition) -> bool {
+    pub fn is_strict_keyword(
+        self,
+        edition: Edition,
+    ) -> bool {
         matches!(
             self,
             SELF_TYPE_KW
             _ => false,
         }
     }
+
     #[doc = r" Checks whether this syntax kind is a weak keyword for the given edition."]
     #[doc = r" Weak keywords are identifiers that are considered keywords only in certain contexts."]
-    pub fn is_contextual_keyword(self, edition: Edition) -> bool {
+    pub fn is_contextual_keyword(
+        self,
+        edition: Edition,
+    ) -> bool {
         match self {
             ASM_KW => true,
             ATT_SYNTAX_KW => true,
             _ => false,
         }
     }
+
     #[doc = r" Checks whether this syntax kind is a strict or weak keyword for the given edition."]
-    pub fn is_keyword(self, edition: Edition) -> bool {
+    pub fn is_keyword(
+        self,
+        edition: Edition,
+    ) -> bool {
         matches!(
             self,
             SELF_TYPE_KW
             _ => false,
         }
     }
+
     pub fn is_punct(self) -> bool {
         matches!(
             self,
                 | SHREQ
         )
     }
+
     pub fn is_literal(self) -> bool {
         matches!(self, BYTE | BYTE_STRING | CHAR | C_STRING | FLOAT_NUMBER | INT_NUMBER | STRING)
     }
-    pub fn from_keyword(ident: &str, edition: Edition) -> Option<SyntaxKind> {
+
+    pub fn from_keyword(
+        ident: &str,
+        edition: Edition,
+    ) -> Option<SyntaxKind> {
         let kw = match ident {
             "Self" => SELF_TYPE_KW,
             "abstract" => ABSTRACT_KW,
         };
         Some(kw)
     }
-    pub fn from_contextual_keyword(ident: &str, edition: Edition) -> Option<SyntaxKind> {
+
+    pub fn from_contextual_keyword(
+        ident: &str,
+        edition: Edition,
+    ) -> Option<SyntaxKind> {
         let kw = match ident {
             "asm" => ASM_KW,
             "att_syntax" => ATT_SYNTAX_KW,
         };
         Some(kw)
     }
+
     pub fn from_char(c: char) -> Option<SyntaxKind> {
         let tok = match c {
             '$' => DOLLAR,
         Some(tok)
     }
 }
+
 #[macro_export]
 macro_rules ! T_ { [$] => { $ crate :: SyntaxKind :: DOLLAR } ; [;] => { $ crate :: SyntaxKind :: SEMICOLON } ; [,] => { $ crate :: SyntaxKind :: COMMA } ; ['('] => { $ crate :: SyntaxKind :: L_PAREN } ; [')'] => { $ crate :: SyntaxKind :: R_PAREN } ; ['{'] => { $ crate :: SyntaxKind :: L_CURLY } ; ['}'] => { $ crate :: SyntaxKind :: R_CURLY } ; ['['] => { $ crate :: SyntaxKind :: L_BRACK } ; [']'] => { $ crate :: SyntaxKind :: R_BRACK } ; [<] => { $ crate :: SyntaxKind :: L_ANGLE } ; [>] => { $ crate :: SyntaxKind :: R_ANGLE } ; [@] => { $ crate :: SyntaxKind :: AT } ; [#] => { $ crate :: SyntaxKind :: POUND } ; [~] => { $ crate :: SyntaxKind :: TILDE } ; [?] => { $ crate :: SyntaxKind :: QUESTION } ; [&] => { $ crate :: SyntaxKind :: AMP } ; [|] => { $ crate :: SyntaxKind :: PIPE } ; [+] => { $ crate :: SyntaxKind :: PLUS } ; [*] => { $ crate :: SyntaxKind :: STAR } ; [/] => { $ crate :: SyntaxKind :: SLASH } ; [^] => { $ crate :: SyntaxKind :: CARET } ; [%] => { $ crate :: SyntaxKind :: PERCENT } ; [_] => { $ crate :: SyntaxKind :: UNDERSCORE } ; [.] => { $ crate :: SyntaxKind :: DOT } ; [..] => { $ crate :: SyntaxKind :: DOT2 } ; [...] => { $ crate :: SyntaxKind :: DOT3 } ; [..=] => { $ crate :: SyntaxKind :: DOT2EQ } ; [:] => { $ crate :: SyntaxKind :: COLON } ; [::] => { $ crate :: SyntaxKind :: COLON2 } ; [=] => { $ crate :: SyntaxKind :: EQ } ; [==] => { $ crate :: SyntaxKind :: EQ2 } ; [=>] => { $ crate :: SyntaxKind :: FAT_ARROW } ; [!] => { $ crate :: SyntaxKind :: BANG } ; [!=] => { $ crate :: SyntaxKind :: NEQ } ; [-] => { $ crate :: SyntaxKind :: MINUS } ; [->] => { $ crate :: SyntaxKind :: THIN_ARROW } ; [<=] => { $ crate :: SyntaxKind :: LTEQ } ; [>=] => { $ crate :: SyntaxKind :: GTEQ } ; [+=] => { $ crate :: SyntaxKind :: PLUSEQ } ; [-=] => { $ crate :: SyntaxKind :: MINUSEQ } ; [|=] => { $ crate :: SyntaxKind :: PIPEEQ } ; [&=] => { $ crate :: SyntaxKind :: AMPEQ } ; [^=] => { $ crate :: SyntaxKind :: CARETEQ } ; [/=] => { $ crate :: SyntaxKind :: SLASHEQ } ; [*=] => { $ crate :: SyntaxKind :: STAREQ } ; [%=] => { $ crate :: SyntaxKind :: PERCENTEQ } ; [&&] => { $ crate :: SyntaxKind :: AMP2 } ; [||] => { $ crate :: SyntaxKind :: PIPE2 } ; [<<] => { $ crate :: SyntaxKind :: SHL } ; [>>] => { $ crate :: SyntaxKind :: SHR } ; [<<=] => { $ crate :: SyntaxKind :: SHLEQ } ; [>>=] => { $ crate :: SyntaxKind :: SHREQ } ; [Self] => { $ crate :: SyntaxKind :: SELF_TYPE_KW } ; [abstract] => { $ crate :: SyntaxKind :: ABSTRACT_KW } ; [as] => { $ crate :: SyntaxKind :: AS_KW } ; [become] => { $ crate :: SyntaxKind :: BECOME_KW } ; [box] => { $ crate :: SyntaxKind :: BOX_KW } ; [break] => { $ crate :: SyntaxKind :: BREAK_KW } ; [const] => { $ crate :: SyntaxKind :: CONST_KW } ; [continue] => { $ crate :: SyntaxKind :: CONTINUE_KW } ; [crate] => { $ crate :: SyntaxKind :: CRATE_KW } ; [do] => { $ crate :: SyntaxKind :: DO_KW } ; [else] => { $ crate :: SyntaxKind :: ELSE_KW } ; [enum] => { $ crate :: SyntaxKind :: ENUM_KW } ; [extern] => { $ crate :: SyntaxKind :: EXTERN_KW } ; [false] => { $ crate :: SyntaxKind :: FALSE_KW } ; [final] => { $ crate :: SyntaxKind :: FINAL_KW } ; [fn] => { $ crate :: SyntaxKind :: FN_KW } ; [for] => { $ crate :: SyntaxKind :: FOR_KW } ; [if] => { $ crate :: SyntaxKind :: IF_KW } ; [impl] => { $ crate :: SyntaxKind :: IMPL_KW } ; [in] => { $ crate :: SyntaxKind :: IN_KW } ; [let] => { $ crate :: SyntaxKind :: LET_KW } ; [loop] => { $ crate :: SyntaxKind :: LOOP_KW } ; [macro] => { $ crate :: SyntaxKind :: MACRO_KW } ; [match] => { $ crate :: SyntaxKind :: MATCH_KW } ; [mod] => { $ crate :: SyntaxKind :: MOD_KW } ; [move] => { $ crate :: SyntaxKind :: MOVE_KW } ; [mut] => { $ crate :: SyntaxKind :: MUT_KW } ; [override] => { $ crate :: SyntaxKind :: OVERRIDE_KW } ; [priv] => { $ crate :: SyntaxKind :: PRIV_KW } ; [pub] => { $ crate :: SyntaxKind :: PUB_KW } ; [ref] => { $ crate :: SyntaxKind :: REF_KW } ; [return] => { $ crate :: SyntaxKind :: RETURN_KW } ; [self] => { $ crate :: SyntaxKind :: SELF_KW } ; [static] => { $ crate :: SyntaxKind :: STATIC_KW } ; [struct] => { $ crate :: SyntaxKind :: STRUCT_KW } ; [super] => { $ crate :: SyntaxKind :: SUPER_KW } ; [trait] => { $ crate :: SyntaxKind :: TRAIT_KW } ; [true] => { $ crate :: SyntaxKind :: TRUE_KW } ; [type] => { $ crate :: SyntaxKind :: TYPE_KW } ; [typeof] => { $ crate :: SyntaxKind :: TYPEOF_KW } ; [unsafe] => { $ crate :: SyntaxKind :: UNSAFE_KW } ; [unsized] => { $ crate :: SyntaxKind :: UNSIZED_KW } ; [use] => { $ crate :: SyntaxKind :: USE_KW } ; [virtual] => { $ crate :: SyntaxKind :: VIRTUAL_KW } ; [where] => { $ crate :: SyntaxKind :: WHERE_KW } ; [while] => { $ crate :: SyntaxKind :: WHILE_KW } ; [yield] => { $ crate :: SyntaxKind :: YIELD_KW } ; [asm] => { $ crate :: SyntaxKind :: ASM_KW } ; [att_syntax] => { $ crate :: SyntaxKind :: ATT_SYNTAX_KW } ; [auto] => { $ crate :: SyntaxKind :: AUTO_KW } ; [builtin] => { $ crate :: SyntaxKind :: BUILTIN_KW } ; [clobber_abi] => { $ crate :: SyntaxKind :: CLOBBER_ABI_KW } ; [default] => { $ crate :: SyntaxKind :: DEFAULT_KW } ; [dyn] => { $ crate :: SyntaxKind :: DYN_KW } ; [format_args] => { $ crate :: SyntaxKind :: FORMAT_ARGS_KW } ; [global_asm] => { $ crate :: SyntaxKind :: GLOBAL_ASM_KW } ; [inlateout] => { $ crate :: SyntaxKind :: INLATEOUT_KW } ; [inout] => { $ crate :: SyntaxKind :: INOUT_KW } ; [label] => { $ crate :: SyntaxKind :: LABEL_KW } ; [lateout] => { $ crate :: SyntaxKind :: LATEOUT_KW } ; [macro_rules] => { $ crate :: SyntaxKind :: MACRO_RULES_KW } ; [may_unwind] => { $ crate :: SyntaxKind :: MAY_UNWIND_KW } ; [naked_asm] => { $ crate :: SyntaxKind :: NAKED_ASM_KW } ; [nomem] => { $ crate :: SyntaxKind :: NOMEM_KW } ; [noreturn] => { $ crate :: SyntaxKind :: NORETURN_KW } ; [nostack] => { $ crate :: SyntaxKind :: NOSTACK_KW } ; [offset_of] => { $ crate :: SyntaxKind :: OFFSET_OF_KW } ; [options] => { $ crate :: SyntaxKind :: OPTIONS_KW } ; [out] => { $ crate :: SyntaxKind :: OUT_KW } ; [preserves_flags] => { $ crate :: SyntaxKind :: PRESERVES_FLAGS_KW } ; [pure] => { $ crate :: SyntaxKind :: PURE_KW } ; [raw] => { $ crate :: SyntaxKind :: RAW_KW } ; [readonly] => { $ crate :: SyntaxKind :: READONLY_KW } ; [safe] => { $ crate :: SyntaxKind :: SAFE_KW } ; [sym] => { $ crate :: SyntaxKind :: SYM_KW } ; [union] => { $ crate :: SyntaxKind :: UNION_KW } ; [yeet] => { $ crate :: SyntaxKind :: YEET_KW } ; [async] => { $ crate :: SyntaxKind :: ASYNC_KW } ; [await] => { $ crate :: SyntaxKind :: AWAIT_KW } ; [dyn] => { $ crate :: SyntaxKind :: DYN_KW } ; [gen] => { $ crate :: SyntaxKind :: GEN_KW } ; [try] => { $ crate :: SyntaxKind :: TRY_KW } ; [lifetime_ident] => { $ crate :: SyntaxKind :: LIFETIME_IDENT } ; [int_number] => { $ crate :: SyntaxKind :: INT_NUMBER } ; [ident] => { $ crate :: SyntaxKind :: IDENT } ; [string] => { $ crate :: SyntaxKind :: STRING } ; [shebang] => { $ crate :: SyntaxKind :: SHEBANG } ; [frontmatter] => { $ crate :: SyntaxKind :: FRONTMATTER } ; }
-impl ::core::marker::Copy for SyntaxKind {}
+
+impl ::core::marker::Copy for SyntaxKind {
+}
+
 impl ::core::clone::Clone for SyntaxKind {
     #[inline]
-    fn clone(&self) -> Self { *self }
+    fn clone(&self) -> Self {
+        *self
+    }
 }
+
 impl ::core::cmp::PartialEq for SyntaxKind {
     #[inline]
-    fn eq(&self, other: &Self) -> bool { (*self as u16) == (*other as u16) }
+    fn eq(
+        &self,
+        other: &Self,
+    ) -> bool {
+        (*self as u16) == (*other as u16)
+    }
 }
-impl ::core::cmp::Eq for SyntaxKind {}
+
+impl ::core::cmp::Eq for SyntaxKind {
+}
+
 impl ::core::cmp::PartialOrd for SyntaxKind {
     #[inline]
-    fn partial_cmp(&self, other: &Self) -> core::option::Option<core::cmp::Ordering> {
+    fn partial_cmp(
+        &self,
+        other: &Self,
+    ) -> core::option::Option<core::cmp::Ordering> {
         Some(self.cmp(other))
     }
 }
+
 impl ::core::cmp::Ord for SyntaxKind {
     #[inline]
-    fn cmp(&self, other: &Self) -> core::cmp::Ordering { (*self as u16).cmp(&(*other as u16)) }
+    fn cmp(
+        &self,
+        other: &Self,
+    ) -> core::cmp::Ordering {
+        (*self as u16).cmp(&(*other as u16))
+    }
 }
+
 impl ::core::hash::Hash for SyntaxKind {
-    fn hash<H: ::core::hash::Hasher>(&self, state: &mut H) {
+    fn hash<H: ::core::hash::Hasher>(
+        &self,
+        state: &mut H,
+    ) {
         ::core::mem::discriminant(self).hash(state);
     }
 }

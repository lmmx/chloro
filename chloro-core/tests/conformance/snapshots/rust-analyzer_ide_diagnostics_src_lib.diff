COMPARISON DIFF
============================================================

Original size: 33895 bytes
Chloro size:   33005 bytes
Rustfmt size:  33895 bytes

âœ— Outputs DIFFER

--- DIFF (- rustfmt, + chloro) ---
 //! There are also a couple of ad-hoc diagnostics implemented directly here, we
 //! don't yet have a great pattern for how to do them properly.
 
+use std::{iter, sync::LazyLock};
+
+use either::Either;
+use hir::{
+    Crate, DisplayTarget, InFile, Semantics, db::ExpandDatabase, diagnostics::AnyDiagnostic,
+};
+use ide_db::{
+    EditionedFileId, FileId, FileRange, FxHashMap, FxHashSet, RootDatabase, Severity, SnippetCap,
+    assists::{Assist, AssistId, AssistResolveStrategy, ExprFillDefaultMode},
+    base_db::{ReleaseChannel, RootQueryDb as _},
+    generated::lints::{CLIPPY_LINT_GROUPS, DEFAULT_LINT_GROUPS, DEFAULT_LINTS, Lint, LintGroup},
+    imports::insert_use::InsertUseConfig,
+    label::Label,
+    source_change::SourceChange,
+    syntax_helpers::node_ext::parse_tt_as_comma_sep_paths,
+};
+use itertools::Itertools;
+use syntax::{
+    AstPtr, Edition, NodeOrToken, SmolStr, SyntaxKind, SyntaxNode, SyntaxNodePtr, T, TextRange,
+    ast::{self, AstNode, HasAttrs},
+};
+
 mod handlers {
     pub(crate) mod await_outside_of_async;
     pub(crate) mod bad_rtn;
     pub(crate) mod unresolved_method;
     pub(crate) mod unresolved_module;
     pub(crate) mod unused_variables;
-
-    // The handlers below are unusual, the implement the diagnostics as well.
     pub(crate) mod field_shorthand;
     pub(crate) mod json_is_not_rust;
     pub(crate) mod unlinked_file;
 #[cfg(test)]
 mod tests;
 
-use std::{iter, sync::LazyLock};
-
-use either::Either;
-use hir::{
-    Crate, DisplayTarget, InFile, Semantics, db::ExpandDatabase, diagnostics::AnyDiagnostic,
-};
-use ide_db::{
-    EditionedFileId, FileId, FileRange, FxHashMap, FxHashSet, RootDatabase, Severity, SnippetCap,
-    assists::{Assist, AssistId, AssistResolveStrategy, ExprFillDefaultMode},
-    base_db::{ReleaseChannel, RootQueryDb as _},
-    generated::lints::{CLIPPY_LINT_GROUPS, DEFAULT_LINT_GROUPS, DEFAULT_LINTS, Lint, LintGroup},
-    imports::insert_use::InsertUseConfig,
-    label::Label,
-    source_change::SourceChange,
-    syntax_helpers::node_ext::parse_tt_as_comma_sep_paths,
-};
-use itertools::Itertools;
-use syntax::{
-    AstPtr, Edition, NodeOrToken, SmolStr, SyntaxKind, SyntaxNode, SyntaxNodePtr, T, TextRange,
-    ast::{self, AstNode, HasAttrs},
-};
-
-// FIXME: Make this an enum
 #[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]
 pub enum DiagnosticCode {
     RustcHardError(&'static str),
     pub unused: bool,
     pub experimental: bool,
     pub fixes: Option<Vec<Assist>>,
-    // The node that will be affected by `#[allow]` and similar attributes.
     pub main_node: Option<InFile<SyntaxNodePtr>>,
 }
 
 impl Diagnostic {
-    fn new(
-        code: DiagnosticCode,
-        message: impl Into<String>,
-        range: impl Into<FileRange>,
-    ) -> Diagnostic {
+    fn new(code: DiagnosticCode, message: impl Into<String>, range: impl Into<FileRange>) -> Diagnostic {
         let message = message.into();
         Diagnostic {
             code,
         }
     }
 
-    fn new_with_syntax_node_ptr(
-        ctx: &DiagnosticsContext<'_>,
-        code: DiagnosticCode,
-        message: impl Into<String>,
-        node: InFile<SyntaxNodePtr>,
-    ) -> Diagnostic {
+    fn new_with_syntax_node_ptr(ctx: &DiagnosticsContext<'_>, code: DiagnosticCode, message: impl Into<String>, node: InFile<SyntaxNodePtr>) -> Diagnostic {
         Diagnostic::new(code, message, ctx.sema.diagnostics_display_range(node))
             .with_main_node(node)
     }
     pub disabled: FxHashSet<String>,
     pub expr_fill_default: ExprFillDefaultMode,
     pub style_lints: bool,
-    // FIXME: We may want to include a whole `AssistConfig` here
     pub snippet_cap: Option<SnippetCap>,
     pub insert_use: InsertUseConfig,
     pub prefer_no_std: bool,
     pub fn test_sample() -> Self {
         use hir::PrefixKind;
         use ide_db::imports::insert_use::ImportGranularity;
-
         Self {
             enabled: true,
             proc_macros_enabled: Default::default(),
 }
 
 impl DiagnosticsContext<'_> {
-    fn resolve_precise_location(
-        &self,
-        node: &InFile<SyntaxNodePtr>,
-        precise_location: Option<TextRange>,
-    ) -> FileRange {
+    fn resolve_precise_location(&self, node: &InFile<SyntaxNodePtr>, precise_location: Option<TextRange>) -> FileRange {
         let sema = &self.sema;
         (|| {
             let precise_location = precise_location?;
 }
 
 /// Request parser level diagnostics for the given [`FileId`].
-pub fn syntax_diagnostics(
-    db: &RootDatabase,
-    config: &DiagnosticsConfig,
-    file_id: FileId,
-) -> Vec<Diagnostic> {
+pub fn syntax_diagnostics(db: &RootDatabase, config: &DiagnosticsConfig, file_id: FileId) -> Vec<Diagnostic> {
     let _p = tracing::info_span!("syntax_diagnostics").entered();
-
     if config.disabled.contains("syntax-error") {
         return Vec::new();
     }
-
     let sema = Semantics::new(db);
     let editioned_file_id = sema
         .attach_first_edition(file_id)
         .unwrap_or_else(|| EditionedFileId::current_edition(db, file_id));
-
     let (file_id, _) = editioned_file_id.unpack(db);
-
     // [#3434] Only take first 128 errors to prevent slowing down editor/ide, the number 128 is chosen arbitrarily.
     db.parse_errors(editioned_file_id)
         .into_iter()
 
 /// Request semantic diagnostics for the given [`FileId`]. The produced diagnostics may point to other files
 /// due to macros.
-pub fn semantic_diagnostics(
-    db: &RootDatabase,
-    config: &DiagnosticsConfig,
-    resolve: &AssistResolveStrategy,
-    file_id: FileId,
-) -> Vec<Diagnostic> {
+pub fn semantic_diagnostics(db: &RootDatabase, config: &DiagnosticsConfig, resolve: &AssistResolveStrategy, file_id: FileId) -> Vec<Diagnostic> {
     let _p = tracing::info_span!("semantic_diagnostics").entered();
     let sema = Semantics::new(db);
     let editioned_file_id = sema
         .attach_first_edition(file_id)
         .unwrap_or_else(|| EditionedFileId::current_edition(db, file_id));
-
     let (file_id, edition) = editioned_file_id.unpack(db);
     let mut res = Vec::new();
-
     let parse = sema.parse(editioned_file_id);
-
     // FIXME: This iterates the entire file which is a rather expensive operation.
     // We should implement these differently in some form?
     // Salsa caching + incremental re-parse would be better here
             edition,
         );
     }
-
     let module = sema.file_to_module_def(file_id);
-
     let is_nightly = matches!(
         module.and_then(|m| db.toolchain_channel(m.krate().into())),
         Some(ReleaseChannel::Nightly) | None
     );
-
     let krate = match module {
         Some(module) => module.krate(),
         None => {
     };
     let display_target = krate.to_display_target(db);
     let ctx = DiagnosticsContext { config, sema, resolve, edition, is_nightly, display_target };
-
     let mut diags = Vec::new();
     match module {
         // A bunch of parse errors in a file indicate some bigger structural parse changes in the
             handlers::unlinked_file::unlinked_file(&ctx, &mut res, editioned_file_id.file_id(db))
         }
     }
-
     for diag in diags {
         let d = match diag {
             AnyDiagnostic::AwaitOutsideOfAsync(d) => handlers::await_outside_of_async::await_outside_of_async(&ctx, &d),
         };
         res.push(d)
     }
-
     res.retain(|d| {
         !(ctx.config.disabled.contains(d.code.as_str())
             || ctx.config.disable_experimental && d.experimental)
     });
-
     let mut lints = res
         .iter_mut()
         .filter(|it| matches!(it.code, DiagnosticCode::Clippy(_) | DiagnosticCode::RustcLint(_)))
             ))
         })
         .collect::<Vec<_>>();
-
     // The edition isn't accurate (each diagnostics may have its own edition due to macros),
     // but it's okay as it's only being used for error recovery.
     handle_lints(&ctx.sema, &mut lints, editioned_file_id.edition(db));
-
     res.retain(|d| d.severity != Severity::Allow);
-
     res.retain_mut(|diag| {
         if let Some(node) = diag
             .main_node
             true
         }
     });
-
     res
 }
 
 /// Request both syntax and semantic diagnostics for the given [`FileId`].
-pub fn full_diagnostics(
-    db: &RootDatabase,
-    config: &DiagnosticsConfig,
-    resolve: &AssistResolveStrategy,
-    file_id: FileId,
-) -> Vec<Diagnostic> {
+pub fn full_diagnostics(db: &RootDatabase, config: &DiagnosticsConfig, resolve: &AssistResolveStrategy, file_id: FileId) -> Vec<Diagnostic> {
     let mut res = syntax_diagnostics(db, config, file_id);
     let sema = semantic_diagnostics(db, config, resolve, file_id);
     res.extend(sema);
 }
 
 /// Returns whether to keep this diagnostic (or remove it).
-fn handle_diag_from_macros(
-    sema: &Semantics<'_, RootDatabase>,
-    diag: &mut Diagnostic,
-    node: &InFile<SyntaxNode>,
-) -> bool {
+fn handle_diag_from_macros(sema: &Semantics<'_, RootDatabase>, diag: &mut Diagnostic, node: &InFile<SyntaxNode>) -> bool {
     let Some(macro_file) = node.file_id.macro_file() else { return true };
     let span_map = sema.db.expansion_span_map(macro_file);
     let mut spans = span_map.spans_for_range(node.text_range());
     groups: Vec<&'static str>,
 }
 
-static RUSTC_LINTS: LazyLock<FxHashMap<&str, BuiltLint>> =
-    LazyLock::new(|| build_lints_map(DEFAULT_LINTS, DEFAULT_LINT_GROUPS, ""));
-
-static CLIPPY_LINTS: LazyLock<FxHashMap<&str, BuiltLint>> = LazyLock::new(|| {
-    build_lints_map(ide_db::generated::lints::CLIPPY_LINTS, CLIPPY_LINT_GROUPS, "clippy::")
-});
 
+{
+    build_lints_map(ide_db::generated::lints::CLIPPY_LINTS, CLIPPY_LINT_GROUPS, "clippy::");
+}
 // FIXME: Autogenerate this instead of enumerating by hand.
-static LINTS_TO_REPORT_IN_EXTERNAL_MACROS: LazyLock<FxHashSet<&str>> =
-    LazyLock::new(|| FxHashSet::from_iter([]));
 
-fn build_lints_map(
-    lints: &'static [Lint],
-    lint_group: &'static [LintGroup],
-    prefix: &'static str,
-) -> FxHashMap<&'static str, BuiltLint> {
+fn build_lints_map(lints: &'static [Lint], lint_group: &'static [LintGroup], prefix: &'static str) -> FxHashMap<&'static str, BuiltLint> {
     let mut map_with_prefixes: FxHashMap<_, _> = lints
         .iter()
         .map(|lint| (lint.label, BuiltLint { lint, groups: vec![lint.label, "__RA_EVERY_LINT"] }))
     map_with_prefixes.into_iter().map(|(k, v)| (k.strip_prefix(prefix).unwrap(), v)).collect()
 }
 
-fn handle_lints(
-    sema: &Semantics<'_, RootDatabase>,
-    diagnostics: &mut [(InFile<SyntaxNode>, &mut Diagnostic)],
-    edition: Edition,
-) {
+fn handle_lints(sema: &Semantics<'_, RootDatabase>, diagnostics: &mut [(InFile<SyntaxNode>, &mut Diagnostic)], edition: Edition) {
     for (node, diag) in diagnostics {
         let lint = match diag.code {
             DiagnosticCode::RustcLint(lint) => RUSTC_LINTS[lint].lint,
     }
 }
 
-fn find_outline_mod_lint_severity(
-    sema: &Semantics<'_, RootDatabase>,
-    node: &InFile<SyntaxNode>,
-    diag: &Diagnostic,
-    edition: Edition,
-) -> Option<Severity> {
+fn find_outline_mod_lint_severity(sema: &Semantics<'_, RootDatabase>, node: &InFile<SyntaxNode>, diag: &Diagnostic, edition: Edition) -> Option<Severity> {
     let mod_node = node.value.ancestors().find_map(ast::Module::cast)?;
     if mod_node.item_list().is_some() {
         // Inline modules will be handled by `fill_lint_attrs()`.
         return None;
     }
-
     let mod_def = sema.to_module_def(&mod_node)?;
     let module_source_file = sema.module_definition_node(mod_def);
     let mut result = None;
     result
 }
 
-fn lint_severity_at(
-    sema: &Semantics<'_, RootDatabase>,
-    node: &InFile<SyntaxNode>,
-    lint_groups: &LintGroups,
-    edition: Edition,
-) -> Option<Severity> {
+fn lint_severity_at(sema: &Semantics<'_, RootDatabase>, node: &InFile<SyntaxNode>, lint_groups: &LintGroups, edition: Edition) -> Option<Severity> {
     node.value
         .ancestors()
         .filter_map(ast::AnyHasAttrs::cast)
         })
 }
 
-fn lint_attrs<'a>(
-    sema: &'a Semantics<'a, RootDatabase>,
-    ancestor: ast::AnyHasAttrs,
-    edition: Edition,
-) -> impl Iterator<Item = (SmolStr, Severity)> + 'a {
+fn lint_attrs<'a>(sema: &'a Semantics<'a, RootDatabase>, ancestor: ast::AnyHasAttrs, edition: Edition) -> impl Iterator<Item = (SmolStr, Severity)> + 'a {
     ancestor
         .attrs_including_inner()
         .filter_map(|attr| {
         })
 }
 
-fn cfg_attr_lint_attrs(
-    sema: &Semantics<'_, RootDatabase>,
-    value: &ast::TokenTree,
-    lint_attrs: &mut Vec<(Severity, ast::TokenTree)>,
-) {
+fn cfg_attr_lint_attrs(sema: &Semantics<'_, RootDatabase>, value: &ast::TokenTree, lint_attrs: &mut Vec<(Severity, ast::TokenTree)>) {
     let prev_len = lint_attrs.len();
-
     let mut iter = value.token_trees_and_tokens().filter(|it| match it {
         NodeOrToken::Node(_) => true,
         NodeOrToken::Token(it) => !it.kind().is_trivia(),
     });
-
     // Skip the condition.
     for value in &mut iter {
         if value.as_token().is_some_and(|it| it.kind() == T![,]) {
             break;
         }
     }
-
     while let Some(value) = iter.next() {
         if let Some(token) = value.as_token()
             && token.kind() == SyntaxKind::IDENT
             }
         }
     }
-
     if prev_len != lint_attrs.len()
         && let Some(false) | None = sema.check_cfg_attr(value)
     {
     }
 }
 
-fn adjusted_display_range<N: AstNode>(
-    ctx: &DiagnosticsContext<'_>,
-    diag_ptr: InFile<AstPtr<N>>,
-    adj: &dyn Fn(N) -> Option<TextRange>,
-) -> FileRange {
+fn adjusted_display_range<N: AstNode>(ctx: &DiagnosticsContext<'_>, diag_ptr: InFile<AstPtr<N>>, adj: &dyn Fn(N) -> Option<TextRange>) -> FileRange {
     let source_file = ctx.sema.parse_or_expand(diag_ptr.file_id);
     let node = diag_ptr.value.to_node(&source_file);
     let hir::FileRange { file_id, range } = diag_ptr
COMPARISON DIFF
============================================================

Original size: 58546 bytes
Chloro size:   58434 bytes
Rustfmt size:  58546 bytes

âœ— Outputs DIFFER

--- DIFF (- rustfmt, + chloro) ---
 };
 
 impl flags::AnalysisStats {
-    pub fn run(self, verbosity: Verbosity) -> anyhow::Result<()> {
+    pub fn run(
+        self,
+        verbosity: Verbosity,
+    ) -> anyhow::Result<()> {
         let mut rng = {
             let seed = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_millis() as u64;
             Rand32::new(seed)
         };
-
         let cargo_config = CargoConfig {
             sysroot: match self.no_sysroot {
                 true => None,
             ..Default::default()
         };
         let no_progress = &|_| ();
-
         let mut db_load_sw = self.stop_watch();
-
         let path = AbsPathBuf::assert_utf8(env::current_dir()?.join(&self.path));
         let manifest = ProjectManifest::discover_single(&path)?;
-
         let mut workspace = ProjectWorkspace::load(manifest, &cargo_config, no_progress)?;
         let metadata_time = db_load_sw.elapsed();
         let load_cargo_config = LoadCargoConfig {
             },
             prefill_caches: false,
         };
-
         let build_scripts_time = if self.disable_build_scripts {
             None
         } else {
             workspace.set_build_scripts(bs);
             Some(build_scripts_sw.elapsed())
         };
-
         let (db, vfs, _proc_macro) =
             load_workspace(workspace.clone(), &cargo_config.extra_env, &load_cargo_config)?;
         eprint!("{:<20} {}", "Database loaded:", db_load_sw.elapsed());
             eprint!("; build {build_scripts_time}");
         }
         eprintln!(")");
-
         let mut host = AnalysisHost::with_database(db);
         let db = host.raw_database();
-
         let mut analysis_sw = self.stop_watch();
-
         let mut krates = Crate::all(db);
         if self.randomize {
             shuffle(&mut rng, &mut krates);
         }
-
         let mut item_tree_sw = self.stop_watch();
         let source_roots = krates
             .iter()
             .cloned()
             .map(|krate| db.file_source_root(krate.root_file(db)).source_root_id(db))
             .unique();
-
         let mut dep_loc = 0;
         let mut workspace_loc = 0;
         let mut dep_item_trees = 0;
         let mut workspace_item_trees = 0;
-
         let mut workspace_item_stats = PrettyItemStats::default();
         let mut dep_item_stats = PrettyItemStats::default();
-
         for source_root_id in source_roots {
             let source_root = db.source_root(source_root_id).source_root(db);
             for file_id in source_root.iter() {
         }
         eprintln!("  item trees: {workspace_item_trees}");
         let item_tree_time = item_tree_sw.elapsed();
-
         eprintln!(
             "  dependency lines of code: {}, item trees: {}",
             UsizeWithUnderscore(dep_loc),
             UsizeWithUnderscore(dep_item_trees),
         );
         eprintln!("  dependency item stats: {dep_item_stats}");
-
         // FIXME(salsa-transition): bring back stats for ParseQuery (file size)
         // and ParseMacroExpansionQuery (macro expansion "file") size whenever we implement
         // Salsa's memory usage tracking works with tracked functions.
-
         // let mut total_file_size = Bytes::default();
         // for e in ide_db::base_db::ParseQuery.in_db(db).entries::<Vec<_>>() {
         //     total_file_size += syntax_len(db.parse(e.key).syntax_node())
         // }
-
         // let mut total_macro_file_size = Bytes::default();
         // for e in hir::db::ParseMacroExpansionQuery.in_db(db).entries::<Vec<_>>() {
         //     let val = db.parse_macro_expansion(e.key).value.0;
         //     total_macro_file_size += syntax_len(val.syntax_node())
         // }
         // eprintln!("source files: {total_file_size}, macro files: {total_macro_file_size}");
-
         eprintln!("{:<20} {}", "Item Tree Collection:", item_tree_time);
         report_metric("item tree time", item_tree_time.time.as_millis() as u64, "ms");
         eprintln!("  Total Statistics:");
-
         let mut crate_def_map_sw = self.stop_watch();
         let mut num_crates = 0;
         let mut visited_modules = FxHashSet::default();
                 visit_queue.push(module);
             }
         }
-
         if self.randomize {
             shuffle(&mut rng, &mut visit_queue);
         }
-
         eprint!("    crates: {num_crates}");
         let mut num_decls = 0;
         let mut bodies = Vec::new();
         let mut adts = Vec::new();
         let mut file_ids = Vec::new();
-
         let mut num_traits = 0;
         let mut num_macro_rules_macros = 0;
         let mut num_proc_macros = 0;
-
         while let Some(module) = visit_queue.pop() {
             if visited_modules.insert(module) {
                 file_ids.extend(module.as_source_file_id(db));
                 .filter(|it| matches!(it, DefWithBody::Const(_) | DefWithBody::Static(_)))
                 .count(),
         );
-
         eprintln!("  Workspace:");
         eprintln!(
             "    traits: {num_traits}, macro_rules macros: {num_macro_rules_macros}, proc_macros: {num_proc_macros}"
             UsizeWithUnderscore(workspace_item_trees),
         );
         eprintln!("    usages: {workspace_item_stats}");
-
         eprintln!("  Dependencies:");
         eprintln!(
             "    lines of code: {}, item trees: {}",
             UsizeWithUnderscore(dep_item_trees),
         );
         eprintln!("    declarations: {dep_item_stats}");
-
         let crate_def_map_time = crate_def_map_sw.elapsed();
         eprintln!("{:<20} {}", "Item Collection:", crate_def_map_time);
         report_metric("crate def map time", crate_def_map_time.time.as_millis() as u64, "ms");
-
         if self.randomize {
             shuffle(&mut rng, &mut bodies);
         }
-
         hir::attach_db(db, || {
             if !self.skip_lowering {
                 self.run_body_lowering(db, &vfs, &bodies, verbosity);
                 self.run_const_eval(db, &bodies, verbosity);
             }
         });
-
         file_ids.sort();
         file_ids.dedup();
-
         if self.run_all_ide_things {
             self.run_ide_things(host.analysis(), &file_ids, db, &vfs, verbosity);
         }
-
         if self.run_term_search {
             self.run_term_search(&workspace, db, &vfs, &file_ids, verbosity);
         }
-
         hir::clear_tls_solver_cache();
-
         let db = host.raw_database_mut();
         db.trigger_lru_eviction();
-
         let total_span = analysis_sw.elapsed();
         eprintln!("{:<20} {total_span}", "Total:");
         report_metric("total time", total_span.time.as_millis() as u64, "ms");
             report_metric("total instructions", instructions, "#instr");
         }
         report_metric("total memory", total_span.memory.allocated.megabytes() as u64, "MB");
-
         if verbosity.is_verbose() {
             print_memory_usage(host, vfs);
         }
-
         Ok(())
     }
 
-    fn run_data_layout(&self, db: &RootDatabase, adts: &[hir::Adt], verbosity: Verbosity) {
+    fn run_data_layout(
+        &self,
+        db: &RootDatabase,
+        adts: &[hir::Adt],
+        verbosity: Verbosity,
+    ) {
         let mut sw = self.stop_watch();
         let mut all = 0;
         let mut fail = 0;
         report_metric("data layout time", data_layout_time.time.as_millis() as u64, "ms");
     }
 
-    fn run_const_eval(&self, db: &RootDatabase, bodies: &[DefWithBody], verbosity: Verbosity) {
+    fn run_const_eval(
+        &self,
+        db: &RootDatabase,
+        bodies: &[DefWithBody],
+        verbosity: Verbosity,
+    ) {
         let len = bodies
             .iter()
             .filter(|body| matches!(body, DefWithBody::Const(_) | DefWithBody::Static(_)))
             _ if self.parallel || self.output.is_some() => ProgressReport::hidden(),
             _ => ProgressReport::new(len),
         };
-
         let mut sw = self.stop_watch();
         let mut all = 0;
         let mut fail = 0;
             all_targets: true,
             ..Default::default()
         };
-
         let mut bar = match verbosity {
             Verbosity::Quiet | Verbosity::Spammy => ProgressReport::hidden(),
             _ if self.parallel || self.output.is_some() => ProgressReport::hidden(),
             _ => ProgressReport::new(file_ids.len()),
         };
-
         #[derive(Debug, Default)]
         struct Acc {
             tail_expr_syntax_hits: u64,
             error_codes: FxHashMap<String, u32>,
             syntax_errors: u32,
         }
-
         let mut acc: Acc = Default::default();
         bar.tick();
         let mut sw = self.stop_watch();
-
         for &file_id in file_ids {
             let file_id = file_id.editioned_file_id(db);
             let sema = hir::Semantics::new(db);
             bar.inc(1);
         }
         let term_search_time = sw.elapsed();
-
         bar.println(format!(
             "Tail Expr syntactic hits: {}/{} ({}%)",
             acc.tail_expr_syntax_hits,
         ));
         bar.println(format!("{:<20} {}", "Term search:", term_search_time));
         report_metric("term search time", term_search_time.time.as_millis() as u64, "ms");
-
         bar.finish_and_clear();
     }
 
-    fn run_mir_lowering(&self, db: &RootDatabase, bodies: &[DefWithBody], verbosity: Verbosity) {
+    fn run_mir_lowering(
+        &self,
+        db: &RootDatabase,
+        bodies: &[DefWithBody],
+        verbosity: Verbosity,
+    ) {
         let mut bar = match verbosity {
             Verbosity::Quiet | Verbosity::Spammy => ProgressReport::hidden(),
             _ if self.parallel || self.output.is_some() => ProgressReport::hidden(),
             _ if self.parallel || self.output.is_some() => ProgressReport::hidden(),
             _ => ProgressReport::new(bodies.len()),
         };
-
         if self.parallel {
             let mut inference_sw = self.stop_watch();
             bodies
                 .count();
             eprintln!("{:<20} {}", "Parallel Inference:", inference_sw.elapsed());
         }
-
         let mut inference_sw = self.stop_watch();
         bar.tick();
         let mut num_exprs = 0;
             // endregion:patterns
             bar.inc(1);
         }
-
         bar.finish_and_clear();
         let inference_time = inference_sw.elapsed();
         eprintln!(
             _ if self.output.is_some() => ProgressReport::hidden(),
             _ => ProgressReport::new(bodies.len()),
         };
-
         let mut sw = self.stop_watch();
         bar.tick();
         for &body_id in bodies {
             db.body(body_id.into());
             bar.inc(1);
         }
-
         bar.finish_and_clear();
         let body_lowering_time = sw.elapsed();
         eprintln!("{:<20} {}", "Body lowering:", body_lowering_time);
             _ if self.parallel || self.output.is_some() => ProgressReport::hidden(),
             _ => ProgressReport::new(len),
         };
-
         let mut sw = self.stop_watch();
-
         let mut bar = create_bar();
         for &file_id in file_ids {
             let msg = format!("diagnostics: {}", vfs.file_path(file_id.file_id(db)));
             bar.inc(1);
         }
         bar.finish_and_clear();
-
         let mut bar = create_bar();
         for &file_id in file_ids {
             let msg = format!("inlay hints: {}", vfs.file_path(file_id.file_id(db)));
             bar.inc(1);
         }
         bar.finish_and_clear();
-
         let mut bar = create_bar();
         let annotation_config = AnnotationConfig {
             binary_target: true,
             bar.inc(1);
         }
         bar.finish_and_clear();
-
         let ide_time = sw.elapsed();
         eprintln!("{:<20} {} ({} files)", "IDE:", ide_time, file_ids.len());
     }
 
-    fn should_process(&self, db: &RootDatabase, body_id: DefWithBody, module: hir::Module) -> bool {
+    fn should_process(
+        &self,
+        db: &RootDatabase,
+        body_id: DefWithBody,
+        module: hir::Module,
+    ) -> bool {
         if let Some(only_name) = self.only.as_deref() {
             let name = body_id.name(db).unwrap_or_else(Name::missing);
 
     }
 }
 
-fn full_name(db: &RootDatabase, body_id: DefWithBody, module: hir::Module) -> String {
+fn full_name(
+    db: &RootDatabase,
+    body_id: DefWithBody,
+    module: hir::Module,
+) -> String {
     module
         .krate()
         .display_name(db)
         .join("::")
 }
 
-fn location_csv_expr(db: &RootDatabase, vfs: &Vfs, sm: &BodySourceMap, expr_id: ExprId) -> String {
+fn location_csv_expr(
+    db: &RootDatabase,
+    vfs: &Vfs,
+    sm: &BodySourceMap,
+    expr_id: ExprId,
+) -> String {
     let src = match sm.expr_syntax(expr_id) {
         Ok(s) => s,
         Err(SyntheticSyntax) => return "synthetic,,".to_owned(),
     format!("{path},{}:{},{}:{}", start.line + 1, start.col, end.line + 1, end.col)
 }
 
-fn location_csv_pat(db: &RootDatabase, vfs: &Vfs, sm: &BodySourceMap, pat_id: PatId) -> String {
+fn location_csv_pat(
+    db: &RootDatabase,
+    vfs: &Vfs,
+    sm: &BodySourceMap,
+    pat_id: PatId,
+) -> String {
     let src = match sm.pat_syntax(pat_id) {
         Ok(s) => s,
         Err(SyntheticSyntax) => return "synthetic,,".to_owned(),
         None
     }
 }
+
 fn pat_syntax_range<'a>(
     db: &RootDatabase,
     vfs: &'a Vfs,
     }
 }
 
-fn shuffle<T>(rng: &mut Rand32, slice: &mut [T]) {
+fn shuffle<T>(
+    rng: &mut Rand32,
+    slice: &mut [T],
+) {
     for i in 0..slice.len() {
         randomize_first(rng, &mut slice[i..]);
     }
-
     fn randomize_first<T>(rng: &mut Rand32, slice: &mut [T]) {
         assert!(!slice.is_empty());
         let idx = rng.rand_range(0..slice.len() as u32) as usize;
     }
 }
 
-fn percentage(n: u64, total: u64) -> u64 {
+fn percentage(
+    n: u64,
+    total: u64,
+) -> u64 {
     (n * 100).checked_div(total).unwrap_or(100)
 }
 
 struct UsizeWithUnderscore(usize);
 
 impl fmt::Display for UsizeWithUnderscore {
-    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
+    fn fmt(
+        &self,
+        f: &mut fmt::Formatter<'_>,
+    ) -> fmt::Result {
         let num_str = self.0.to_string();
-
         if num_str.len() <= 3 {
             return write!(f, "{num_str}");
         }
-
         let mut result = String::new();
-
         for (count, ch) in num_str.chars().rev().enumerate() {
             if count > 0 && count % 3 == 0 {
                 result.push('_');
             }
             result.push(ch);
         }
-
         let result = result.chars().rev().collect::<String>();
         write!(f, "{result}")
     }
 }
 
 impl std::ops::AddAssign for UsizeWithUnderscore {
-    fn add_assign(&mut self, other: UsizeWithUnderscore) {
+    fn add_assign(
+        &mut self,
+        other: UsizeWithUnderscore,
+    ) {
         self.0 += other.0;
     }
 }
 }
 
 impl AddAssign for PrettyItemStats {
-    fn add_assign(&mut self, rhs: Self) {
+    fn add_assign(
+        &mut self,
+        rhs: Self,
+    ) {
         self.traits += rhs.traits;
         self.impls += rhs.impls;
         self.mods += rhs.mods;
 }
 
 impl fmt::Display for PrettyItemStats {
-    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
+    fn fmt(
+        &self,
+        f: &mut fmt::Formatter<'_>,
+    ) -> fmt::Result {
         write!(
             f,
             "traits: {}, impl: {}, mods: {}, macro calls: {}, macro rules: {}",
         )
     }
 }
-
-// FIXME(salsa-transition): bring this back whenever we implement
-// Salsa's memory usage tracking to work with tracked functions.
-// fn syntax_len(node: SyntaxNode) -> usize {
-//     // Macro expanded code doesn't contain whitespace, so erase *all* whitespace
-//     // to make macro and non-macro code comparable.
-//     node.to_string().replace(|it: char| it.is_ascii_whitespace(), "").len()
-// }
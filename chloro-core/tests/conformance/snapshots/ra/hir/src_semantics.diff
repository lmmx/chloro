COMPARISON DIFF
============================================================

Original size: 101650 bytes
Chloro size:   99948 bytes
Rustfmt size:  101650 bytes

âœ— Outputs DIFFER

=== DIFF (- rustfmt, + chloro) ===
 
 use either::Either;
 use hir_def::{
-    DefWithBodyId, FunctionId, MacroId, StructId, TraitId, VariantId,
-    expr_store::{Body, ExprOrPatSource, path::Path},
+    expr_store::{path::Path, Body, ExprOrPatSource},
     hir::{BindingId, Expr, ExprId, ExprOrPatId, Pat},
-    nameres::{ModuleOrigin, crate_def_map},
+    nameres::{crate_def_map, ModuleOrigin},
     resolver::{self, HasResolver, Resolver, TypeNs},
     type_ref::Mutability,
+    DefWithBodyId, FunctionId, MacroId, StructId, TraitId, VariantId,
 };
 use hir_expand::{
-    EditionedFileId, ExpandResult, FileRange, HirFileId, InMacroFile, MacroCallId,
     attrs::collect_attrs,
     builtin::{BuiltinFnLikeExpander, EagerExpander},
     db::ExpandDatabase,
     files::{FileRangeWrapper, HirFileRange, InRealFile},
     mod_path::{ModPath, PathKind},
     name::AsName,
+    EditionedFileId, ExpandResult, FileRange, HirFileId, InMacroFile, MacroCallId,
 };
 use hir_ty::{
     diagnostics::{unsafe_operations, unsafe_operations_for_body},
     next_solver::DbInterner,
 };
-use intern::{Interned, Symbol, sym};
+use intern::{sym, Interned, Symbol};
 use itertools::Itertools;
 use rustc_hash::{FxHashMap, FxHashSet};
-use smallvec::{SmallVec, smallvec};
+use smallvec::{smallvec, SmallVec};
 use span::{Edition, FileId, SyntaxContext};
-use stdx::{TupleExt, always};
+use stdx::{always, TupleExt};
 use syntax::{
-    AstNode, AstToken, Direction, SyntaxKind, SyntaxNode, SyntaxNodePtr, SyntaxToken, TextRange,
-    TextSize,
     algo::skip_trivia_token,
     ast::{self, HasAttrs as _, HasGenericParams},
+    AstNode, AstToken, Direction, SyntaxKind, SyntaxNode, SyntaxNodePtr, SyntaxToken, TextRange,
+    TextSize,
 };
 
 use crate::{
+    db::HirDatabase,
+    semantics::source_to_def::{ChildContainer, SourceToDefCache, SourceToDefCtx},
+    source_analyzer::{name_hygiene, resolve_hir_path, SourceAnalyzer},
     Adjust, Adjustment, Adt, AutoBorrow, BindingMode, BuiltinAttr, Callable, Const, ConstParam,
     Crate, DefWithBody, DeriveHelper, Enum, Field, Function, GenericSubstitution, HasSource, Impl,
     InFile, InlineAsmOperand, ItemInNs, Label, LifetimeParam, Local, Macro, Module, ModuleDef,
     Name, OverloadedDeref, ScopeDef, Static, Struct, ToolModule, Trait, TupleField, Type,
     TypeAlias, TypeParam, Union, Variant, VariantDef,
-    db::HirDatabase,
-    semantics::source_to_def::{ChildContainer, SourceToDefCache, SourceToDefCtx},
-    source_analyzer::{SourceAnalyzer, name_hygiene, resolve_hir_path},
 };
 
 const CONTINUE_NO_BREAKS: ControlFlow<Infallible, ()> = ControlFlow::Continue(());
     ) -> Self {
         PathResolutionPerNs { type_ns, value_ns, macro_ns }
     }
+
     pub fn any(&self) -> Option<PathResolution> {
         self.type_ns.or(self.value_ns).or(self.macro_ns)
     }
     }
 }
 
-// Note: while this variant of `Semantics<'_, _>` might seem unused, as it does not
-// find actual use within the rust-analyzer project itself, it exists to enable the use
-// within e.g. tracked salsa functions in third-party crates that build upon `ra_ap_hir`.
 impl Semantics<'_, dyn HirDatabase> {
     /// Creates an instance that's weakly coupled to its underlying database type.
     pub fn new_dyn(db: &'_ dyn HirDatabase) -> Semantics<'_, dyn HirDatabase> {
     }
 }
 
-// Note: We take `DB` as `?Sized` here in order to support type-erased
-// use of `Semantics` via `Semantics<'_, dyn HirDatabase>`:
 impl<DB: HirDatabase + ?Sized> Semantics<'_, DB> {
     pub fn hir_file_for(&self, syntax_node: &SyntaxNode) -> HirFileId {
         self.imp.find_file(syntax_node).file_id
 
     /// Find an AstNode by offset inside SyntaxNode, if it is inside *MacroCall*,
     /// descend it and find again
-    // FIXME: Rethink this API
     pub fn find_node_at_offset_with_descend<N: AstNode>(
         &self,
         node: &SyntaxNode,
 
     /// Find an AstNode by offset inside SyntaxNode, if it is inside an attribute macro call,
     /// descend it and find again
-    // FIXME: Rethink this API
     pub fn find_nodes_at_offset_with_descend<'slf, N: AstNode + 'slf>(
         &'slf self,
         node: &SyntaxNode,
         self.imp.descend_node_at_offset(node, offset).filter_map(|mut it| it.find_map(N::cast))
     }
 
-    // FIXME: Rethink this API
     pub fn find_namelike_at_offset_with_descend<'slf>(
         &'slf self,
         node: &SyntaxNode,
         offset: TextSize,
     ) -> impl Iterator<Item = ast::NameLike> + 'slf {
-        node.token_at_offset(offset)
-            .map(move |token| self.descend_into_macros_no_opaque(token, true))
-            .map(|descendants| descendants.into_iter().filter_map(move |it| it.value.parent()))
-            // re-order the tokens from token_at_offset by returning the ancestors with the smaller first nodes first
-            // See algo::ancestors_at_offset, which uses the same approach
-            .kmerge_by(|left, right| left.text_range().len().lt(&right.text_range().len()))
-            .filter_map(ast::NameLike::cast)
+        node.token_at_offset(offset).map(
+            move |token| self.descend_into_macros_no_opaque(token, true),
+        ).map(
+            |descendants| descendants.into_iter().filter_map(move |it| it.value.parent()),
+        ).kmerge_by(
+            |left, right| left.text_range().len().lt(&right.text_range().len()),
+        ).filter_map(
+            ast::NameLike::cast,
+        )
     }
 
     pub fn resolve_range_pat(&self, range_pat: &ast::RangePat) -> Option<Struct> {
 
     pub fn adjust_edition(&self, file_id: HirFileId) -> HirFileId {
         if let Some(editioned_file_id) = file_id.file_id() {
-            self.attach_first_edition(editioned_file_id.file_id(self.db))
-                .map_or(file_id, Into::into)
+            self.attach_first_edition(editioned_file_id.file_id(self.db)).map_or(
+                file_id,
+                Into::into,
+            )
         } else {
             file_id
         }
             resolver,
         };
         visitor.rename_conflicts(starting_expr);
-        visitor
-            .conflicts
-            .into_iter()
-            .map(|binding_id| Local { parent: to_be_renamed.parent, binding_id })
-            .collect()
+        visitor.conflicts.into_iter().map(
+            |binding_id| Local { parent: to_be_renamed.parent, binding_id },
+        ).collect(
+        )
     }
 
     /// Retrieves all the formatting parts of the format_args! (or `asm!`) template string.
     ) -> Option<Vec<(TextRange, Option<Either<PathResolution, InlineAsmOperand>>)>> {
         let string_start = string.syntax().text_range().start();
         let token = self.wrap_token_infile(string.syntax().clone());
-        self.descend_into_macros_breakable(token, |token, _| {
+        self.descend_into_macros_breakable(
+            token,
+            |token, _| {
             (|| {
                 let token = token.value;
                 let string = ast::String::cast(token)?;
                 }
             })()
             .map_or(ControlFlow::Continue(()), ControlFlow::Break)
-        })
+        },
+        )
     }
 
     /// Retrieves the formatting part of the format_args! template string at the given offset.
     ///
-    // FIXME: Type the return type
     /// Returns the range (pre-expansion) in the string literal corresponding to the resolution,
     /// absolute file range (post-expansion)
     /// of the part in the format string, the corresponding string token and the resolution if it
     /// exists.
-    // FIXME: Remove this in favor of `check_for_format_args_template_with_file`
     pub fn check_for_format_args_template(
         &self,
         original_token: SyntaxToken,
 
     /// Retrieves the formatting part of the format_args! template string at the given offset.
     ///
-    // FIXME: Type the return type
     /// Returns the range (pre-expansion) in the string literal corresponding to the resolution,
     /// absolute file range (post-expansion)
     /// of the part in the format string, the corresponding string token and the resolution if it
         if let Some(format_args) = ast::FormatArgsExpr::cast(parent.clone()) {
             let source_analyzer =
                 &self.analyze_impl(InFile::new(file_id, format_args.syntax()), None, false)?;
-            source_analyzer
-                .resolve_offset_in_format_args(self.db, InFile::new(file_id, &format_args), offset)
-                .map(|(range, res)| (range, res.map(Either::Left)))
+            source_analyzer.resolve_offset_in_format_args(
+                self.db,
+                InFile::new(file_id, &format_args),
+                offset,
+            ).map(
+                |(range, res)| (range, res.map(Either::Left)),
+            )
         } else {
             let asm = ast::AsmExpr::cast(parent)?;
             let source_analyzer =
                 self.analyze_impl(InFile::new(file_id, asm.syntax()), None, false)?;
             let line = asm.template().position(|it| *it.syntax() == literal)?;
-            source_analyzer
-                .resolve_offset_in_asm_template(InFile::new(file_id, &asm), line, offset)
-                .map(|(owner, (expr, range, index))| {
+            source_analyzer.resolve_offset_in_asm_template(InFile::new(file_id, &asm), line, offset).map(|(owner, (expr, range, index))| {
                     (range, Some(Either::Right(InlineAsmOperand { owner, expr, index })))
                 })
         }
     ///
     /// Note that if this token itself is within the context of a macro expansion does not matter.
     /// That is, we strictly check if it lies inside the input of a macro call.
-    pub fn is_inside_macro_call(&self, token @ InFile { value, .. }: InFile<&SyntaxToken>) -> bool {
+    pub fn is_inside_macro_call(
+        &self,
+        token @ InFile { value, .. }: InFile<&SyntaxToken>,
+    ) -> bool {
         value.parent_ancestors().any(|ancestor| {
             if ast::MacroCall::can_cast(ancestor.kind()) {
                 return true;
                 let matches = (kind == mapped_kind || any_ident_match()) && text == value.text();
                 if matches { ControlFlow::Break(value) } else { ControlFlow::Continue(()) }
             },
+        ).unwrap_or(
+            token,
         )
-        .unwrap_or(token)
     }
 
     fn descend_into_macros_all(
             };
 
         // A stack of tokens to process, along with the file they came from
+
         // These are tracked to know which macro calls we still have to look into
+
         // the tokens themselves aren't that interesting as the span that is being used to map
+
         // things down never changes.
         let mut stack: Vec<(_, SmallVec<[_; 2]>)> = vec![];
         let include = file_id
         let mut m_cache = self.macro_call_cache.borrow_mut();
 
         // Filters out all tokens that contain the given range (usually the macro call), any such
+
         // token is redundant as the corresponding macro call has already been processed
         let filter_duplicates = |tokens: &mut SmallVec<_>, range: TextRange| {
             tokens.retain(|(t, _): &mut (SyntaxToken, _)| !range.contains_range(t.text_range()))
         None
     }
 
-    // Note this return type is deliberate as [`find_nodes_at_offset_with_descend`] wants to stop
-    // traversing the inner iterator when it finds a node.
-    // The outer iterator is over the tokens descendants
-    // The inner iterator is the ancestors of a descendant
     fn descend_node_at_offset(
         &self,
         node: &SyntaxNode,
         offset: TextSize,
     ) -> impl Iterator<Item = impl Iterator<Item = SyntaxNode> + '_> + '_ {
-        node.token_at_offset(offset)
-            .map(move |token| self.descend_into_macros_exact(token))
-            .map(|descendants| {
+        node.token_at_offset(offset).map(move |token| self.descend_into_macros_exact(token)).map(|descendants| {
                 descendants.into_iter().map(move |it| self.token_ancestors_with_macros(it))
-            })
-            // re-order the tokens from token_at_offset by returning the ancestors with the smaller first nodes first
-            // See algo::ancestors_at_offset, which uses the same approach
-            .kmerge_by(|left, right| {
+            }).kmerge_by(|left, right| {
                 left.clone()
                     .map(|node| node.text_range().len())
                     .lt(right.clone().map(|node| node.text_range().len()))
     /// Attempts to map the node out of macro expanded files.
     /// This only work for attribute expansions, as other ones do not have nodes as input.
     pub fn original_ast_node<N: AstNode>(&self, node: N) -> Option<N> {
-        self.wrap_node_infile(node).original_ast_node_rooted(self.db).map(
-            |InRealFile { file_id, value }| {
+        self.wrap_node_infile(node).original_ast_node_rooted(self.db).map(|InRealFile { file_id, value }| {
                 self.cache(find_root(value.syntax()), file_id.into());
                 value
-            },
-        )
+            })
     }
 
     /// Attempts to map the node out of macro expanded files.
     /// This only work for attribute expansions, as other ones do not have nodes as input.
     pub fn original_syntax_node_rooted(&self, node: &SyntaxNode) -> Option<SyntaxNode> {
         let InFile { file_id, .. } = self.find_file(node);
-        InFile::new(file_id, node).original_syntax_node_rooted(self.db).map(
-            |InRealFile { file_id, value }| {
+        InFile::new(file_id, node).original_syntax_node_rooted(self.db).map(|InRealFile { file_id, value }| {
                 self.cache(find_root(&value), file_id.into());
                 value
-            },
-        )
+            })
     }
 
     pub fn diagnostics_display_range(
     }
 
     /// Iterates the ancestors of the given node, climbing up macro expansions while doing so.
-    // FIXME: Replace with `ancestors_with_macros_file` when all usages are updated.
     pub fn ancestors_with_macros(
         &self,
         node: SyntaxNode,
         &self,
         node: InFile<SyntaxNode>,
     ) -> impl Iterator<Item = InFile<SyntaxNode>> + Clone + '_ {
-        iter::successors(Some(node), move |&InFile { file_id, ref value }| match value.parent() {
+        iter::successors(
+            Some(node),
+            move |&InFile { file_id, ref value }| match value.parent() {
             Some(parent) => Some(InFile::new(file_id, parent)),
             None => {
                 let macro_file = file_id.macro_file()?;
                     expansion_info.arg().map(|node| node?.parent()).transpose()
                 })
             }
-        })
+        },
+        )
     }
 
     pub fn ancestors_at_offset_with_macros(
         node: &SyntaxNode,
         offset: TextSize,
     ) -> impl Iterator<Item = SyntaxNode> + '_ {
-        node.token_at_offset(offset)
-            .map(|token| self.token_ancestors_with_macros(token))
-            .kmerge_by(|node1, node2| node1.text_range().len() < node2.text_range().len())
+        node.token_at_offset(offset).map(|token| self.token_ancestors_with_macros(token)).kmerge_by(
+            |node1, node2| node1.text_range().len() < node2.text_range().len(),
+        )
     }
 
     pub fn resolve_lifetime_param(&self, lifetime: &ast::Lifetime) -> Option<LifetimeParam> {
     }
 
     pub fn type_of_expr(&self, expr: &ast::Expr) -> Option<TypeInfo<'db>> {
-        self.analyze(expr.syntax())?
-            .type_of_expr(self.db, expr)
-            .map(|(ty, coerced)| TypeInfo { original: ty, adjusted: coerced })
+        self.analyze(expr.syntax())?.type_of_expr(self.db, expr).map(
+            |(ty, coerced)| TypeInfo { original: ty, adjusted: coerced },
+        )
     }
 
     pub fn type_of_pat(&self, pat: &ast::Pat) -> Option<TypeInfo<'db>> {
-        self.analyze(pat.syntax())?
-            .type_of_pat(self.db, pat)
-            .map(|(ty, coerced)| TypeInfo { original: ty, adjusted: coerced })
+        self.analyze(pat.syntax())?.type_of_pat(self.db, pat).map(
+            |(ty, coerced)| TypeInfo { original: ty, adjusted: coerced },
+        )
     }
 
     /// It also includes the changes that binding mode makes in the type. For example in
     }
 
     pub fn pattern_adjustments(&self, pat: &ast::Pat) -> SmallVec<[Type<'db>; 1]> {
-        self.analyze(pat.syntax())
-            .and_then(|it| it.pattern_adjustments(self.db, pat))
-            .unwrap_or_default()
+        self.analyze(pat.syntax()).and_then(|it| it.pattern_adjustments(self.db, pat)).unwrap_or_default(
+        )
     }
 
     pub fn binding_mode_of_pat(&self, pat: &ast::IdentPat) -> Option<BindingMode> {
     }
 
     /// Env is used to derive the trait environment
-    // FIXME: better api for the trait environment
     pub fn resolve_trait_impl_method(
         &self,
         env: Type<'db>,
         self.analyze(try_expr.syntax())?.resolve_try_expr(self.db, try_expr)
     }
 
-    // This does not resolve the method call to the correct trait impl!
-    // We should probably fix that.
     pub fn resolve_method_call_as_callable(
         &self,
         call: &ast::MethodCallExpr,
     pub fn resolve_field_fallback(
         &self,
         field: &ast::FieldExpr,
-    ) -> Option<(Either<Either<Field, TupleField>, Function>, Option<GenericSubstitution<'db>>)>
-    {
+    ) -> Option<(Either<Either<Field, TupleField>, Function>, Option<GenericSubstitution<'db>>)> {
         self.analyze(field.syntax())?.resolve_field_fallback(self.db, field)
     }
 
         &self,
         field: &ast::RecordExprField,
     ) -> Option<(Field, Option<Local>, Type<'db>)> {
-        self.resolve_record_field_with_substitution(field)
-            .map(|(field, local, ty, _)| (field, local, ty))
+        self.resolve_record_field_with_substitution(field).map(
+            |(field, local, ty, _)| (field, local, ty),
+        )
     }
 
     pub fn resolve_record_field_with_substitution(
         self.analyze(field.syntax())?.resolve_record_pat_field(self.db, field)
     }
 
-    // FIXME: Replace this with `resolve_macro_call2`
     pub fn resolve_macro_call(&self, macro_call: &ast::MacroCall) -> Option<Macro> {
         let macro_call = self.find_file(macro_call.syntax()).with_value(macro_call);
         self.resolve_macro_call2(macro_call)
     }
 
     pub fn resolve_macro_call2(&self, macro_call: InFile<&ast::MacroCall>) -> Option<Macro> {
-        self.to_def2(macro_call)
-            .and_then(|call| self.with_ctx(|ctx| macro_call_to_macro_id(ctx, call)))
-            .map(Into::into)
+        self.to_def2(macro_call).and_then(
+            |call| self.with_ctx(|ctx| macro_call_to_macro_id(ctx, call)),
+        ).map(
+            Into::into,
+        )
     }
 
     pub fn is_proc_macro_call(&self, macro_call: InFile<&ast::MacroCall>) -> bool {
-        self.resolve_macro_call2(macro_call)
-            .is_some_and(|m| matches!(m.id, MacroId::ProcMacroId(..)))
+        self.resolve_macro_call2(macro_call).is_some_and(
+            |m| matches!(m.id, MacroId::ProcMacroId(..)),
+        )
     }
 
     pub fn resolve_macro_call_arm(&self, macro_call: &ast::MacroCall) -> Option<u32> {
         &self,
         literal: &ast::RecordExpr,
     ) -> Vec<(Field, Type<'db>)> {
-        self.analyze(literal.syntax())
-            .and_then(|it| it.record_literal_missing_fields(self.db, literal))
-            .unwrap_or_default()
+        self.analyze(literal.syntax()).and_then(
+            |it| it.record_literal_missing_fields(self.db, literal),
+        ).unwrap_or_default(
+        )
     }
 
     pub fn record_pattern_missing_fields(
         &self,
         pattern: &ast::RecordPat,
     ) -> Vec<(Field, Type<'db>)> {
-        self.analyze(pattern.syntax())
-            .and_then(|it| it.record_pattern_missing_fields(self.db, pattern))
-            .unwrap_or_default()
+        self.analyze(pattern.syntax()).and_then(
+            |it| it.record_pattern_missing_fields(self.db, pattern),
+        ).unwrap_or_default(
+        )
     }
 
     fn with_ctx<F: FnOnce(&mut SourceToDefCtx<'_, '_>) -> T, T>(&self, f: F) -> T {
         node: &SyntaxNode,
         offset: TextSize,
     ) -> Option<SemanticsScope<'db>> {
-        self.analyze_with_offset_no_infer(node, offset).map(
-            |SourceAnalyzer { file_id, resolver, .. }| SemanticsScope {
+        self.analyze_with_offset_no_infer(node, offset).map(|SourceAnalyzer { file_id, resolver, .. }| SemanticsScope {
                 db: self.db,
                 file_id,
                 resolver,
-            },
-        )
+            })
     }
 
     /// Search for a definition's source and cache its syntax tree
         &self,
         node: InFile<&SyntaxNode>,
         offset: Option<TextSize>,
-        // replace this, just make the inference result a `LazyCell`
         infer_body: bool,
     ) -> Option<SourceAnalyzer<'db>> {
         let _p = tracing::info_span!("SemanticsImpl::analyze_impl").entered();
             if &parent == enclosing_node {
                 break false;
             }
-
             if let Some(parent) = ast::Expr::cast(parent.clone())
                 && let Some(ExprOrPatId::ExprId(expr_id)) =
                     source_map.node_expr(InFile { file_id, value: &parent })
             {
                 break true;
             }
-
             let Some(parent_) = parent.parent() else { break false };
             parent = parent_;
         }
     }
 }
 
-// FIXME This can't be the best way to do this
 fn macro_call_to_macro_id(
     ctx: &mut SourceToDefCtx<'_, '_>,
     macro_call_id: MacroCallId,
     }
 }
 
-pub trait ToDef: AstNode + Clone {
+pub trait ToDef {
     type Def;
+
     fn to_def(sema: &SemanticsImpl<'_>, src: InFile<&Self>) -> Option<Self::Def>;
 }
 
 
 impl RenameConflictsVisitor<'_> {
     fn resolve_path(&mut self, node: ExprOrPatId, path: &Path) {
-        if let Path::BarePath(path) = path
-            && let Some(name) = path.as_ident()
-        {
+        if let Path::BarePath(path) = path && let Some(name) = path.as_ident() {
             if *name.symbol() == self.new_name {
                 if let Some(conflicting) = self.resolver.rename_will_conflict_with_renamed(
                     self.db,
                 ) {
                     self.conflicts.insert(conflicting);
                 }
-            } else if *name.symbol() == self.old_name
-                && let Some(conflicting) = self.resolver.rename_will_conflict_with_another_variable(
-                    self.db,
-                    name,
-                    path,
-                    self.body.expr_or_pat_path_hygiene(node),
-                    &self.new_name,
-                    self.to_be_renamed,
-                )
-            {
+            } else if *name.symbol() == self.old_name && let Some(conflicting) = self.resolver.rename_will_conflict_with_another_variable(
+                self.db,
+                name,
+                path,
+                self.body.expr_or_pat_path_hygiene(node),
+                &self.new_name,
+                self.to_be_renamed,
+            ) {
                 self.conflicts.insert(conflicting);
             }
         }
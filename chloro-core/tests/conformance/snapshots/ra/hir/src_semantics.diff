COMPARISON DIFF
============================================================

Original size: 101650 bytes
Chloro size:   100390 bytes
Rustfmt size:  101650 bytes

âœ— Outputs DIFFER

=== DIFF (- rustfmt, + chloro) ===
 
 use either::Either;
 use hir_def::{
-    DefWithBodyId, FunctionId, MacroId, StructId, TraitId, VariantId,
-    expr_store::{Body, ExprOrPatSource, path::Path},
+    expr_store::{path::Path, Body, ExprOrPatSource},
     hir::{BindingId, Expr, ExprId, ExprOrPatId, Pat},
-    nameres::{ModuleOrigin, crate_def_map},
+    nameres::{crate_def_map, ModuleOrigin},
     resolver::{self, HasResolver, Resolver, TypeNs},
     type_ref::Mutability,
+    DefWithBodyId, FunctionId, MacroId, StructId, TraitId, VariantId,
 };
 use hir_expand::{
-    EditionedFileId, ExpandResult, FileRange, HirFileId, InMacroFile, MacroCallId,
     attrs::collect_attrs,
     builtin::{BuiltinFnLikeExpander, EagerExpander},
     db::ExpandDatabase,
     files::{FileRangeWrapper, HirFileRange, InRealFile},
     mod_path::{ModPath, PathKind},
     name::AsName,
+    EditionedFileId, ExpandResult, FileRange, HirFileId, InMacroFile, MacroCallId,
 };
 use hir_ty::{
     diagnostics::{unsafe_operations, unsafe_operations_for_body},
     next_solver::DbInterner,
 };
-use intern::{Interned, Symbol, sym};
+use intern::{sym, Interned, Symbol};
 use itertools::Itertools;
 use rustc_hash::{FxHashMap, FxHashSet};
-use smallvec::{SmallVec, smallvec};
+use smallvec::{smallvec, SmallVec};
 use span::{Edition, FileId, SyntaxContext};
-use stdx::{TupleExt, always};
+use stdx::{always, TupleExt};
 use syntax::{
-    AstNode, AstToken, Direction, SyntaxKind, SyntaxNode, SyntaxNodePtr, SyntaxToken, TextRange,
-    TextSize,
     algo::skip_trivia_token,
     ast::{self, HasAttrs as _, HasGenericParams},
+    AstNode, AstToken, Direction, SyntaxKind, SyntaxNode, SyntaxNodePtr, SyntaxToken, TextRange,
+    TextSize,
 };
 
 use crate::{
+    db::HirDatabase,
+    semantics::source_to_def::{ChildContainer, SourceToDefCache, SourceToDefCtx},
+    source_analyzer::{name_hygiene, resolve_hir_path, SourceAnalyzer},
     Adjust, Adjustment, Adt, AutoBorrow, BindingMode, BuiltinAttr, Callable, Const, ConstParam,
     Crate, DefWithBody, DeriveHelper, Enum, Field, Function, GenericSubstitution, HasSource, Impl,
     InFile, InlineAsmOperand, ItemInNs, Label, LifetimeParam, Local, Macro, Module, ModuleDef,
     Name, OverloadedDeref, ScopeDef, Static, Struct, ToolModule, Trait, TupleField, Type,
     TypeAlias, TypeParam, Union, Variant, VariantDef,
-    db::HirDatabase,
-    semantics::source_to_def::{ChildContainer, SourceToDefCache, SourceToDefCtx},
-    source_analyzer::{SourceAnalyzer, name_hygiene, resolve_hir_path},
 };
 
 const CONTINUE_NO_BREAKS: ControlFlow<Infallible, ()> = ControlFlow::Continue(());
     ) -> Self {
         PathResolutionPerNs { type_ns, value_ns, macro_ns }
     }
+
     pub fn any(&self) -> Option<PathResolution> {
         self.type_ns.or(self.value_ns).or(self.macro_ns)
     }
     }
 }
 
-// Note: while this variant of `Semantics<'_, _>` might seem unused, as it does not
-// find actual use within the rust-analyzer project itself, it exists to enable the use
-// within e.g. tracked salsa functions in third-party crates that build upon `ra_ap_hir`.
 impl Semantics<'_, dyn HirDatabase> {
     /// Creates an instance that's weakly coupled to its underlying database type.
     pub fn new_dyn(db: &'_ dyn HirDatabase) -> Semantics<'_, dyn HirDatabase> {
     }
 }
 
-// Note: We take `DB` as `?Sized` here in order to support type-erased
-// use of `Semantics` via `Semantics<'_, dyn HirDatabase>`:
 impl<DB: HirDatabase + ?Sized> Semantics<'_, DB> {
     pub fn hir_file_for(&self, syntax_node: &SyntaxNode) -> HirFileId {
         self.imp.find_file(syntax_node).file_id
 
     /// Find an AstNode by offset inside SyntaxNode, if it is inside *MacroCall*,
     /// descend it and find again
-    // FIXME: Rethink this API
     pub fn find_node_at_offset_with_descend<N: AstNode>(
         &self,
         node: &SyntaxNode,
 
     /// Find an AstNode by offset inside SyntaxNode, if it is inside an attribute macro call,
     /// descend it and find again
-    // FIXME: Rethink this API
     pub fn find_nodes_at_offset_with_descend<'slf, N: AstNode + 'slf>(
         &'slf self,
         node: &SyntaxNode,
         self.imp.descend_node_at_offset(node, offset).filter_map(|mut it| it.find_map(N::cast))
     }
 
-    // FIXME: Rethink this API
     pub fn find_namelike_at_offset_with_descend<'slf>(
         &'slf self,
         node: &SyntaxNode,
 
     /// Retrieves the formatting part of the format_args! template string at the given offset.
     ///
-    // FIXME: Type the return type
     /// Returns the range (pre-expansion) in the string literal corresponding to the resolution,
     /// absolute file range (post-expansion)
     /// of the part in the format string, the corresponding string token and the resolution if it
     /// exists.
-    // FIXME: Remove this in favor of `check_for_format_args_template_with_file`
     pub fn check_for_format_args_template(
         &self,
         original_token: SyntaxToken,
         ast::String,
         Option<Either<PathResolution, InlineAsmOperand>>,
     )> {
-        let original_token =
-            self.wrap_token_infile(original_token).map(ast::String::cast).transpose()?;
+        let original_token = self.wrap_token_infile(original_token).map(ast::String::cast).transpose()?;
         self.check_for_format_args_template_with_file(original_token, offset)
     }
 
     /// Retrieves the formatting part of the format_args! template string at the given offset.
     ///
-    // FIXME: Type the return type
     /// Returns the range (pre-expansion) in the string literal corresponding to the resolution,
     /// absolute file range (post-expansion)
     /// of the part in the format string, the corresponding string token and the resolution if it
         ast::String,
         Option<Either<PathResolution, InlineAsmOperand>>,
     )> {
-        let relative_offset =
-            offset.checked_sub(original_token.value.syntax().text_range().start())?;
+        let relative_offset = offset.checked_sub(original_token.value.syntax().text_range().start())?;
         self.descend_into_macros_breakable(
             original_token.as_ref().map(|it| it.syntax().clone()),
             |token, _| {
     ///
     /// Note that if this token itself is within the context of a macro expansion does not matter.
     /// That is, we strictly check if it lies inside the input of a macro call.
-    pub fn is_inside_macro_call(&self, token @ InFile { value, .. }: InFile<&SyntaxToken>) -> bool {
+    pub fn is_inside_macro_call(
+        &self,
+        token @ InFile { value, .. }: InFile<&SyntaxToken>,
+    ) -> bool {
         value.parent_ancestors().any(|ancestor| {
             if ast::MacroCall::can_cast(ancestor.kind()) {
                 return true;
         token: SyntaxToken,
         mut cb: impl FnMut(InFile<SyntaxToken>, SyntaxContext),
     ) {
-        self.descend_into_macros_all(self.wrap_token_infile(token), false, &mut |t, ctx| {
+        self
+            .descend_into_macros_all(self.wrap_token_infile(token), false, &mut |t, ctx| {
             cb(t, ctx)
         });
     }
 
     pub fn descend_into_macros(&self, token: SyntaxToken) -> SmallVec<[SyntaxToken; 1]> {
         let mut res = smallvec![];
-        self.descend_into_macros_all(
+        self
+            .descend_into_macros_all(
             self.wrap_token_infile(token.clone()),
             false,
             &mut |t, _ctx| res.push(t.value),
     ) -> SmallVec<[InFile<SyntaxToken>; 1]> {
         let mut res = smallvec![];
         let token = self.wrap_token_infile(token);
-        self.descend_into_macros_all(token.clone(), always_descend_into_derives, &mut |t, ctx| {
+        self
+            .descend_into_macros_all(token.clone(), always_descend_into_derives, &mut |t, ctx| {
             if !ctx.is_opaque(self.db) {
                 // Don't descend into opaque contexts
                 res.push(t);
         let text = token.text();
         let kind = token.kind();
 
-        self.descend_into_macros_cb(token.clone(), |InFile { value, file_id: _ }, ctx| {
+        self
+            .descend_into_macros_cb(token.clone(), |InFile { value, file_id: _ }, ctx| {
             let mapped_kind = value.kind();
             let any_ident_match = || kind.is_any_identifier() && value.kind().is_any_identifier();
             let matches = (kind == mapped_kind || any_ident_match())
         let text = token.text();
         let kind = token.kind();
 
-        self.descend_into_macros_cb(token.clone(), |InFile { value, file_id }, ctx| {
+        self
+            .descend_into_macros_cb(token.clone(), |InFile { value, file_id }, ctx| {
             let mapped_kind = value.kind();
             let any_ident_match = || kind.is_any_identifier() && value.kind().is_any_identifier();
             let matches = (kind == mapped_kind || any_ident_match())
         always_descend_into_derives: bool,
         f: &mut dyn FnMut(InFile<SyntaxToken>, SyntaxContext),
     ) {
-        self.descend_into_macros_impl(token, always_descend_into_derives, &mut |tok, ctx| {
+        self
+            .descend_into_macros_impl(token, always_descend_into_derives, &mut |tok, ctx| {
             f(tok, ctx);
             CONTINUE_NO_BREAKS
         });
         let span = db.span_map(file_id).span_for_range(token.text_range());
 
         // Process the expansion of a call, pushing all tokens with our span in the expansion back onto our stack
-        let process_expansion_for_token =
-            |ctx: &mut SourceToDefCtx<'_, '_>, stack: &mut Vec<_>, macro_file| {
+        let process_expansion_for_token = |ctx: &mut SourceToDefCtx<'_, '_>, stack: &mut Vec<_>, macro_file| {
                 let InMacroFile { file_id, value: mapped_tokens } = ctx
                     .cache
                     .get_or_insert_expansion(ctx.db, macro_file)
             };
 
         // A stack of tokens to process, along with the file they came from
+
         // These are tracked to know which macro calls we still have to look into
+
         // the tokens themselves aren't that interesting as the span that is being used to map
+
         // things down never changes.
         let mut stack: Vec<(_, SmallVec<[_; 2]>)> = vec![];
         let include = file_id
         let mut m_cache = self.macro_call_cache.borrow_mut();
 
         // Filters out all tokens that contain the given range (usually the macro call), any such
+
         // token is redundant as the corresponding macro call has already been processed
         let filter_duplicates = |tokens: &mut SmallVec<_>, range: TextRange| {
             tokens.retain(|(t, _): &mut (SyntaxToken, _)| !range.contains_range(t.text_range()))
         None
     }
 
-    // Note this return type is deliberate as [`find_nodes_at_offset_with_descend`] wants to stop
-    // traversing the inner iterator when it finds a node.
-    // The outer iterator is over the tokens descendants
-    // The inner iterator is the ancestors of a descendant
     fn descend_node_at_offset(
         &self,
         node: &SyntaxNode,
     }
 
     /// Iterates the ancestors of the given node, climbing up macro expansions while doing so.
-    // FIXME: Replace with `ancestors_with_macros_file` when all usages are updated.
     pub fn ancestors_with_macros(
         &self,
         node: SyntaxNode,
     }
 
     /// Env is used to derive the trait environment
-    // FIXME: better api for the trait environment
     pub fn resolve_trait_impl_method(
         &self,
         env: Type<'db>,
     ) -> Option<Function> {
         let interner = DbInterner::new_with(self.db, None, None);
         let mut subst = subst.into_iter();
-        let substs =
-            hir_ty::next_solver::GenericArgs::for_item(interner, trait_.id.into(), |_, id, _| {
+        let substs = hir_ty::next_solver::GenericArgs::for_item(interner, trait_.id.into(), |_, id, _| {
                 assert!(matches!(id, hir_def::GenericParamId::TypeParamId(_)), "expected a type");
                 subst.next().expect("too few subst").ty.into()
             });
         self.analyze(try_expr.syntax())?.resolve_try_expr(self.db, try_expr)
     }
 
-    // This does not resolve the method call to the correct trait impl!
-    // We should probably fix that.
     pub fn resolve_method_call_as_callable(
         &self,
         call: &ast::MethodCallExpr,
     pub fn resolve_field_fallback(
         &self,
         field: &ast::FieldExpr,
-    ) -> Option<(Either<Either<Field, TupleField>, Function>, Option<GenericSubstitution<'db>>)>
-    {
+    ) -> Option<(Either<Either<Field, TupleField>, Function>, Option<GenericSubstitution<'db>>)> {
         self.analyze(field.syntax())?.resolve_field_fallback(self.db, field)
     }
 
         self.analyze(field.syntax())?.resolve_record_pat_field(self.db, field)
     }
 
-    // FIXME: Replace this with `resolve_macro_call2`
     pub fn resolve_macro_call(&self, macro_call: &ast::MacroCall) -> Option<Macro> {
         let macro_call = self.find_file(macro_call.syntax()).with_value(macro_call);
         self.resolve_macro_call2(macro_call)
         &self,
         node: InFile<&SyntaxNode>,
         offset: Option<TextSize>,
-        // replace this, just make the inference result a `LazyCell`
         infer_body: bool,
     ) -> Option<SourceAnalyzer<'db>> {
         let _p = tracing::info_span!("SemanticsImpl::analyze_impl").entered();
     /// Wraps the node in a [`InFile`] with the file id it belongs to.
     fn find_file<'node>(&self, node: &'node SyntaxNode) -> InFile<&'node SyntaxNode> {
         let root_node = find_root(node);
-        let file_id = self.lookup(&root_node).unwrap_or_else(|| {
+        let file_id = self
+            .lookup(&root_node)
+            .unwrap_or_else(|| {
             panic!(
                 "\n\nFailed to lookup {:?} in this Semantics.\n\
                  Make sure to only query nodes derived from this instance of Semantics.\n\
     }
 }
 
-// FIXME This can't be the best way to do this
 fn macro_call_to_macro_id(
     ctx: &mut SourceToDefCtx<'_, '_>,
     macro_call_id: MacroCallId,
     }
 }
 
-pub trait ToDef: AstNode + Clone {
+pub trait ToDef {
     type Def;
+
     fn to_def(sema: &SemanticsImpl<'_>, src: InFile<&Self>) -> Option<Self::Def>;
 }
 
COMPARISON DIFF
============================================================

Original size: 101650 bytes
Chloro size:   98813 bytes
Rustfmt size:  101650 bytes

âœ— Outputs DIFFER

=== DIFF (- rustfmt, + chloro) ===
 
 use either::Either;
 use hir_def::{
-    DefWithBodyId, FunctionId, MacroId, StructId, TraitId, VariantId,
     expr_store::{Body, ExprOrPatSource, path::Path},
     hir::{BindingId, Expr, ExprId, ExprOrPatId, Pat},
     nameres::{ModuleOrigin, crate_def_map},
     resolver::{self, HasResolver, Resolver, TypeNs},
     type_ref::Mutability,
+    DefWithBodyId, FunctionId, MacroId, StructId, TraitId, VariantId,
 };
 use hir_expand::{
-    EditionedFileId, ExpandResult, FileRange, HirFileId, InMacroFile, MacroCallId,
     attrs::collect_attrs,
     builtin::{BuiltinFnLikeExpander, EagerExpander},
     db::ExpandDatabase,
     files::{FileRangeWrapper, HirFileRange, InRealFile},
     mod_path::{ModPath, PathKind},
     name::AsName,
+    EditionedFileId, ExpandResult, FileRange, HirFileId, InMacroFile, MacroCallId,
 };
 use hir_ty::{
     diagnostics::{unsafe_operations, unsafe_operations_for_body},
 use span::{Edition, FileId, SyntaxContext};
 use stdx::{TupleExt, always};
 use syntax::{
-    AstNode, AstToken, Direction, SyntaxKind, SyntaxNode, SyntaxNodePtr, SyntaxToken, TextRange,
-    TextSize,
     algo::skip_trivia_token,
     ast::{self, HasAttrs as _, HasGenericParams},
+    AstNode, AstToken, Direction, SyntaxKind, SyntaxNode, SyntaxNodePtr, SyntaxToken, TextRange,
+    TextSize,
 };
 
 use crate::{
-    Adjust, Adjustment, Adt, AutoBorrow, BindingMode, BuiltinAttr, Callable, Const, ConstParam,
-    Crate, DefWithBody, DeriveHelper, Enum, Field, Function, GenericSubstitution, HasSource, Impl,
-    InFile, InlineAsmOperand, ItemInNs, Label, LifetimeParam, Local, Macro, Module, ModuleDef,
-    Name, OverloadedDeref, ScopeDef, Static, Struct, ToolModule, Trait, TupleField, Type,
-    TypeAlias, TypeParam, Union, Variant, VariantDef,
     db::HirDatabase,
     semantics::source_to_def::{ChildContainer, SourceToDefCache, SourceToDefCtx},
     source_analyzer::{SourceAnalyzer, name_hygiene, resolve_hir_path},
+    Adjust, Adjustment, Adt, AutoBorrow, BindingMode, BuiltinAttr, Callable, Const, ConstParam,
+    Crate, DefWithBody, DeriveHelper, Enum, Field, Function, GenericSubstitution, HasSource, Impl,
+    InFile, InlineAsmOperand, ItemInNs, Label, LifetimeParam, Local, Macro, Module, ModuleDef, Name,
+    OverloadedDeref, ScopeDef, Static, Struct, ToolModule, Trait, TupleField, Type, TypeAlias,
+    TypeParam, Union, Variant, VariantDef,
 };
 
 const CONTINUE_NO_BREAKS: ControlFlow<Infallible, ()> = ControlFlow::Continue(());
     ) -> Self {
         PathResolutionPerNs { type_ns, value_ns, macro_ns }
     }
+
     pub fn any(&self) -> Option<PathResolution> {
         self.type_ns.or(self.value_ns).or(self.macro_ns)
     }
     }
 }
 
-// Note: while this variant of `Semantics<'_, _>` might seem unused, as it does not
-// find actual use within the rust-analyzer project itself, it exists to enable the use
-// within e.g. tracked salsa functions in third-party crates that build upon `ra_ap_hir`.
 impl Semantics<'_, dyn HirDatabase> {
     /// Creates an instance that's weakly coupled to its underlying database type.
     pub fn new_dyn(db: &'_ dyn HirDatabase) -> Semantics<'_, dyn HirDatabase> {
     }
 }
 
-// Note: We take `DB` as `?Sized` here in order to support type-erased
-// use of `Semantics` via `Semantics<'_, dyn HirDatabase>`:
 impl<DB: HirDatabase + ?Sized> Semantics<'_, DB> {
     pub fn hir_file_for(&self, syntax_node: &SyntaxNode) -> HirFileId {
         self.imp.find_file(syntax_node).file_id
 
     /// Find an AstNode by offset inside SyntaxNode, if it is inside *MacroCall*,
     /// descend it and find again
-    // FIXME: Rethink this API
     pub fn find_node_at_offset_with_descend<N: AstNode>(
         &self,
         node: &SyntaxNode,
 
     /// Find an AstNode by offset inside SyntaxNode, if it is inside an attribute macro call,
     /// descend it and find again
-    // FIXME: Rethink this API
     pub fn find_nodes_at_offset_with_descend<'slf, N: AstNode + 'slf>(
         &'slf self,
         node: &SyntaxNode,
         self.imp.descend_node_at_offset(node, offset).filter_map(|mut it| it.find_map(N::cast))
     }
 
-    // FIXME: Rethink this API
     pub fn find_namelike_at_offset_with_descend<'slf>(
         &'slf self,
         node: &SyntaxNode,
         let file_id = self
             .attach_first_edition(file_id)
             .unwrap_or_else(|| EditionedFileId::new(self.db, file_id, Edition::CURRENT));
-
         let tree = self.db.parse(file_id).tree();
         self.cache(tree.syntax().clone(), file_id.into());
         tree
     ) -> Option<ExpandResult<SyntaxNode>> {
         let file_id = self.to_def(macro_call)?;
         let macro_call = self.db.lookup_intern_macro_call(file_id);
-
         let skip = matches!(
             macro_call.def.kind,
             hir_expand::MacroDefKind::BuiltIn(
             // showing these to the user
             return None;
         }
-
         let node = self.expand(file_id);
         Some(node)
     }
 
     /// Retrieves the formatting part of the format_args! template string at the given offset.
     ///
-    // FIXME: Type the return type
     /// Returns the range (pre-expansion) in the string literal corresponding to the resolution,
     /// absolute file range (post-expansion)
     /// of the part in the format string, the corresponding string token and the resolution if it
     /// exists.
-    // FIXME: Remove this in favor of `check_for_format_args_template_with_file`
     pub fn check_for_format_args_template(
         &self,
         original_token: SyntaxToken,
 
     /// Retrieves the formatting part of the format_args! template string at the given offset.
     ///
-    // FIXME: Type the return type
     /// Returns the range (pre-expansion) in the string literal corresponding to the resolution,
     /// absolute file range (post-expansion)
     /// of the part in the format string, the corresponding string token and the resolution if it
             None => return res,
         };
         let file = self.find_file(node.syntax());
-
         if first == last {
             // node is just the token, so descend the token
             self.descend_into_macros_all(
     ///
     /// Note that if this token itself is within the context of a macro expansion does not matter.
     /// That is, we strictly check if it lies inside the input of a macro call.
-    pub fn is_inside_macro_call(&self, token @ InFile { value, .. }: InFile<&SyntaxToken>) -> bool {
+    pub fn is_inside_macro_call(
+        &self,
+        token @ InFile { value, .. }: InFile<&SyntaxToken>,
+    ) -> bool {
         value.parent_ancestors().any(|ancestor| {
             if ast::MacroCall::can_cast(ancestor.kind()) {
                 return true;
         let mut r = smallvec![];
         let text = token.text();
         let kind = token.kind();
-
         self.descend_into_macros_cb(token.clone(), |InFile { value, file_id: _ }, ctx| {
             let mapped_kind = value.kind();
             let any_ident_match = || kind.is_any_identifier() && value.kind().is_any_identifier();
         let mut r = smallvec![];
         let text = token.text();
         let kind = token.kind();
-
         self.descend_into_macros_cb(token.clone(), |InFile { value, file_id }, ctx| {
             let mapped_kind = value.kind();
             let any_ident_match = || kind.is_any_identifier() && value.kind().is_any_identifier();
         f: &mut dyn FnMut(InFile<SyntaxToken>, SyntaxContext) -> ControlFlow<T>,
     ) -> Option<T> {
         let _p = tracing::info_span!("descend_into_macros_impl").entered();
-
         let db = self.db;
         let span = db.span_map(file_id).span_for_range(token.text_range());
-
         // Process the expansion of a call, pushing all tokens with our span in the expansion back onto our stack
         let process_expansion_for_token =
             |ctx: &mut SourceToDefCtx<'_, '_>, stack: &mut Vec<_>, macro_file| {
                 stack.push((HirFileId::from(file_id), mapped_tokens));
                 res
             };
-
         // A stack of tokens to process, along with the file they came from
         // These are tracked to know which macro calls we still have to look into
         // the tokens themselves aren't that interesting as the span that is being used to map
                 stack.push((file_id, smallvec![(token, span.ctx)]));
             }
         }
-
         let mut m_cache = self.macro_call_cache.borrow_mut();
-
         // Filters out all tokens that contain the given range (usually the macro call), any such
         // token is redundant as the corresponding macro call has already been processed
         let filter_duplicates = |tokens: &mut SmallVec<_>, range: TextRange| {
             tokens.retain(|(t, _): &mut (SyntaxToken, _)| !range.contains_range(t.text_range()))
         };
-
         while let Some((expansion, ref mut tokens)) = stack.pop() {
             // Reverse the tokens so we prefer first tokens (to accommodate for popping from the
             // back)
         None
     }
 
-    // Note this return type is deliberate as [`find_nodes_at_offset_with_descend`] wants to stop
-    // traversing the inner iterator when it finds a node.
-    // The outer iterator is over the tokens descendants
-    // The inner iterator is the ancestors of a descendant
     fn descend_node_at_offset(
         &self,
         node: &SyntaxNode,
     }
 
     /// Iterates the ancestors of the given node, climbing up macro expansions while doing so.
-    // FIXME: Replace with `ancestors_with_macros_file` when all usages are updated.
     pub fn ancestors_with_macros(
         &self,
         node: SyntaxNode,
             hir_ty::next_solver::Mutability::Not => Mutability::Shared,
             hir_ty::next_solver::Mutability::Mut => Mutability::Mut,
         };
-
         let analyzer = self.analyze(expr.syntax())?;
-
         let (mut source_ty, _) = analyzer.type_of_expr(self.db, expr)?;
-
         analyzer.expr_adjustments(expr).map(|it| {
             it.iter()
                 .map(|adjust| {
     }
 
     /// Env is used to derive the trait environment
-    // FIXME: better api for the trait environment
     pub fn resolve_trait_impl_method(
         &self,
         env: Type<'db>,
         self.analyze(try_expr.syntax())?.resolve_try_expr(self.db, try_expr)
     }
 
-    // This does not resolve the method call to the correct trait impl!
-    // We should probably fix that.
     pub fn resolve_method_call_as_callable(
         &self,
         call: &ast::MethodCallExpr,
     pub fn resolve_field_fallback(
         &self,
         field: &ast::FieldExpr,
-    ) -> Option<(Either<Either<Field, TupleField>, Function>, Option<GenericSubstitution<'db>>)>
-    {
+    ) -> Option<(Either<Either<Field, TupleField>, Function>, Option<GenericSubstitution<'db>>)> {
         self.analyze(field.syntax())?.resolve_field_fallback(self.db, field)
     }
 
         self.analyze(field.syntax())?.resolve_record_pat_field(self.db, field)
     }
 
-    // FIXME: Replace this with `resolve_macro_call2`
     pub fn resolve_macro_call(&self, macro_call: &ast::MacroCall) -> Option<Macro> {
         let macro_call = self.find_file(macro_call.syntax()).with_value(macro_call);
         self.resolve_macro_call2(macro_call)
         if mac.is_asm_like(self.db) {
             return true;
         }
-
         let Some(sa) = self.analyze(macro_call.syntax()) else { return false };
         let macro_call = self.find_file(macro_call.syntax()).with_value(macro_call);
         match macro_call.map(|it| it.syntax().parent().and_then(ast::MacroExpr::cast)).transpose() {
 
     pub fn body_for(&self, node: InFile<&SyntaxNode>) -> Option<DefWithBody> {
         let container = self.with_ctx(|ctx| ctx.find_container(node))?;
-
         match container {
             ChildContainer::DefWithBodyId(def) => Some(def.into()),
             _ => None,
         &self,
         node: InFile<&SyntaxNode>,
         offset: Option<TextSize>,
-        // replace this, just make the inference result a `LazyCell`
         infer_body: bool,
     ) -> Option<SourceAnalyzer<'db>> {
         let _p = tracing::info_span!("SemanticsImpl::analyze_impl").entered();
-
         let container = self.with_ctx(|ctx| ctx.find_container(node))?;
-
         let resolver = match container {
             ChildContainer::DefWithBodyId(def) => {
                 return Some(if infer_body {
         else {
             return false;
         };
-
         let def = match &enclosing_item {
             Either::Left(ast::Item::Fn(it)) if it.unsafe_token().is_some() => return true,
             Either::Left(ast::Item::Fn(it)) => {
         };
         let Some(def) = def else { return false };
         let enclosing_node = enclosing_item.as_ref().either(|i| i.syntax(), |v| v.syntax());
-
         let (body, source_map) = self.db.body_with_source_map(def);
-
         let file_id = self.find_file(expr.syntax()).file_id;
-
         let Some(mut parent) = expr.syntax().parent() else { return false };
         loop {
             if &parent == enclosing_node {
     }
 }
 
-// FIXME This can't be the best way to do this
 fn macro_call_to_macro_id(
     ctx: &mut SourceToDefCtx<'_, '_>,
     macro_call_id: MacroCallId,
 ) -> Option<MacroId> {
     let db: &dyn ExpandDatabase = ctx.db;
     let loc = db.lookup_intern_macro_call(macro_call_id);
-
     match loc.def.ast_id() {
         Either::Left(it) => {
             let node = match it.file_id {
     }
 }
 
-pub trait ToDef: AstNode + Clone {
+pub trait ToDef {
     type Def;
+
     fn to_def(sema: &SemanticsImpl<'_>, src: InFile<&Self>) -> Option<Self::Def>;
 }
 
         }
     )*}
 }
-
-to_def_impls![
-    (crate::Module, ast::Module, module_to_def),
-    (crate::Module, ast::SourceFile, source_file_to_def),
-    (crate::Struct, ast::Struct, struct_to_def),
-    (crate::Enum, ast::Enum, enum_to_def),
-    (crate::Union, ast::Union, union_to_def),
-    (crate::Trait, ast::Trait, trait_to_def),
-    (crate::Impl, ast::Impl, impl_to_def),
-    (crate::TypeAlias, ast::TypeAlias, type_alias_to_def),
-    (crate::Const, ast::Const, const_to_def),
-    (crate::Static, ast::Static, static_to_def),
-    (crate::Function, ast::Fn, fn_to_def),
-    (crate::Field, ast::RecordField, record_field_to_def),
-    (crate::Field, ast::TupleField, tuple_field_to_def),
-    (crate::Variant, ast::Variant, enum_variant_to_def),
-    (crate::TypeParam, ast::TypeParam, type_param_to_def),
-    (crate::LifetimeParam, ast::LifetimeParam, lifetime_param_to_def),
-    (crate::ConstParam, ast::ConstParam, const_param_to_def),
-    (crate::GenericParam, ast::GenericParam, generic_param_to_def),
-    (crate::Macro, ast::Macro, macro_to_def),
-    (crate::Local, ast::IdentPat, bind_pat_to_def),
-    (crate::Local, ast::SelfParam, self_param_to_def),
-    (crate::Label, ast::Label, label_to_def),
-    (crate::Adt, ast::Adt, adt_to_def),
-    (crate::ExternCrateDecl, ast::ExternCrate, extern_crate_to_def),
-    (crate::InlineAsmOperand, ast::AsmOperandNamed, asm_operand_to_def),
-    (crate::ExternBlock, ast::ExternBlock, extern_block_to_def),
-    (MacroCallId, ast::MacroCall, macro_call_to_macro_call),
-];
-
 fn find_root(node: &SyntaxNode) -> SyntaxNode {
     node.ancestors().last().unwrap()
 }
                 ast::PathSegmentKind::CrateKw => kind = PathKind::Crate,
             }
         }
-
         resolve_hir_path(
             self.db,
             &self.resolver,
             }
             _ => {}
         }
-
         self.body.walk_child_exprs(expr, |expr| self.rename_conflicts(expr));
     }
 }
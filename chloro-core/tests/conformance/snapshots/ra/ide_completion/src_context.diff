COMPARISON DIFF
============================================================

Original size: 30787 bytes
Chloro size:   30665 bytes
Rustfmt size:  31005 bytes

âœ— Outputs DIFFER

=== DIFF (- rustfmt, + chloro) ===
 /// Existing qualifiers for the thing we are currently completing.
 #[derive(Debug, Default)]
 pub(crate) struct QualifierCtx {
-    // TODO: Add try_tok and default_tok
     pub(crate) async_tok: Option<SyntaxToken>,
     pub(crate) unsafe_tok: Option<SyntaxToken>,
     pub(crate) safe_tok: Option<SyntaxToken>,
     pub(crate) qualified: Qualified<'db>,
     /// The parent of the path we are completing.
     pub(crate) parent: Option<ast::Path>,
-    #[allow(dead_code)]
     /// The path of which we are completing the segment
+    #[allow(dead_code)]
     pub(crate) path: ast::Path,
     /// The path of which we are completing the segment in the original file
     pub(crate) original_path: Option<ast::Path>,
 
     pub(crate) fn complete_types(&self) -> bool {
         match self {
-            TypeLocation::GenericArg {
-                corresponding_param: Some(param),
-                ..
-            } => {
+            TypeLocation::GenericArg { corresponding_param: Some(param), .. } => {
                 matches!(param, ast::GenericParam::TypeParam(_))
             }
             TypeLocation::AssocConstEq => false,
     Impl,
     TraitImpl(Option<ast::Impl>),
     Trait,
-    ExternBlock { is_unsafe: bool },
+    ExternBlock {
+        is_unsafe: bool,
+    },
 }
 
 #[derive(Debug)]
     pub(crate) db: &'a RootDatabase,
     pub(crate) config: &'a CompletionConfig<'a>,
     pub(crate) position: FilePosition,
-
     pub(crate) trigger_character: Option<char>,
     /// The token before the cursor, in the original file.
     pub(crate) original_token: SyntaxToken,
     /// Whether nightly toolchain is used. Cached since this is looked up a lot.
     pub(crate) is_nightly: bool,
     /// The edition of the current crate
-    // FIXME: This should probably be the crate of the current token?
     pub(crate) edition: Edition,
-
     /// The expected name of what we are completing.
     /// This is usually the parameter name of the function argument we are completing.
     pub(crate) expected_name: Option<NameOrNameRef>,
     /// The expected type of what we are completing.
     pub(crate) expected_type: Option<Type<'a>>,
-
     pub(crate) qualifier_ctx: QualifierCtx,
-
     pub(crate) locals: FxHashMap<Name, Local>,
-
     /// The module depth of the current module of the cursor position.
     /// - crate-root
     ///  - mod foo
     ///
     /// Here depth will be 2
     pub(crate) depth_from_crate_root: usize,
-
     /// Traits whose methods will be excluded from flyimport. Flyimport should not suggest
     /// importing those traits.
     ///
     ///
     /// Note the trait *themselves* are not excluded, only their methods are.
     pub(crate) exclude_traits: FxHashSet<hir::Trait>,
-
     /// Whether and how to complete semicolon for unit-returning functions.
     pub(crate) complete_semicolon: CompleteSemicolon,
 }
             };
         }
 
-        if self.is_doc_hidden(attrs, defining_crate) {
-            Visible::No
-        } else {
-            Visible::Yes
-        }
+        if self.is_doc_hidden(attrs, defining_crate) { Visible::No } else { Visible::Yes }
     }
 
     pub(crate) fn is_doc_hidden(&self, attrs: &hir::Attrs, defining_crate: hir::Crate) -> bool {
     }
 }
 
-// CompletionContext construction
 impl<'db> CompletionContext<'db> {
     pub(crate) fn new(
         db: &'db RootDatabase,
 
         let editioned_file_id = sema.attach_first_edition(file_id)?;
         let original_file = sema.parse(editioned_file_id);
-
         // Insert a fake ident to get a valid parse tree. We will use this file
         // to determine context, though the original_file will be used for
         // actual completion.
+
         let file_with_fake_ident = {
             let (_, edition) = editioned_file_id.unpack(db);
             let parse = db.parse(editioned_file_id);
-            parse
-                .reparse(TextRange::empty(offset), COMPLETION_MARKER, edition)
-                .tree()
+            parse.reparse(TextRange::empty(offset), COMPLETION_MARKER, edition).tree()
         };
-
         // always pick the token to the immediate left of the cursor, as that is what we are actually
         // completing on
-        let original_token = original_file
-            .syntax()
-            .token_at_offset(offset)
-            .left_biased()?;
 
+        let original_token = original_file.syntax().token_at_offset(offset).left_biased()?;
         // try to skip completions on path with invalid colons
         // this approach works in normal path and inside token tree
+
         if original_token.kind() == T![:] {
             // return if no prev token before colon
             let prev_token = original_token.prev_token()?;
             offset,
             &original_token,
         )?;
-
         // adjust for macro input, this still fails if there is no token written yet
+
         let scope = sema.scope_at_offset(&token.parent()?, original_offset)?;
 
         let krate = scope.krate();
                     .map(|it| (it.into_module_def(), *kind))
             })
             .collect();
-        exclude_flyimport.extend(
-            exclude_traits
-                .iter()
-                .map(|&t| (t.into(), AutoImportExclusionType::Always)),
-        );
-
+        exclude_flyimport
+            .extend(exclude_traits.iter().map(|&t| (t.into(), AutoImportExclusionType::Always)));
         // FIXME: This should be part of `CompletionAnalysis` / `expand_and_analyze`
+
         let complete_semicolon = if config.add_semicolon_to_unit {
             let inside_closure_ret = token.parent_ancestors().try_for_each(|ancestor| {
                 match_ast! {
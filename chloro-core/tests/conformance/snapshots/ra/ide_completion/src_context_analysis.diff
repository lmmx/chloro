COMPARISON DIFF
============================================================

Original size: 89146 bytes
Chloro size:   89144 bytes
Rustfmt size:  89146 bytes

âœ— Outputs DIFFER

=== DIFF (- rustfmt, + chloro) ===
 //! Module responsible for analyzing the code surrounding the cursor for completion.
+
 use std::iter;
 
 use hir::{ExpandResult, InFile, Semantics, Type, TypeInfo, Variant};
 use crate::{
     completions::postfix::is_in_condition,
     context::{
-        AttrCtx, BreakableKind, COMPLETION_MARKER, CompletionAnalysis, DotAccess, DotAccessExprCtx,
-        DotAccessKind, ItemListKind, LifetimeContext, LifetimeKind, NameContext, NameKind,
-        NameRefContext, NameRefKind, ParamContext, ParamKind, PathCompletionCtx, PathExprCtx,
-        PathKind, PatternContext, PatternRefutability, Qualified, QualifierCtx,
+        AttrCtx, BreakableKind, COMPLETION_MARKER, CompletionAnalysis, DotAccess,
+        DotAccessExprCtx, DotAccessKind, ItemListKind, LifetimeContext, LifetimeKind, NameContext,
+        NameKind, NameRefContext, NameRefKind, ParamContext, ParamKind, PathCompletionCtx,
+        PathExprCtx, PathKind, PatternContext, PatternRefutability, Qualified, QualifierCtx,
         TypeAscriptionTarget, TypeLocation,
     },
 };
     });
 
     // add the relative offset back, so that left_biased finds the proper token
+
     let original_offset = expansion.original_offset + relative_offset;
     let token = expansion.original_file.token_at_offset(original_offset).left_biased()?;
 
-    hir::attach_db(sema.db, || analyze(sema, expansion, original_token, &token)).map(
-        |(analysis, expected, qualifier_ctx)| AnalysisResult {
+    hir::attach_db(sema.db, || analyze(sema, expansion, original_token, &token)).map(|(analysis, expected, qualifier_ctx)| AnalysisResult {
             analysis,
             expected,
             qualifier_ctx,
             token,
             original_offset,
-        },
-    )
+        })
 }
 
 fn token_at_offset_ignore_whitespace(file: &SyntaxNode, offset: TextSize) -> Option<SyntaxToken> {
     }
 
     // We can't check whether the fake expansion is inside macro call, because that requires semantic info.
+
     // But hopefully checking just the real one should be enough.
-    if token_at_offset_ignore_whitespace(&original_file.value, original_offset + relative_offset)
-        .is_some_and(|original_token| {
+
+    if token_at_offset_ignore_whitespace(&original_file.value, original_offset + relative_offset).is_some_and(|original_token| {
             !sema.is_inside_macro_call(original_file.with_value(&original_token))
-        })
-    {
+        }) {
         // Recursion base case.
         Some(ExpansionResult {
             original_file: original_file.value,
     );
 
     // first try to expand attributes as these are always the outermost macro calls
+
     'ancestors: for (actual_item, item_with_fake_ident) in ancestor_items {
         match (
             sema.expand_attr_macro(&actual_item),
     }
 
     // No attributes have been expanded, so look for macro_call! token trees or derive token trees
+
     let orig_tt = ancestors_at_offset(&original_file.value, original_offset)
         .map_while(Either::<ast::TokenTree, ast::Meta>::cast)
         .last()?;
     };
 
     // Expand pseudo-derive expansion aka `derive(Debug$0)`
+
     if let Some((orig_attr, spec_attr)) = attrs {
         if let (Some(actual_expansion), Some((fake_expansion, fake_mapped_tokens))) = (
             sema.expand_derive_as_pseudo_attr_macro(&orig_attr),
     }
 
     // Expand fn-like macro calls
+
     let (orig_tt, spec_tt) = tts?;
     let (actual_macro_call, macro_call_with_fake_ident) = (
         orig_tt.syntax().parent().and_then(ast::MacroCall::cast)?,
     let mac_call_path1 = macro_call_with_fake_ident.path().as_ref().map(|s| s.syntax().text());
 
     // inconsistent state, stop expanding
+
     if mac_call_path0 != mac_call_path1 {
         return None;
     }
     expansion_result: ExpansionResult,
     original_token: &SyntaxToken,
     self_token: &SyntaxToken,
-) -> Option<(CompletionAnalysis<'db>, (Option<Type<'db>>, Option<ast::NameOrNameRef>), QualifierCtx)>
-{
+) -> Option<(CompletionAnalysis<'db>, (Option<Type<'db>>, Option<ast::NameOrNameRef>), QualifierCtx)> {
     let _p = tracing::info_span!("CompletionContext::analyze").entered();
     let ExpansionResult {
         original_file,
     }
 
     // Overwrite the path kind for derives
+
     if let Some((original_file, file_with_fake_ident, offset, origin_attr)) = derive_ctx {
         if let Some(ast::NameLike::NameRef(name_ref)) =
             find_node_at_offset(&file_with_fake_ident, offset)
     };
 
     // We do not want to generate path completions when we are sandwiched between an item decl signature and its body.
+
     // ex. trait Foo $0 {}
+
     // in these cases parser recovery usually kicks in for our inserted identifier, causing it
+
     // to either be parsed as an ExprStmt or a ItemRecovery, depending on whether it is in a block
+
     // expression or an item list.
+
     // The following code checks if the body is missing, if it is we either cut off the body
+
     // from the item or it was missing in the first place
+
     let inbetween_body_and_decl_check = |node: SyntaxNode| {
         if let Some(NodeOrToken::Node(n)) =
             syntax::algo::non_trivia_sibling(node.into(), syntax::Direction::Prev)
     };
 
     // Infer the path kind
+
     let parent = path.syntax().parent()?;
     let kind = 'find_kind: {
         if parent.kind() == SyntaxKind::ERROR {
     path_ctx.has_type_args = segment.generic_arg_list().is_some();
 
     // calculate the qualifier context
+
     if let Some((qualifier, use_tree_parent)) = path_or_use_tree_qualifier(&path) {
         path_ctx.use_tree_parent = use_tree_parent;
         if !use_tree_parent && segment.coloncolon_token().is_some() {
     };
 
     // Only suggest name in let-stmt or fn param
+
     let should_suggest_name = matches!(
             &pat,
             ast::Pat::IdentPat(it)
                 t.text_range().start() == path.syntax().text_range().start()
             }
         })
-    })()
-    .unwrap_or(false)
+    })().unwrap_or(
+        false,
+    )
 }
 
 fn is_in_breakable(node: &SyntaxNode) -> Option<(BreakableKind, SyntaxNode)> {
             .ancestors()
             .take_while(|it| it.text_range().start() == node.text_range().start())
             .filter_map(Either::<ast::ExprStmt, ast::Expr>::cast)
-            .last()
-    {
+            .last() {
         stmt_like.syntax().parent().and_then(ast::StmtList::cast).is_some()
     } else {
         false
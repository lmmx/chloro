COMPARISON DIFF
============================================================

Original size: 89146 bytes
Chloro size:   88874 bytes
Rustfmt size:  89146 bytes

âœ— Outputs DIFFER

=== DIFF (- rustfmt, + chloro) ===
 //! Module responsible for analyzing the code surrounding the cursor for completion.
+
 use std::iter;
 
 use hir::{ExpandResult, InFile, Semantics, Type, TypeInfo, Variant};
-use ide_db::{RootDatabase, active_parameter::ActiveParameter};
+use ide_db::{active_parameter::ActiveParameter, RootDatabase};
 use itertools::Either;
 use stdx::always;
 use syntax::{
-    AstNode, AstToken, Direction, NodeOrToken, SyntaxElement, SyntaxKind, SyntaxNode, SyntaxToken,
-    T, TextRange, TextSize,
     algo::{
         self, ancestors_at_offset, find_node_at_offset, non_trivia_sibling,
         previous_non_trivia_token,
         self, AttrKind, HasArgList, HasGenericArgs, HasGenericParams, HasLoopBody, HasName,
         NameOrNameRef,
     },
-    match_ast,
+    match_ast, AstNode, AstToken, Direction, NodeOrToken, SyntaxElement, SyntaxKind, SyntaxNode,
+    SyntaxToken, TextRange, TextSize, T,
 };
 
 use crate::{
     completions::postfix::is_in_condition,
     context::{
-        AttrCtx, BreakableKind, COMPLETION_MARKER, CompletionAnalysis, DotAccess, DotAccessExprCtx,
-        DotAccessKind, ItemListKind, LifetimeContext, LifetimeKind, NameContext, NameKind,
-        NameRefContext, NameRefKind, ParamContext, ParamKind, PathCompletionCtx, PathExprCtx,
-        PathKind, PatternContext, PatternRefutability, Qualified, QualifierCtx,
-        TypeAscriptionTarget, TypeLocation,
+        AttrCtx, BreakableKind, CompletionAnalysis, DotAccess, DotAccessExprCtx, DotAccessKind,
+        ItemListKind, LifetimeContext, LifetimeKind, NameContext, NameKind, NameRefContext,
+        NameRefKind, ParamContext, ParamKind, PathCompletionCtx, PathExprCtx, PathKind,
+        PatternContext, PatternRefutability, Qualified, QualifierCtx, TypeAscriptionTarget,
+        TypeLocation, COMPLETION_MARKER,
     },
 };
 
     let original_offset = expansion.original_offset + relative_offset;
     let token = expansion.original_file.token_at_offset(original_offset).left_biased()?;
 
-    hir::attach_db(sema.db, || analyze(sema, expansion, original_token, &token)).map(
-        |(analysis, expected, qualifier_ctx)| AnalysisResult {
+    hir::attach_db(sema.db, || analyze(sema, expansion, original_token, &token)).map(|(analysis, expected, qualifier_ctx)| AnalysisResult {
             analysis,
             expected,
             qualifier_ctx,
             token,
             original_offset,
-        },
-    )
+        })
 }
 
 fn token_at_offset_ignore_whitespace(file: &SyntaxNode, offset: TextSize) -> Option<SyntaxToken> {
     }
 
     // We can't check whether the fake expansion is inside macro call, because that requires semantic info.
+
     // But hopefully checking just the real one should be enough.
-    if token_at_offset_ignore_whitespace(&original_file.value, original_offset + relative_offset)
-        .is_some_and(|original_token| {
+    if token_at_offset_ignore_whitespace(&original_file.value, original_offset + relative_offset).is_some_and(|original_token| {
             !sema.is_inside_macro_call(original_file.with_value(&original_token))
-        })
-    {
-        // Recursion base case.
+        }) {
         Some(ExpansionResult {
             original_file: original_file.value,
             speculative_file,
         sema.expand_macro_call(&actual_macro_call),
         sema.speculative_expand_macro_call(&actual_macro_call, &speculative_args, fake_ident_token),
     ) {
-        // successful expansions
         (Some(actual_expansion), Some((fake_expansion, fake_mapped_tokens))) => {
             let mut accumulated_offset_from_fake_tokens = 0;
             let actual_range = actual_expansion.text_range().end();
-            fake_mapped_tokens
-                .into_iter()
-                .filter_map(|(fake_mapped_token, rank)| {
+            fake_mapped_tokens.into_iter().filter_map(|(fake_mapped_token, rank)| {
                     let accumulated_offset = accumulated_offset_from_fake_tokens;
                     if !fake_mapped_token.text().contains(COMPLETION_MARKER) {
                         // Proc macros can make the same span with different text, we don't
                         relative_offset,
                     )?;
                     Some((result, rank))
-                })
-                .min_by_key(|(_, rank)| *rank)
-                .map(|(result, _)| result)
+                }).min_by_key(
+                |(_, rank)| *rank,
+            ).map(
+                |(result, _)| result,
+            )
         }
-        // at least one expansion failed, we won't have anything to expand from this point
-        // onwards so break out
         _ => None,
     }
 }
     expansion_result: ExpansionResult,
     original_token: &SyntaxToken,
     self_token: &SyntaxToken,
-) -> Option<(CompletionAnalysis<'db>, (Option<Type<'db>>, Option<ast::NameOrNameRef>), QualifierCtx)>
-{
+) -> Option<(CompletionAnalysis<'db>, (Option<Type<'db>>, Option<ast::NameOrNameRef>), QualifierCtx)> {
     let _p = tracing::info_span!("CompletionContext::analyze").entered();
     let ExpansionResult {
         original_file,
     };
 
     // We do not want to generate path completions when we are sandwiched between an item decl signature and its body.
+
     // ex. trait Foo $0 {}
+
     // in these cases parser recovery usually kicks in for our inserted identifier, causing it
+
     // to either be parsed as an ExprStmt or a ItemRecovery, depending on whether it is in a block
+
     // expression or an item list.
+
     // The following code checks if the body is missing, if it is we either cut off the body
+
     // from the item or it was missing in the first place
     let inbetween_body_and_decl_check = |node: SyntaxNode| {
         if let Some(NodeOrToken::Node(n)) =
     let prev_siblings = iter::successors(arg_list.syntax().prev_sibling_or_token(), |it| {
         it.prev_sibling_or_token()
     });
-    prev_siblings
-        .take_while(|syntax| syntax.kind().is_trivia())
-        .filter_map(|syntax| {
+    prev_siblings.take_while(|syntax| syntax.kind().is_trivia()).filter_map(|syntax| {
             syntax.into_token().filter(|token| token.kind() == SyntaxKind::WHITESPACE)
-        })
-        .all(|whitespace| !whitespace.text().contains('\n'))
+        }).all(
+        |whitespace| !whitespace.text().contains('\n'),
+    )
 }
 
 fn pattern_context_for(
                 t.text_range().start() == path.syntax().text_range().start()
             }
         })
-    })()
-    .unwrap_or(false)
+    })(
+    ).unwrap_or(
+        false,
+    )
 }
 
 fn is_in_breakable(node: &SyntaxNode) -> Option<(BreakableKind, SyntaxNode)> {
-    node.ancestors()
-        .take_while(|it| it.kind() != SyntaxKind::FN && it.kind() != SyntaxKind::CLOSURE_EXPR)
-        .find_map(|it| {
+    node.ancestors().take_while(
+        |it| it.kind() != SyntaxKind::FN && it.kind() != SyntaxKind::CLOSURE_EXPR,
+    ).find_map(|it| {
             let (breakable, loop_body) = match_ast! {
                 match it {
                     ast::ForExpr(it) => (BreakableKind::For, it.loop_body()?),
     if has_in_newline_expr_first(node) {
         return true;
     };
-    node.parent()
-        .map(|node| ast::ExprStmt::can_cast(node.kind()) || ast::StmtList::can_cast(node.kind()))
-        .unwrap_or(false)
+    node.parent().map(
+        |node| ast::ExprStmt::can_cast(node.kind()) || ast::StmtList::can_cast(node.kind()),
+    ).unwrap_or(
+        false,
+    )
 }
 
 /// Similar to `has_parens`, heuristic sensing incomplete statement before ambiguous `Expr`
 /// If the `PathExpr` is left part of the `Expr` and there is a newline after the `PathExpr`,
 /// it is considered that the `PathExpr` is not part of the `Expr`.
 fn has_in_newline_expr_first(node: &SyntaxNode) -> bool {
-    if ast::PathExpr::can_cast(node.kind())
-        && let Some(NodeOrToken::Token(next)) = node.next_sibling_or_token()
-        && next.kind() == SyntaxKind::WHITESPACE
-        && next.text().contains('\n')
-        && let Some(stmt_like) = node
-            .ancestors()
-            .take_while(|it| it.text_range().start() == node.text_range().start())
-            .filter_map(Either::<ast::ExprStmt, ast::Expr>::cast)
-            .last()
-    {
+    if ast::PathExpr::can_cast(node.kind()) && let Some(NodeOrToken::Token(next)) = node.next_sibling_or_token() && next.kind() == SyntaxKind::WHITESPACE && next.text().contains('\n') && let Some(stmt_like) = node.ancestors().take_while(|it| it.text_range().start() == node.text_range().start()).filter_map(
+        Either::<ast::ExprStmt, ast::Expr>::cast,
+    ).last(
+    ) {
         stmt_like.syntax().parent().and_then(ast::StmtList::cast).is_some()
     } else {
         false
     };
     let prev_sibling =
         non_trivia_sibling(node.into(), Direction::Prev).and_then(NodeOrToken::into_node);
-    iter::successors(prev_sibling, |it| it.last_child_or_token()?.into_node())
-        .find_map(ast::IfExpr::cast)
-        .is_some()
+    iter::successors(prev_sibling, |it| it.last_child_or_token()?.into_node()).find_map(
+        ast::IfExpr::cast,
+    ).is_some(
+    )
 }
 
 fn next_non_trivia_token(e: impl Into<SyntaxElement>) -> Option<SyntaxToken> {
COMPARISON DIFF
============================================================

Original size: 167117 bytes
Chloro size:   166047 bytes
Rustfmt size:  167117 bytes

âœ— Outputs DIFFER

=== DIFF (- rustfmt, + chloro) ===
 //! Config used by the language server.
 //!
 //! Of particular interest is the `feature_flags` hash map: while other fields
 //! configure the server itself, feature flags are passed into analysis, and
 //! tweak things like automatic insertion of `()` in completions.
+
+mod patch_old_style;
+
 use std::{env, fmt, iter, ops::Not, sync::OnceLock};
 
 use cfg::{CfgAtom, CfgDiff};
     MemoryLayoutHoverRenderKind, RenameConfig, Snippet, SnippetScope, SourceRootId,
 };
 use ide_db::{
-    MiniCore, SnippetCap,
     assists::ExprFillDefaultMode,
     imports::insert_use::{ImportGranularity, InsertUseConfig, PrefixKind},
+    MiniCore, SnippetCap,
 };
 use itertools::{Either, Itertools};
 use paths::{Utf8Path, Utf8PathBuf};
 use rustc_hash::{FxHashMap, FxHashSet};
 use semver::Version;
 use serde::{
-    Deserialize, Serialize,
     de::{DeserializeOwned, Error},
+    Deserialize, Serialize,
 };
 use stdx::format_to_acc;
 use triomphe::Arc;
 use vfs::{AbsPath, AbsPathBuf, VfsPath};
+use _config_data as config_data;
+use _default_str as default_str;
+use _default_val as default_val;
+use _impl_for_config_data as impl_for_config_data;
 
 use crate::{
     diagnostics::DiagnosticsMapConfig,
 
 type FxIndexMap<K, V> = indexmap::IndexMap<K, V, rustc_hash::FxBuildHasher>;
 
-mod patch_old_style;
-
 // Conventions for configuration keys to preserve maximal extendability without breakage:
-//  - Toggles (be it binary true/false or with more options in-between) should almost always suffix as `_enable`
-//    This has the benefit of namespaces being extensible, and if the suffix doesn't fit later it can be changed without breakage.
-//  - In general be wary of using the namespace of something verbatim, it prevents us from adding subkeys in the future
-//  - Don't use abbreviations unless really necessary
-//  - foo_command = overrides the subcommand, foo_overrideCommand allows full overwriting, extra args only applies for foo_command
 
+//  - Toggles (be it binary true/false or with more options in-between) should almost always suffix as `_enable`
+
+//    This has the benefit of namespaces being extensible, and if the suffix doesn't fit later it can be changed without breakage.
+
+//  - In general be wary of using the namespace of something verbatim, it prevents us from adding subkeys in the future
+
+//  - Don't use abbreviations unless really necessary
+
+//  - foo_command = overrides the subcommand, foo_overrideCommand allows full overwriting, extra args only applies for foo_command
 #[derive(Debug, Clone, Copy, Serialize, Deserialize)]
 #[serde(rename_all = "camelCase")]
 pub enum MaxSubstitutionLength {
     Limit(usize),
 }
 
-// Defines the server-side configuration of the rust-analyzer. We generate *parts* of VS Code's
-// `package.json` config from this. Run `cargo test` to re-generate that file.
-//
-// However, editor specific config, which the server doesn't know about, should be specified
-// directly in `package.json`.
-//
-// To deprecate an option by replacing it with another name use `new_name` | `old_name` so that we
-// keep parsing the old name.
 config_data! {
     /// Configs that apply on a workspace-wide scope. There are 2 levels on which a global
     /// configuration can be configured
     root_path: AbsPathBuf,
     snippets: Vec<Snippet>,
     client_info: Option<ClientInfo>,
-
     default_config: &'static DefaultConfigData,
     /// Config node that obtains its initial value during the server initialization and
     /// by receiving a `lsp_types::notification::DidChangeConfiguration`.
     client_config: (FullConfigInput, ConfigErrors),
-
     /// Config node whose values apply to **every** Rust project.
     user_config: Option<(GlobalWorkspaceLocalConfigInput, ConfigErrors)>,
-
     ratoml_file: FxHashMap<SourceRootId, (RatomlFile, ConfigErrors)>,
-
     /// Clone of the value that is stored inside a `GlobalState`.
     source_root_parent_map: Arc<FxHashMap<SourceRootId, SourceRootId>>,
-
     /// Use case : It is an error to have an empty value for `check_command`.
     /// Since it is a `global` command at the moment, its final value can only be determined by
     /// traversing through `global` configs and the `client` config. However the non-null value constraint
     /// is config level agnostic, so this requires an independent error storage
     validation_errors: ConfigErrors,
-
     detached_files: Vec<AbsPathBuf>,
 }
 
 impl fmt::Debug for Config {
     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
-        f.debug_struct("Config")
-            .field("discovered_projects_from_filesystem", &self.discovered_projects_from_filesystem)
-            .field("discovered_projects_from_command", &self.discovered_projects_from_command)
-            .field("workspace_roots", &self.workspace_roots)
-            .field("caps", &self.caps)
-            .field("root_path", &self.root_path)
-            .field("snippets", &self.snippets)
-            .field("client_info", &self.client_info)
-            .field("client_config", &self.client_config)
-            .field("user_config", &self.user_config)
-            .field("ratoml_file", &self.ratoml_file)
-            .field("source_root_parent_map", &self.source_root_parent_map)
-            .field("validation_errors", &self.validation_errors)
-            .field("detached_files", &self.detached_files)
-            .finish()
+        f.debug_struct("Config").field(
+            "discovered_projects_from_filesystem",
+            &self.discovered_projects_from_filesystem,
+        ).field(
+            "discovered_projects_from_command",
+            &self.discovered_projects_from_command,
+        ).field(
+            "workspace_roots",
+            &self.workspace_roots,
+        ).field(
+            "caps",
+            &self.caps,
+        ).field(
+            "root_path",
+            &self.root_path,
+        ).field(
+            "snippets",
+            &self.snippets,
+        ).field(
+            "client_info",
+            &self.client_info,
+        ).field(
+            "client_config",
+            &self.client_config,
+        ).field(
+            "user_config",
+            &self.user_config,
+        ).field(
+            "ratoml_file",
+            &self.ratoml_file,
+        ).field(
+            "source_root_parent_map",
+            &self.source_root_parent_map,
+        ).field(
+            "validation_errors",
+            &self.validation_errors,
+        ).field(
+            "detached_files",
+            &self.detached_files,
+        ).finish(
+        )
     }
 }
 
-// Delegate capability fetching methods
 impl std::ops::Deref for Config {
     type Target = ClientCapabilities;
 
         Arc::ptr_eq(&self.source_root_parent_map, other)
     }
 
-    // FIXME @alibektas : Server's health uses error sink but in other places it is not used atm.
     /// Changes made to client and global configurations will partially not be reflected even after `.apply_change()` was called.
     /// The return tuple's bool component signals whether the `GlobalState` should call its `update_configuration()` method.
     fn apply_change_with_sink(&self, change: ConfigChange) -> (Config, bool) {
 pub struct ConfigChange {
     user_config_change: Option<Arc<str>>,
     client_config_change: Option<serde_json::Value>,
-    ratoml_file_change:
-        Option<FxHashMap<SourceRootId, (RatomlFileKind, VfsPath, Option<Arc<str>>)>>,
+    ratoml_file_change: Option<FxHashMap<SourceRootId, (RatomlFileKind, VfsPath, Option<Arc<str>>)>>,
     source_map_change: Option<Arc<FxHashMap<SourceRootId, SourceRootId>>>,
 }
 
         vfs_path: VfsPath,
         content: Option<Arc<str>>,
     ) -> Option<(RatomlFileKind, VfsPath, Option<Arc<str>>)> {
-        self.ratoml_file_change
-            .get_or_insert_with(Default::default)
-            .insert(source_root, (RatomlFileKind::Crate, vfs_path, content))
+        self.ratoml_file_change.get_or_insert_with(Default::default).insert(
+            source_root,
+            (RatomlFileKind::Crate, vfs_path, content),
+        )
     }
 
     pub fn change_user_config(&mut self, content: Option<Arc<str>>) {
-        assert!(self.user_config_change.is_none()); // Otherwise it is a double write.
+        assert!(self.user_config_change.is_none());
+        // Otherwise it is a double write.
         self.user_config_change = content;
     }
 
         vfs_path: VfsPath,
         content: Option<Arc<str>>,
     ) -> Option<(RatomlFileKind, VfsPath, Option<Arc<str>>)> {
-        self.ratoml_file_change
-            .get_or_insert_with(Default::default)
-            .insert(source_root, (RatomlFileKind::Workspace, vfs_path, content))
+        self.ratoml_file_change.get_or_insert_with(Default::default).insert(
+            source_root,
+            (RatomlFileKind::Workspace, vfs_path, content),
+        )
     }
 
     pub fn change_client_config(&mut self, change: serde_json::Value) {
     pub debug: bool,
     pub update_test: bool,
     pub interpret: bool,
-
     // implementations
     pub implementations: bool,
-
     // references
     pub method_refs: bool,
-    pub refs_adt: bool,   // for Struct, Enum, Union and Trait
-    pub refs_trait: bool, // for Struct, Enum, Union and Trait
+    pub refs_adt: bool,
+    // for Struct, Enum, Union and Trait
+    pub refs_trait: bool,
+    // for Struct, Enum, Union and Trait
     pub enum_variant_refs: bool,
-
     // annotations
     pub location: AnnotationLocation,
     pub filter_adjacent_derive_implementations: bool,
 
 impl LensConfig {
     pub fn any(&self) -> bool {
-        self.run
-            || self.debug
-            || self.update_test
-            || self.implementations
-            || self.method_refs
-            || self.refs_adt
-            || self.refs_trait
-            || self.enum_variant_refs
+        self.run || self.debug || self.update_test || self.implementations || self.method_refs || self.refs_adt || self.refs_trait || self.enum_variant_refs
     }
 
     pub fn none(&self) -> bool {
 
 #[derive(Debug, Clone)]
 pub enum RustfmtConfig {
-    Rustfmt { extra_args: Vec<String>, enable_range_formatting: bool },
-    CustomCommand { command: String, args: Vec<String> },
+    Rustfmt {
+        extra_args: Vec<String>,
+        enable_range_formatting: bool,
+    },
+    CustomCommand {
+        command: String,
+        args: Vec<String>,
+    },
 }
 
 /// Configuration for runnable items, such as `main` function or tests.
     /// How many items are returned at most.
     pub search_limit: usize,
 }
+
 #[derive(Debug, Clone, Copy, PartialEq, Eq)]
 pub struct ClientCommandsConfig {
     pub run_single: bool,
 
 #[derive(Debug)]
 pub enum ConfigErrorInner {
-    Json { config_key: String, error: serde_json::Error },
-    Toml { config_key: String, error: toml::de::Error },
-    ParseError { reason: String },
+    Json {
+        config_key: String,
+        error: serde_json::Error,
+    },
+    Toml {
+        config_key: String,
+        error: toml::de::Error,
+    },
+    ParseError {
+        reason: String,
+    },
 }
 
 #[derive(Clone, Debug, Default)]
     }
 }
 
-impl std::error::Error for ConfigErrors {}
+impl std::error::Error for ConfigErrors {
+}
 
 impl Config {
     pub fn new(
         DiagnosticsConfig {
             enabled: true,
             disable_experimental: false,
-            ..self.diagnostics(source_root)
         }
     }
 
             references: enable && self.hover_actions_references_enable().to_owned(),
             run: enable && self.hover_actions_run_enable().to_owned(),
             debug: enable && self.hover_actions_debug_enable().to_owned(),
-            update_test: enable
-                && self.hover_actions_run_enable().to_owned()
-                && self.hover_actions_updateTest_enable().to_owned(),
+            update_test: enable && self.hover_actions_run_enable().to_owned() && self.hover_actions_updateTest_enable().to_owned(),
             goto_type_def: enable && self.hover_actions_gotoTypeDef_enable().to_owned(),
         }
     }
             granularity: match self.imports_granularity_group(source_root) {
                 ImportGranularityDef::Item | ImportGranularityDef::Preserve => {
                     ImportGranularity::Item
-                }
+                },
                 ImportGranularityDef::Crate => ImportGranularity::Crate,
                 ImportGranularityDef::Module => ImportGranularity::Module,
                 ImportGranularityDef::One => ImportGranularity::One,
     pub fn linked_manifests(&self) -> impl Iterator<Item = &Utf8Path> + '_ {
         self.linkedProjects().iter().filter_map(|it| match it {
             ManifestOrProjectJson::Manifest(p) => Some(&**p),
-            // despite having a buildfile, using this variant as a manifest
-            // will fail.
             ManifestOrProjectJson::DiscoveredProjectJson { .. } => None,
             ManifestOrProjectJson::ProjectJson { .. } => None,
         })
     }
 
     pub fn has_linked_project_jsons(&self) -> bool {
-        self.linkedProjects()
-            .iter()
-            .any(|it| matches!(it, ManifestOrProjectJson::ProjectJson { .. }))
+        self.linkedProjects().iter().any(
+            |it| matches!(it, ManifestOrProjectJson::ProjectJson { .. }),
+        )
     }
 
     pub fn discover_workspace_config(&self) -> Option<&DiscoverWorkspaceConfig> {
             linked_projects.clone()
         };
 
-        projects
-            .iter()
-            .filter_map(|linked_project| match linked_project {
-                ManifestOrProjectJson::Manifest(it) => {
-                    let path = self.root_path.join(it);
-                    ProjectManifest::from_manifest_file(path)
-                        .map_err(|e| tracing::error!("failed to load linked project: {}", e))
-                        .ok()
-                        .map(Into::into)
-                }
-                ManifestOrProjectJson::DiscoveredProjectJson { data, buildfile } => {
-                    let root_path = buildfile.parent().expect("Unable to get parent of buildfile");
-
-                    Some(ProjectJson::new(None, root_path, data.clone()).into())
-                }
-                ManifestOrProjectJson::ProjectJson(it) => {
-                    Some(ProjectJson::new(None, &self.root_path, it.clone()).into())
-                }
-            })
-            .collect()
+        projects.iter().filter_map(|linked_project| match linked_project {
+            ManifestOrProjectJson::Manifest(it) => {
+                let path = self.root_path.join(it);
+                ProjectManifest::from_manifest_file(path).map_err(
+                    |e| tracing::error!("failed to load linked project: {}", e),
+                ).ok(
+                ).map(
+                    Into::into,
+                )
+            },
+            ManifestOrProjectJson::DiscoveredProjectJson { data, buildfile } => {
+                let root_path = buildfile.parent().expect("Unable to get parent of buildfile");
+                Some(ProjectJson::new(None, root_path, data.clone()).into())
+            },
+            ManifestOrProjectJson::ProjectJson(it) => {
+                Some(ProjectJson::new(None, &self.root_path, it.clone()).into())
+            },
+        }).collect(
+        )
     }
 
     pub fn prefill_caches(&self) -> bool {
             watcher: match self.files_watcher() {
                 FilesWatcherDef::Client if self.did_change_watched_files_dynamic_registration() => {
                     FilesWatcher::Client
-                }
+                },
                 _ => FilesWatcher::Server,
             },
             exclude: self.excluded().collect(),
     }
 
     pub(crate) fn completion_snippets_default() -> FxIndexMap<String, SnippetDef> {
-        serde_json::from_str(
-            r#"{
+        serde_json::from_str(r#"{
             "Ok": {
                 "postfix": "ok",
                 "body": "Ok(${receiver})",
                 "description": "Put the expression into an `Rc`",
                 "scope": "expr"
             }
-        }"#,
+        }"#).unwrap(
         )
-        .unwrap()
     }
 
     pub fn rustfmt(&self, source_root_id: Option<SourceRootId>) -> RustfmtConfig {
                 let mut args = args.clone();
                 let command = args.remove(0);
                 RustfmtConfig::CustomCommand { command, args }
-            }
+            },
             Some(_) | None => RustfmtConfig::Rustfmt {
                 extra_args: self.rustfmt_extraArgs(source_root_id).clone(),
                 enable_range_formatting: *self.rustfmt_rangeFormatting_enable(source_root_id),
                         }
                     },
                 }
-            }
+            },
             Some(_) | None => FlycheckConfig::CargoCommand {
                 command: self.check_command(source_root).clone(),
                 options: CargoOptions {
-                    target_tuples: self
-                        .check_targets(source_root)
-                        .clone()
-                        .and_then(|targets| match &targets.0[..] {
-                            [] => None,
-                            targets => Some(targets.into()),
-                        })
-                        .unwrap_or_else(|| {
-                            self.cargo_target(source_root).clone().into_iter().collect()
-                        }),
-                    all_targets: self
-                        .check_allTargets(source_root)
-                        .unwrap_or(*self.cargo_allTargets(source_root)),
-                    no_default_features: self
-                        .check_noDefaultFeatures(source_root)
-                        .unwrap_or(*self.cargo_noDefaultFeatures(source_root)),
+                    target_tuples: self.check_targets(source_root).clone().and_then(|targets| match &targets.0[..] {
+                        [] => None,
+                        targets => Some(targets.into()),
+                    }).unwrap_or_else(|| {
+                        self.cargo_target(source_root).clone().into_iter().collect()
+                    }),
+                    all_targets: self.check_allTargets(source_root).unwrap_or(
+                        *self.cargo_allTargets(source_root),
+                    ),
+                    no_default_features: self.check_noDefaultFeatures(source_root).unwrap_or(
+                        *self.cargo_noDefaultFeatures(source_root),
+                    ),
                     all_features: matches!(
                         self.check_features(source_root)
                             .as_ref()
                             .unwrap_or(self.cargo_features(source_root)),
                         CargoFeaturesDef::All
                     ),
-                    features: match self
-                        .check_features(source_root)
-                        .clone()
-                        .unwrap_or_else(|| self.cargo_features(source_root).clone())
-                    {
+                    features: match self.check_features(source_root).clone().unwrap_or_else(
+                        || self.cargo_features(source_root).clone(),
+                    ) {
                         CargoFeaturesDef::All => vec![],
                         CargoFeaturesDef::Selected(it) => it,
                     },
         LensConfig {
             run: *self.lens_enable() && *self.lens_run_enable(),
             debug: *self.lens_enable() && *self.lens_debug_enable(),
-            update_test: *self.lens_enable()
-                && *self.lens_updateTest_enable()
-                && *self.lens_run_enable(),
+            update_test: *self.lens_enable() && *self.lens_updateTest_enable() && *self.lens_run_enable(),
             interpret: *self.lens_enable() && *self.lens_run_enable() && *self.interpret_tests(),
             implementations: *self.lens_enable() && *self.lens_implementations_enable(),
             method_refs: *self.lens_enable() && *self.lens_references_method_enable(),
             refs_trait: *self.lens_enable() && *self.lens_references_trait_enable(),
             enum_variant_refs: *self.lens_enable() && *self.lens_references_enumVariant_enable(),
             location: *self.lens_location(),
-            filter_adjacent_derive_implementations: *self
-                .gotoImplementations_filterAdjacentDerives(),
+            filter_adjacent_derive_implementations: *self.gotoImplementations_filterAdjacentDerives(),
         }
     }
 
                 WorkspaceSymbolSearchScopeDef::Workspace => WorkspaceSymbolSearchScope::Workspace,
                 WorkspaceSymbolSearchScopeDef::WorkspaceAndDependencies => {
                     WorkspaceSymbolSearchScope::WorkspaceAndDependencies
-                }
+                },
             },
             search_kind: match self.workspace_symbol_search_kind(source_root) {
                 WorkspaceSymbolSearchKindDef::OnlyTypes => WorkspaceSymbolSearchKind::OnlyTypes,
         match self.numThreads() {
             Some(NumThreads::Concrete(0)) | None | Some(NumThreads::Physical) => {
                 num_cpus::get_physical()
-            }
+            },
             &Some(NumThreads::Concrete(n)) => n,
             Some(NumThreads::Logical) => num_cpus::get(),
         }
         self.typing_triggerChars().as_deref().unwrap_or_default()
     }
 
-    // VSCode is our reference implementation, so we allow ourselves to work around issues by
-    // special casing certain versions
     pub fn visual_studio_code_version(&self) -> Option<&Version> {
-        self.client_info
-            .as_ref()
-            .filter(|it| it.name.starts_with("Visual Studio Code"))
-            .and_then(|it| it.version.as_ref())
+        self.client_info.as_ref().filter(|it| it.name.starts_with("Visual Studio Code")).and_then(
+            |it| it.version.as_ref(),
+        )
     }
 
     pub fn client_is_neovim(&self) -> bool {
         self.client_info.as_ref().map(|it| it.name == "Neovim").unwrap_or_default()
     }
 }
-// Deserialization definitions
 
+// Deserialization definitions
 macro_rules! create_bool_or_string_serde {
     ($ident:ident<$bool:literal, $string:literal>) => {
         mod $ident {
         }
     };
 }
+
 create_bool_or_string_serde!(true_or_always<true, "always">);
+
 create_bool_or_string_serde!(false_or_never<false, "never">);
 
 #[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq)]
     #[serde(with = "single_or_array")]
     #[serde(skip_serializing_if = "Vec::is_empty")]
     prefix: Vec<String>,
-
     #[serde(with = "single_or_array")]
     #[serde(skip_serializing_if = "Vec::is_empty")]
     postfix: Vec<String>,
-
     #[serde(with = "single_or_array")]
     #[serde(skip_serializing_if = "Vec::is_empty")]
     body: Vec<String>,
-
     #[serde(with = "single_or_array")]
     #[serde(skip_serializing_if = "Vec::is_empty")]
     requires: Vec<String>,
-
     #[serde(skip_serializing_if = "Option::is_none")]
     description: Option<String>,
-
     scope: SnippetScopeDef,
 }
 
 mod single_or_array {
     use serde::{Deserialize, Serialize};
-
     pub(super) fn deserialize<'de, D>(deserializer: D) -> Result<Vec<String>, D::Error>
     where
         D: serde::Deserializer<'de>,
 
         deserializer.deserialize_any(SingleOrVec)
     }
-
     pub(super) fn serialize<S>(vec: &[String], serializer: S) -> Result<S::Ok, S::Error>
     where
         S: serde::Serializer,
     {
         match vec {
-            // []  case is handled by skip_serializing_if
             [single] => serializer.serialize_str(single),
             slice => slice.serialize(serializer),
         }
 {
     let path = String::deserialize(de)?;
 
-    AbsPathBuf::try_from(path.as_ref())
-        .map_err(|err| serde::de::Error::custom(format!("invalid path name: {err:?}")))
+    AbsPathBuf::try_from(path.as_ref()).map_err(
+        |err| serde::de::Error::custom(format!("invalid path name: {err:?}")),
+    )
 }
 
 fn serialize_abs_pathbuf<S>(path: &AbsPathBuf, se: S) -> Result<S::Ok, S::Error>
 #[serde(rename_all = "snake_case")]
 pub enum AutoImportExclusion {
     Path(String),
-    Verbose { path: String, r#type: AutoImportExclusionType },
+    Verbose {
+        path: String,
+        r#type: AutoImportExclusionType,
+    },
 }
 
 #[derive(Serialize, Deserialize, Debug, Clone)]
 }
 
 #[derive(Serialize, Deserialize, Debug, Clone)]
-struct CheckOnSaveTargets(#[serde(with = "single_or_array")] Vec<String>);
+struct CheckOnSaveTargets(Vec<String>);
 
 #[derive(Serialize, Deserialize, Debug, Clone)]
 #[serde(rename_all = "snake_case")]
         default_
     }};
 }
-use _default_val as default_val;
 
 macro_rules! _default_str {
     ($default:expr, $ty:ty) => {{
         serde_json::to_string_pretty(&val).unwrap()
     }};
 }
-use _default_str as default_str;
 
 macro_rules! _impl_for_config_data {
     (local, $(
         }
     };
 }
-use _impl_for_config_data as impl_for_config_data;
 
 macro_rules! _config_data {
     // modname is for the tests
         }
     };
 }
-use _config_data as config_data;
 
 #[derive(Default, Debug, Clone)]
 struct DefaultConfigData {
 }
 
 impl GlobalWorkspaceLocalConfigInput {
-    const FIELDS: &'static [&'static [&'static str]] =
-        &[GlobalConfigInput::FIELDS, LocalConfigInput::FIELDS];
+    const FIELDS: &'static [&'static [&'static str]] = &[GlobalConfigInput::FIELDS, LocalConfigInput::FIELDS];
+
     fn from_toml(
         toml: toml::Table,
         error_sink: &mut Vec<(String, toml::de::Error)>,
 
 impl WorkspaceLocalConfigInput {
     #[allow(dead_code)]
-    const FIELDS: &'static [&'static [&'static str]] =
-        &[WorkspaceConfigInput::FIELDS, LocalConfigInput::FIELDS];
+    const FIELDS: &'static [&'static [&'static str]] = &[WorkspaceConfigInput::FIELDS, LocalConfigInput::FIELDS];
+
     fn from_toml(toml: toml::Table, error_sink: &mut Vec<(String, toml::de::Error)>) -> Self {
         Self {
             workspace: WorkspaceConfigInput::from_toml(&toml, error_sink),
 ) -> Option<T> {
     // XXX: check alias first, to work around the VS Code where it pre-fills the
     // defaults instead of sending an empty object.
-    alias
-        .into_iter()
-        .chain(iter::once(field))
-        .filter_map(move |field| {
-            let mut pointer = field.replace('_', "/");
-            pointer.insert(0, '/');
-            json.pointer_mut(&pointer)
-                .map(|it| serde_json::from_value(it.take()).map_err(|e| (e, pointer)))
-        })
-        .flat_map(|res| match res {
-            Ok(it) => Some(it),
-            Err((e, pointer)) => {
-                tracing::warn!("Failed to deserialize config field at {}: {:?}", pointer, e);
-                error_sink.push((pointer, e));
-                None
-            }
-        })
-        .next()
+    alias.into_iter().chain(iter::once(field)).filter_map(move |field| {
+        let mut pointer = field.replace('_', "/");
+        pointer.insert(0, '/');
+        json.pointer_mut(&pointer).map(
+            |it| serde_json::from_value(it.take()).map_err(|e| (e, pointer)),
+        )
+    }).flat_map(|res| match res {
+        Ok(it) => Some(it),
+        Err((e, pointer)) => {
+            tracing::warn!("Failed to deserialize config field at {}: {:?}", pointer, e);
+            error_sink.push((pointer, e));
+            None
+        },
+    }).next(
+    )
 }
 
 fn get_field_toml<T: DeserializeOwned>(
 ) -> Option<T> {
     // XXX: check alias first, to work around the VS Code where it pre-fills the
     // defaults instead of sending an empty object.
-    alias
-        .into_iter()
-        .chain(iter::once(field))
-        .filter_map(move |field| {
-            let mut pointer = field.replace('_', "/");
-            pointer.insert(0, '/');
-            toml_pointer(toml, &pointer)
-                .map(|it| <_>::deserialize(it.clone()).map_err(|e| (e, pointer)))
-        })
-        .find(Result::is_ok)
-        .and_then(|res| match res {
-            Ok(it) => Some(it),
-            Err((e, pointer)) => {
-                tracing::warn!("Failed to deserialize config field at {}: {:?}", pointer, e);
-                error_sink.push((pointer, e));
-                None
-            }
-        })
+    alias.into_iter().chain(iter::once(field)).filter_map(move |field| {
+        let mut pointer = field.replace('_', "/");
+        pointer.insert(0, '/');
+        toml_pointer(toml, &pointer).map(
+            |it| <_>::deserialize(it.clone()).map_err(|e| (e, pointer)),
+        )
+    }).find(
+        Result::is_ok,
+    ).and_then(|res| match res {
+        Ok(it) => Some(it),
+        Err((e, pointer)) => {
+            tracing::warn!("Failed to deserialize config field at {}: {:?}", pointer, e);
+            error_sink.push((pointer, e));
+            None
+        },
+    })
 }
 
 fn toml_pointer<'a>(toml: &'a toml::Table, pointer: &str) -> Option<&'a toml::Value> {
     let mut parts = pointer.split('/').skip(1);
     let first = parts.next()?;
     let init = toml.get(first)?;
-    parts.map(|x| x.replace("~1", "/").replace("~0", "~")).try_fold(init, |target, token| {
+    parts.map(|x| x.replace("~1", "/").replace("~0", "~")).try_fold(
+        init,
+        |target, token| {
         match target {
             toml::Value::Table(table) => table.get(&token),
             toml::Value::Array(list) => parse_index(&token).and_then(move |x| list.get(x)),
             _ => None,
         }
-    })
+    },
+    )
 }
 
 type SchemaField = (&'static str, &'static str, &'static [&'static str], String);
             ptr.push('_');
         }
         ptr.push_str(k);
-
         match v {
             // This is a table config, any entry in it is therefore valid
             toml::Value::Table(_) if verify(ptr) => (),
                 .push((ptr.replace('_', "/"), toml::de::Error::custom("unexpected field"))),
             _ => (),
         }
-
         ptr.truncate(l);
     }
 }
 
 #[cfg(test)]
 fn manual(fields: &[SchemaField]) -> String {
-    fields.iter().fold(String::new(), |mut acc, (field, _ty, doc, default)| {
+    fields.iter().fold(
+        String::new(),
+        |mut acc, (field, _ty, doc, default)| {
         let id = field.replace('_', ".");
         let name = format!("rust-analyzer.{id}");
         let doc = doc_comment_to_string(doc);
         } else {
             format_to_acc!(acc, "## {name} {{#{id}}}\n\nDefault: `{default}`\n\n{doc}\n\n")
         }
-    })
+    },
+    )
 }
 
 fn doc_comment_to_string(doc: &[&str]) -> String {
-    doc.iter()
-        .map(|it| it.strip_prefix(' ').unwrap_or(it))
-        .fold(String::new(), |mut acc, it| format_to_acc!(acc, "{it}\n"))
+    doc.iter().map(|it| it.strip_prefix(' ').unwrap_or(it)).fold(
+        String::new(),
+        |mut acc, it| format_to_acc!(acc, "{it}\n"),
+    )
 }
 
 #[cfg(test)]
 mod tests {
     use std::{borrow::Cow, fs};
-
     use test_utils::{ensure_file_contents, project_root};
-
     use super::*;
-
     #[test]
     fn generate_package_json_config() {
         let s = Config::json_schema();
         schema.push_str(",\n");
 
         // Transform the asciidoc form link to markdown style.
+
         //
+
         // https://link[text] => [text](https://link)
         let url_matches = schema.match_indices("https://");
         let mut url_offsets = url_matches.map(|(idx, _)| idx).collect::<Vec<usize>>();
             ensure_file_contents(package_json_path.as_std_path(), &package_json)
         }
     }
-
     #[test]
     fn generate_config_documentation() {
         let docs_path = project_root().join("docs/book/src/configuration_generated.md");
         let expected = FullConfigInput::manual();
         ensure_file_contents(docs_path.as_std_path(), &expected);
     }
-
     fn remove_ws(text: &str) -> String {
         text.replace(char::is_whitespace, "")
     }
-
     #[test]
     fn proc_macro_srv_null() {
         let mut config =
         (config, _, _) = config.apply_change(change);
         assert_eq!(config.proc_macro_srv(), None);
     }
-
     #[test]
     fn proc_macro_srv_abs() {
         let mut config =
         (config, _, _) = config.apply_change(change);
         assert_eq!(config.proc_macro_srv(), Some(AbsPathBuf::assert(project_root())));
     }
-
     #[test]
     fn proc_macro_srv_rel() {
         let mut config =
             Some(AbsPathBuf::try_from(project_root().join("./server")).unwrap())
         );
     }
-
     #[test]
     fn cargo_target_dir_unset() {
         let mut config =
             }
         ));
     }
-
     #[test]
     fn cargo_target_dir_subdir() {
         let mut config =
                 == Some(ws_target_dir.join("rust-analyzer"))
         ));
     }
-
     #[test]
     fn cargo_target_dir_relative_dir() {
         let mut config =
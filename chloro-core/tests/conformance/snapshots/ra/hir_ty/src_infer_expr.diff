COMPARISON DIFF
============================================================

Original size: 111676 bytes
Chloro size:   110153 bytes
Rustfmt size:  111676 bytes

âœ— Outputs DIFFER

=== DIFF (- rustfmt, + chloro) ===
 use either::Either;
 use hir_def::hir::ClosureKind;
 use hir_def::{
-    BlockId, FieldId, GenericDefId, GenericParamId, ItemContainerId, Lookup, TupleFieldId, TupleId,
     expr_store::path::{GenericArg as HirGenericArg, GenericArgs as HirGenericArgs, Path},
     hir::{
-        ArithOp, Array, AsmOperand, AsmOptions, BinaryOp, Expr, ExprId, ExprOrPatId, LabelId,
-        Literal, Pat, PatId, Statement, UnaryOp, generics::GenericParamDataRef,
+        generics::GenericParamDataRef, ArithOp, Array, AsmOperand, AsmOptions, BinaryOp, Expr,
+        ExprId, ExprOrPatId, LabelId, Literal, Pat, PatId, Statement, UnaryOp,
     },
     lang_item::{LangItem, LangItemTarget},
     resolver::ValueNs,
+    BlockId, FieldId, GenericDefId, GenericParamId, ItemContainerId, Lookup, TupleFieldId, TupleId,
 };
 use hir_expand::name::Name;
 use intern::sym;
 use rustc_ast_ir::Mutability;
 use rustc_type_ir::{
-    CoroutineArgs, CoroutineArgsParts, InferTy, Interner,
     inherent::{AdtDef, GenericArgs as _, IntoKind, SliceLike, Ty as _},
+    CoroutineArgs, CoroutineArgsParts, InferTy, Interner,
 };
 use syntax::ast::RangeOp;
 use tracing::debug;
 
 use crate::{
-    Adjust, Adjustment, AutoBorrow, CallableDefId, DeclContext, DeclOrigin,
-    IncorrectGenericsLenKind, Rawness, TraitEnvironment,
     autoderef::overloaded_deref_ty,
     consteval,
     db::InternedCoroutine,
     generics::generics,
     infer::{
+        coerce::{CoerceMany, CoerceNever}, find_continuable, pat::contains_explicit_ref_binding,
         AllowTwoPhase, BreakableKind,
-        coerce::{CoerceMany, CoerceNever},
-        find_continuable,
-        pat::contains_explicit_ref_binding,
     },
     lang_items::lang_items_for_bin_op,
     lower::{
-        LifetimeElisionKind, lower_mutability,
+        lower_mutability,
         path::{GenericArgsLowerer, TypeLikeConst, substs_from_args_and_bindings},
+        LifetimeElisionKind,
     },
     method_resolution::{self, VisibleFromModule},
     next_solver::{
-        Const, DbInterner, ErrorGuaranteed, GenericArg, GenericArgs, TraitRef, Ty, TyKind,
-        TypeError,
         infer::{
             InferOk,
             traits::{Obligation, ObligationCause},
         },
-        obligation_ctxt::ObligationCtxt,
+        obligation_ctxt::ObligationCtxt, Const, DbInterner, ErrorGuaranteed, GenericArg,
+        GenericArgs, TraitRef, Ty, TyKind, TypeError,
     },
     traits::FnTrait,
+    Adjust, Adjustment, AutoBorrow, CallableDefId, DeclContext, DeclOrigin,
+    IncorrectGenericsLenKind, Rawness, TraitEnvironment,
 };
-
 use super::{
-    BreakableContext, Diverges, Expectation, InferenceContext, InferenceDiagnostic, TypeMismatch,
-    cast::CastCheck, find_breakable,
+    cast::CastCheck, find_breakable, BreakableContext, Diverges, Expectation, InferenceContext,
+    InferenceDiagnostic, TypeMismatch,
 };
 
 #[derive(Clone, Copy, PartialEq, Eq)]
         }
 
         // We only care about place exprs. Anything else returns an immediate
+
         // which would constitute a read. We don't care about distinguishing
+
         // "syntactic" place exprs since if the base of a field projection is
+
         // not a place then it would've been UB to read from it anyways since
+
         // that constitutes a read.
         if !self.is_syntactic_place_expr(expr) {
             return true;
         }
 
         // rustc queries parent hir node of `expr` here and determine whether
+
         // the current `expr` is read of value per its parent.
+
         // But since we don't have hir node, we cannot follow such "bottom-up"
+
         // method.
+
         // So, we pass down such readness from the parent expression through the
+
         // recursive `infer_expr*` calls in a "top-down" manner.
         is_read == ExprIsRead::Yes
     }
     /// perform `NeverToAny` coercions.
     fn pat_guaranteed_to_constitute_read_for_never(&self, pat: PatId) -> bool {
         match &self.body[pat] {
-            // Does not constitute a read.
             Pat::Wild => false,
-
-            // This is unnecessarily restrictive when the pattern that doesn't
-            // constitute a read is unreachable.
-            //
-            // For example `match *never_ptr { value => {}, _ => {} }` or
-            // `match *never_ptr { _ if false => {}, value => {} }`.
-            //
-            // It is however fine to be restrictive here; only returning `true`
-            // can lead to unsoundness.
             Pat::Or(subpats) => {
                 subpats.iter().all(|pat| self.pat_guaranteed_to_constitute_read_for_never(*pat))
             }
-
-            // All of these constitute a read, or match on something that isn't `!`,
-            // which would require a `NeverToAny` coercion.
             Pat::Bind { .. }
             | Pat::TupleStruct { .. }
             | Pat::Path(_)
 
     fn is_syntactic_place_expr(&self, expr: ExprId) -> bool {
         match &self.body[expr] {
-            // Lang item paths cannot currently be local variables or statics.
             Expr::Path(Path::LangItem(_, _)) => false,
             Expr::Path(Path::Normal(path)) => path.type_anchor.is_none(),
-            Expr::Path(path) => self
-                .resolver
-                .resolve_path_in_value_ns_fully(self.db, path, self.body.expr_path_hygiene(expr))
-                .is_none_or(|res| matches!(res, ValueNs::LocalBinding(_) | ValueNs::StaticId(_))),
+            Expr::Path(path) => self.resolver.resolve_path_in_value_ns_fully(
+                self.db,
+                path,
+                self.body.expr_path_hygiene(expr),
+            ).is_none_or(
+                |res| matches!(res, ValueNs::LocalBinding(_) | ValueNs::StaticId(_)),
+            ),
             Expr::Underscore => true,
             Expr::UnaryOp { op: UnaryOp::Deref, .. } => true,
             Expr::Field { .. } | Expr::Index { .. } => true,
                     self.err_ty()
                 };
             }
-
             if let Some(target) = expected.only_has_type(&mut self.table) {
-                self.coerce(expr.into(), ty, target, AllowTwoPhase::No, CoerceNever::Yes)
-                    .expect("never-to-any coercion should always succeed")
+                self.coerce(expr.into(), ty, target, AllowTwoPhase::No, CoerceNever::Yes).expect(
+                    "never-to-any coercion should always succeed",
+                )
             } else {
                 ty
             }
                     Expectation::rvalue_hint(self, g)
                 })
                 .unwrap_or_else(Expectation::none);
-
             let inner_ty = self.infer_expr_inner(inner_expr, &inner_exp, ExprIsRead::Yes);
             Ty::new_adt(
                 self.interner(),
                 box_id,
                 GenericArgs::fill_with_defaults(
-                    self.interner(),
-                    box_id.into(),
-                    [inner_ty.into()],
-                    |_, id, _| self.table.next_var_for_param(id),
-                ),
+                self.interner(),
+                box_id.into(),
+                [inner_ty.into()],
+                |_, id, _| self.table.next_var_for_param(id),
+            ),
             )
         } else {
             self.err_ty()
         };
 
         // HACK: We can use this substitution for the function because the function itself doesn't
+
         // have its own generic parameters.
         let args = GenericArgs::new_from_iter(self.interner(), [lhs_ty.into(), rhs_ty.into()]);
 
         let ret_ty = self.process_remote_user_written_ty(ret_ty);
 
         if self.is_builtin_binop(lhs_ty, rhs_ty, op) {
-            // use knowledge of built-in binary ops, which can sometimes help inference
             let builtin_ret = self.enforce_builtin_binop_types(lhs_ty, rhs_ty, op);
             self.unify(builtin_ret, ret_ty);
             builtin_ret
             Some((field_id, ty)) => {
                 let adjustments = autoderef.adjust_steps();
                 let ty = self.process_remote_user_written_ty(ty);
-
                 (ty, field_id, adjustments, true)
             }
             None => {
                 let ty = self.db.field_types(field_id.parent)[field_id.local_id]
                     .instantiate(self.interner(), subst);
                 let ty = self.process_remote_user_written_ty(ty);
-
                 (ty, Either::Left(field_id), adjustments, false)
             }
         })
                 ty
             }
             None => {
-                // no field found, lets attempt to resolve it like a function so that IDE things
-                // work out while people are typing
                 let canonicalized_receiver = self.canonicalize(receiver_ty);
                 let resolved = method_resolution::lookup_method(
                     &canonicalized_receiver,
                         let args = self.substs_for_method_call(tgt_expr, func.into(), None);
                         self.write_expr_adj(receiver, adjustments.into_boxed_slice());
                         self.write_method_resolution(tgt_expr, func, args);
-
                         self.check_method_call(
                             tgt_expr,
                             &[],
-                            self.db
-                                .value_ty(func.into())
-                                .unwrap()
-                                .instantiate(self.interner(), args),
+                            self.db.value_ty(func.into()).unwrap().instantiate(self.interner(), args),
                             ty,
                             expected,
                         )
                         item: func.into(),
                     })
                 }
-
                 let (ty, adjustments) = adjust.apply(&mut self.table, receiver_ty);
                 self.write_expr_adj(receiver, adjustments.into_boxed_slice());
-
                 let gen_args = self.substs_for_method_call(tgt_expr, func.into(), generic_args);
                 self.write_method_resolution(tgt_expr, func, gen_args);
                 let interner = DbInterner::new_with(self.db, None, None);
                 self.check_method_call(
                     tgt_expr,
                     args,
-                    self.db
-                        .value_ty(func.into())
-                        .expect("we have a function def")
-                        .instantiate(interner, gen_args),
+                    self.db.value_ty(func.into()).expect("we have a function def").instantiate(
+                    interner,
+                    gen_args,
+                ),
                     ty,
                     expected,
                 )
             }
-            // Failed to resolve, report diagnostic and try to resolve as call to field access or
-            // assoc function
             None => {
                 let field_with_same_name_exists = match self.lookup_field(receiver_ty, method_name)
                 {
                     }
                     None => None,
                 };
-
                 let assoc_func_with_same_name = method_resolution::iterate_method_candidates(
                     &canonicalized_receiver,
                     &mut self.table,
                         _ => None,
                     },
                 );
-
                 self.push_diagnostic(InferenceDiagnostic::UnresolvedMethodCall {
                     expr: tgt_expr,
                     receiver: receiver_ty,
                     field_with_same_name: field_with_same_name_exists,
                     assoc_func_with_same_name,
                 });
-
                 let recovered = match assoc_func_with_same_name {
                     Some(f) => {
                         let args = self.substs_for_method_call(tgt_expr, f.into(), generic_args);
                             tgt_expr,
                             args,
                             callee_ty,
-                            sig.inputs_and_output
-                                .inputs()
-                                .get(strip_first as usize..)
-                                .unwrap_or(&[]),
+                            sig.inputs_and_output.inputs().get(strip_first as usize..).unwrap_or(&[]),
                             sig.output(),
                             &[],
                             true,
     pub(in super::super) fn check_call_arguments(
         &mut self,
         call_expr: ExprId,
-        // Types (as defined in the *signature* of the target function)
         formal_input_tys: &[Ty<'db>],
         formal_output: Ty<'db>,
-        // Expected output from the parent expression or statement
         expectation: &Expectation<'db>,
-        // The expressions for each provided argument
         provided_args: &[ExprId],
         skip_indices: &[u32],
-        // Whether the function is variadic, for example when imported from C
         c_variadic: bool,
     ) {
         // First, let's unify the formal method signature with the expectation eagerly.
         let provided_arg_count = provided_args.len() - skip_indices.len();
 
         // Keep track of whether we *could possibly* be satisfied, i.e. whether we're on the happy path
+
         // if the wrong number of arguments were supplied, we CAN'T be satisfied,
+
         // and if we're c_variadic, the supplied arguments must be >= the minimum count from the function
+
         // otherwise, they need to be identical, because rust doesn't currently support variadic functions
         let args_count_matches = if c_variadic {
             provided_arg_count >= minimum_input_count
         }
 
         // We introduce a helper function to demand that a given argument satisfy a given input
+
         // This is more complicated than just checking type equality, as arguments could be coerced
+
         // This version writes those types back so further type checking uses the narrowed types
         let demand_compatible = |this: &mut InferenceContext<'_, 'db>, idx| {
             let formal_input_ty: Ty<'db> = formal_input_tys[idx];
         };
 
         // Check the arguments.
+
         // We do this in a pretty awful way: first we type-check any arguments
+
         // that are not closures, then we type-check the closures. This is so
+
         // that we have more information about the types of arguments when we
+
         // type-check the functions. This isn't really the right way to do this.
         for check_closures in [false, true] {
             // More awful hacks: before we check argument types, try to do
             }
         }
 
-        if !args_count_matches {}
+        if !args_count_matches {
+        }
     }
 
     fn substs_for_method_call(
                     Obligation::new(interner, ObligationCause::new(), param_env, predicate)
                 }));
             }
-            // add obligation for trait implementation, if this is a trait method
             match fn_def.0 {
                 CallableDefId::FunctionId(f) => {
                     if let ItemContainerId::TraitId(trait_) = f.lookup(self.db).container {
-                        // construct a TraitRef
                         let trait_params_len = generics(self.db, trait_.into()).len();
                         let substs = GenericArgs::new_from_iter(
                             self.interner(),
                         ));
                     }
                 }
-                CallableDefId::StructId(_) | CallableDefId::EnumVariantId(_) => {}
+                CallableDefId::StructId(_) | CallableDefId::EnumVariantId(_) => {
+                }
             }
         }
     }
 
     /// Enforces expectations on lhs type and rhs type depending on the operator and returns the
     /// output type of the binary op.
-    fn enforce_builtin_binop_types(&mut self, lhs: Ty<'db>, rhs: Ty<'db>, op: BinaryOp) -> Ty<'db> {
+    fn enforce_builtin_binop_types(
+        &mut self,
+        lhs: Ty<'db>,
+        rhs: Ty<'db>,
+        op: BinaryOp,
+    ) -> Ty<'db> {
         // Special-case a single layer of referencing, so that things like `5.0 + &6.0f32` work (See rust-lang/rust#57447).
         let lhs = self.deref_ty_if_possible(lhs);
         let rhs = self.deref_ty_if_possible(rhs);
             BinaryOp::Assignment { .. } => unreachable!("handled above"),
         };
 
-        if is_assign { self.types.unit } else { output_ty }
+        if is_assign {
+            self.types.unit
+        } else {
+            output_ty
+        }
     }
 
     fn is_builtin_binop(&mut self, lhs: Ty<'db>, rhs: Ty<'db>, op: BinaryOp) -> bool {
 
         match op {
             BinaryOp::LogicOp(_) => true,
-
             BinaryOp::ArithOp(ArithOp::Shl | ArithOp::Shr) => {
                 lhs.is_integral() && rhs.is_integral()
             }
-
             BinaryOp::ArithOp(
                 ArithOp::Add | ArithOp::Sub | ArithOp::Mul | ArithOp::Div | ArithOp::Rem,
             ) => {
-                lhs.is_integral() && rhs.is_integral()
-                    || lhs.is_floating_point() && rhs.is_floating_point()
+                lhs.is_integral() && rhs.is_integral() || lhs.is_floating_point() && rhs.is_floating_point()
             }
-
             BinaryOp::ArithOp(ArithOp::BitAnd | ArithOp::BitOr | ArithOp::BitXor) => {
-                lhs.is_integral() && rhs.is_integral()
-                    || lhs.is_floating_point() && rhs.is_floating_point()
-                    || matches!((lhs.kind(), rhs.kind()), (TyKind::Bool, TyKind::Bool))
+                lhs.is_integral() && rhs.is_integral() || lhs.is_floating_point() && rhs.is_floating_point() || matches!((lhs.kind(), rhs.kind()), (TyKind::Bool, TyKind::Bool))
             }
-
             BinaryOp::CmpOp(_) => {
                 let is_scalar = |kind| {
                     matches!(
                 };
                 is_scalar(lhs.kind()) && is_scalar(rhs.kind())
             }
-
             BinaryOp::Assignment { op: None } => {
                 stdx::never!("Simple assignment operator is not binary op.");
                 false
             }
-
             BinaryOp::Assignment { .. } => unreachable!("handled above"),
         }
     }
         });
         let res = cb(self);
         let ctx = self.breakables.pop().expect("breakable stack broken");
-        (if ctx.may_break { ctx.coerce.map(|ctx| ctx.complete(self)) } else { None }, res)
+        (
+            if ctx.may_break {
+            ctx.coerce.map(|ctx| ctx.complete(self))
+        } else {
+            None
+        },
+            res,
+        )
     }
 }
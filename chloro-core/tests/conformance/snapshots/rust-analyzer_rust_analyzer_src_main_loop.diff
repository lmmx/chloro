COMPARISON DIFF
============================================================

Original size: 58838 bytes
Chloro size:   58696 bytes
Rustfmt size:  58838 bytes

âœ— Outputs DIFFER

--- DIFF (- rustfmt, + chloro) ---
     reload::{BuildDataProgress, ProcMacroProgress, ProjectWorkspaceProgress},
     test_runner::{CargoTestMessage, CargoTestOutput, TestState},
 };
-
 pub fn main_loop(config: Config, connection: Connection) -> anyhow::Result<()> {
     tracing::info!("initial config: {:#?}", config);
-
     // Windows scheduler implements priority boosts: if thread waits for an
     // event (like a condvar), and event fires, priority of the thread is
     // temporary bumped. This optimization backfires in our case: each time the
         let thread_priority_above_normal = 1;
         SetThreadPriority(thread, thread_priority_above_normal);
     }
-
     #[cfg(feature = "dhat")]
     {
         if let Some(dhat_output_file) = config.dhat_output_file() {
                 Some(dhat::Profiler::builder().file_name(&dhat_output_file).build());
         }
     }
-
     GlobalState::new(connection.sender, config).run(connection.receiver)
 }
 
     FetchWorkspace(ProjectWorkspaceProgress),
     FetchBuildData(BuildDataProgress),
     LoadProcMacros(ProcMacroProgress),
-    // FIXME: Remove this in favor of a more general QueuedTask, see `handle_did_save_text_document`
     BuildDepsHaveChanged,
 }
 
 pub(crate) enum PrimeCachesProgress {
     Begin,
     Report(ide::ParallelPrimeCachesProgress),
-    End { cancelled: bool },
+    End {
+        cancelled: bool,
+    },
 }
 
 impl fmt::Debug for Event {
         let debug_non_verbose = |not: &Notification, f: &mut fmt::Formatter<'_>| {
             f.debug_struct("Notification").field("method", &not.method).finish()
         };
-
         match self {
             Event::Lsp(lsp_server::Message::Notification(not)) => {
                 if notification_is::<lsp_types::notification::DidOpenTextDocument>(not)
             }
             _ => (),
         }
-
         match self {
             Event::Lsp(it) => fmt::Debug::fmt(it, f),
             Event::Task(it) => fmt::Debug::fmt(it, f),
 impl GlobalState {
     fn run(mut self, inbox: Receiver<lsp_server::Message>) -> anyhow::Result<()> {
         self.update_status_or_notify();
-
         if self.config.did_save_text_document_dynamic_registration() {
             let additional_patterns = self
                 .config
                 .map(|f| format!("**/{f}"));
             self.register_did_save_capability(additional_patterns);
         }
-
         if self.config.discover_workspace_config().is_none() {
             self.fetch_workspaces_queue.request_op(
                 "startup".to_owned(),
                 self.fetch_workspaces(cause, path, force_crate_graph_reload);
             }
         }
-
         while let Ok(event) = self.next_event(&inbox) {
             let Some(event) = event else {
                 anyhow::bail!("client exited without proper shutdown sequence");
             }
             self.handle_event(event);
         }
-
         Err(anyhow::anyhow!("A receiver has been dropped, something panicked!"))
     }
 
             scheme: None,
             pattern: (Some(pattern)),
         });
-
         let mut selectors = vec![
             lsp_types::DocumentFilter {
                 language: None,
             },
         ];
         selectors.extend(additional_filters);
-
         let save_registration_options = lsp_types::TextDocumentSaveRegistrationOptions {
             include_text: Some(false),
             text_document_registration_options: lsp_types::TextDocumentRegistrationOptions {
                 document_selector: Some(selectors),
             },
         };
-
         let registration = lsp_types::Registration {
             id: "textDocument/didSave".to_owned(),
             method: "textDocument/didSave".to_owned(),
         );
     }
 
-    fn next_event(
-        &mut self,
-        inbox: &Receiver<lsp_server::Message>,
-    ) -> Result<Option<Event>, crossbeam_channel::RecvError> {
+    fn next_event(&mut self, inbox: &Receiver<lsp_server::Message>) -> Result<Option<Event>, crossbeam_channel::RecvError> {
         // Make sure we reply to formatting requests ASAP so the editor doesn't block
         if let Ok(task) = self.fmt_pool.receiver.try_recv() {
             return Ok(Some(Event::Task(task)));
         }
-
         select! {
             recv(inbox) -> msg =>
                 return Ok(msg.ok().map(Event::Lsp)),
     fn handle_event(&mut self, event: Event) {
         let loop_start = Instant::now();
         let _p = tracing::info_span!("GlobalState::handle_event", event = %event).entered();
-
         let event_dbg_msg = format!("{event:?}");
         tracing::debug!(?loop_start, ?event, "handle_event");
         if tracing::enabled!(tracing::Level::INFO) {
                 tracing::info!("task queue len: {}", task_queue_len);
             }
         }
-
         let was_quiescent = self.is_quiescent();
         match event {
             Event::Lsp(msg) => match msg {
         } else {
             (false, false)
         };
-
         if self.is_quiescent() {
             let became_quiescent = !was_quiescent;
             if became_quiescent {
                 self.update_tests();
             }
         }
-
         if let Some(diagnostic_changes) = self.diagnostics.take_changes() {
             for file_id in diagnostic_changes {
                 let uri = file_id_to_url(&self.vfs.read().0, file_id);
                 self.publish_diagnostics(uri, version, diagnostics);
             }
         }
-
         if (self.config.cargo_autoreload_config(None)
             || self.config.discover_workspace_config().is_some())
             && let Some((cause, FetchWorkspaceRequest { path, force_crate_graph_reload })) =
         {
             self.fetch_workspaces(cause, path, force_crate_graph_reload);
         }
-
         if !self.fetch_workspaces_queue.op_in_progress() {
             if let Some((cause, ())) = self.fetch_build_data_queue.should_start_op() {
                 self.fetch_build_data(cause);
                 self.fetch_proc_macros(cause, change, paths);
             }
         }
-
         if let Some((cause, ())) = self.prime_caches_queue.should_start_op() {
             self.prime_caches(cause);
         }
-
         self.update_status_or_notify();
-
         let loop_duration = loop_start.elapsed();
         if loop_duration > Duration::from_millis(100) && was_quiescent {
             tracing::warn!(
     fn prime_caches(&mut self, cause: String) {
         tracing::debug!(%cause, "will prime caches");
         let num_worker_threads = self.config.prime_caches_num_threads();
-
         self.task_pool.handle.spawn_with_sender(ThreadIntent::Worker, {
             let analysis = AssertUnwindSafe(self.snapshot().analysis);
             move |sender| {
         let max_tasks = self.config.main_loop_num_threads().div(4).max(1);
         let chunk_length = subscriptions.len() / max_tasks;
         let remainder = subscriptions.len() % max_tasks;
-
         let mut start = 0;
         for task_idx in 0..max_tasks {
             let extra = if task_idx < remainder { 1 } else { 0 };
             })
             .collect::<Vec<_>>();
         tracing::trace!("updating tests for {:?}", subscriptions);
-
         // Updating tests are triggered by the user typing
         // so we run them on a latency sensitive thread.
         self.task_pool.handle.spawn(ThreadIntent::LatencySensitive, {
             s.shutdown_requested = true;
             Ok(())
         });
-
         match &mut dispatcher {
             RequestDispatcher { req: Some(req), global_state: this } if this.shutdown_requested => {
                 this.respond(lsp_server::Response::new_err(
             }
             _ => (),
         }
-
         use crate::handlers::request as handlers;
         use lsp_types::request as lsp_request;
-
         const RETRY: bool = true;
         const NO_RETRY: bool = false;
-
         #[rustfmt::skip]
         dispatcher
             // Request handlers that must run on the main thread
             span!(Level::INFO, "GlobalState::on_notification", not.method = ?not.method).entered();
         use crate::handlers::notification as handlers;
         use lsp_types::notification as notifs;
-
         NotificationDispatcher { not: Some(not), global_state: self }
             .on_sync_mut::<notifs::Cancel>(handlers::handle_cancel)
             .on_sync_mut::<notifs::WorkDoneProgressCancel>(
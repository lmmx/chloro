COMPARISON DIFF
============================================================

Original size: 89146 bytes
Chloro size:   89139 bytes
Rustfmt size:  89146 bytes

âœ— Outputs DIFFER

--- DIFF (- rustfmt, + chloro) ---
 //! Module responsible for analyzing the code surrounding the cursor for completion.
+
 use std::iter;
 
 use hir::{ExpandResult, InFile, Semantics, Type, TypeInfo, Variant};
         fake_ident_token,
         derive_ctx: None,
     });
-
     // add the relative offset back, so that left_biased finds the proper token
     let original_offset = expansion.original_offset + relative_offset;
     let token = expansion.original_file.token_at_offset(original_offset).left_biased()?;
-
     hir::attach_db(sema.db, || analyze(sema, expansion, original_token, &token)).map(
         |(analysis, expected, qualifier_ctx)| AnalysisResult {
             analysis,
     )
 }
 
-fn token_at_offset_ignore_whitespace(file: &SyntaxNode, offset: TextSize) -> Option<SyntaxToken> {
+fn token_at_offset_ignore_whitespace(
+    file: &SyntaxNode,
+    offset: TextSize,
+) -> Option<SyntaxToken> {
     let token = file.token_at_offset(offset).left_biased()?;
     algo::skip_whitespace_token(token, Direction::Prev)
 }
     ) {
         return result;
     }
-
     // We can't check whether the fake expansion is inside macro call, because that requires semantic info.
     // But hopefully checking just the real one should be enough.
     if token_at_offset_ignore_whitespace(&original_file.value, original_offset + relative_offset)
     relative_offset: TextSize,
 ) -> Option<ExpansionResult> {
     let _p = tracing::info_span!("CompletionContext::expand").entered();
-
     let parent_item =
         |item: &ast::Item| item.syntax().ancestors().skip(1).find_map(ast::Item::cast);
     let original_node = token_at_offset_ignore_whitespace(&original_file.value, original_offset)
         ),
         |(a, b)| parent_item(a).zip(parent_item(b)),
     );
-
     // first try to expand attributes as these are always the outermost macro calls
     'ancestors: for (actual_item, item_with_fake_ident) in ancestor_items {
         match (
             _ => break 'ancestors,
         }
     }
-
     // No attributes have been expanded, so look for macro_call! token trees or derive token trees
     let orig_tt = ancestors_at_offset(&original_file.value, original_offset)
         .map_while(Either::<ast::TokenTree, ast::Meta>::cast)
     let spec_tt = ancestors_at_offset(&speculative_file, fake_ident_token.text_range().start())
         .map_while(Either::<ast::TokenTree, ast::Meta>::cast)
         .last()?;
-
     let (tts, attrs) = match (orig_tt, spec_tt) {
         (Either::Left(orig_tt), Either::Left(spec_tt)) => {
             let attrs = orig_tt
         }
         _ => return None,
     };
-
     // Expand pseudo-derive expansion aka `derive(Debug$0)`
     if let Some((orig_attr, spec_attr)) = attrs {
         if let (Some(actual_expansion), Some((fake_expansion, fake_mapped_tokens))) = (
         // at this point we won't have any more successful expansions, so stop
         return None;
     }
-
     // Expand fn-like macro calls
     let (orig_tt, spec_tt) = tts?;
     let (actual_macro_call, macro_call_with_fake_ident) = (
     );
     let mac_call_path0 = actual_macro_call.path().as_ref().map(|s| s.syntax().text());
     let mac_call_path1 = macro_call_with_fake_ident.path().as_ref().map(|s| s.syntax().text());
-
     // inconsistent state, stop expanding
     if mac_call_path0 != mac_call_path1 {
         return None;
     }
     let speculative_args = macro_call_with_fake_ident.token_tree()?;
-
     match (
         sema.expand_macro_call(&actual_macro_call),
         sema.speculative_expand_macro_call(&actual_macro_call, &speculative_args, fake_ident_token),
     expansion_result: ExpansionResult,
     original_token: &SyntaxToken,
     self_token: &SyntaxToken,
-) -> Option<(CompletionAnalysis<'db>, (Option<Type<'db>>, Option<ast::NameOrNameRef>), QualifierCtx)>
-{
+) -> Option<(CompletionAnalysis<'db>, (Option<Type<'db>>, Option<ast::NameOrNameRef>), QualifierCtx)> {
     let _p = tracing::info_span!("CompletionContext::analyze").entered();
     let ExpansionResult {
         original_file,
         fake_ident_token,
         derive_ctx,
     } = expansion_result;
-
     if original_token.kind() != self_token.kind()
         // FIXME: This check can be removed once we use speculative database forking for completions
         && !(original_token.kind().is_punct() || original_token.kind().is_trivia())
     {
         return None;
     }
-
     // Overwrite the path kind for derives
     if let Some((original_file, file_with_fake_ident, offset, origin_attr)) = derive_ctx {
         if let Some(ast::NameLike::NameRef(name_ref)) =
         }
         return None;
     }
-
     let Some(name_like) = find_node_at_offset(&speculative_file, speculative_offset) else {
         let analysis = if let Some(original) = ast::String::cast(original_token.clone()) {
             CompletionAnalysis::String { original, expanded: ast::String::cast(self_token.clone()) }
         };
         return Some((analysis, (None, None), QualifierCtx::default()));
     };
-
     let expected = expected_type_and_name(sema, self_token, &name_like);
     let mut qual_ctx = QualifierCtx::default();
     let analysis = match name_like {
         Some(it) => it,
         None => return (None, None),
     };
-
     let strip_refs = |mut ty: Type<'db>| match name_like {
         ast::NameLike::NameRef(n) => {
             let p = match n.syntax().parent() {
         }
         _ => ty,
     };
-
     let (ty, name) = loop {
         break match_ast! {
             match node {
     if parent.kind() == SyntaxKind::ERROR {
         return None;
     }
-
     let lifetime =
         find_node_at_offset::<ast::Lifetime>(original_file, lifetime.syntax().text_range().start());
     let kind = match_ast! {
             },
         }
     };
-
     Some(LifetimeContext { kind })
 }
 
     parent: SyntaxNode,
 ) -> Option<(NameRefContext<'db>, QualifierCtx)> {
     let nameref = find_node_at_offset(original_file, original_offset);
-
     let make_res = |kind| (NameRefContext { nameref: nameref.clone(), kind }, Default::default());
-
     if let Some(record_field) = ast::RecordExprField::for_field_name(&name_ref) {
         let dot_prefix = previous_non_trivia_token(name_ref.syntax().clone())
             .is_some_and(|it| T![.] == it.kind());
         });
         return Some(make_res(kind));
     }
-
     let field_expr_handle = |receiver, node| {
         let receiver = find_opt_node_in_file(original_file, receiver);
         let receiver_is_ambiguous_float_literal = match &receiver {
         });
         Some(make_res(kind))
     };
-
     let segment = match_ast! {
         match parent {
             ast::PathSegment(segment) => segment,
             _ => return None,
         }
     };
-
     let path = segment.parent_path();
     let original_path = find_node_in_file_compensated(sema, original_file, &path);
-
     let mut path_ctx = PathCompletionCtx {
         has_call_parens: false,
         has_macro_bang: false,
         has_type_args: false,
         use_tree_parent: false,
     };
-
     let func_update_record = |syn: &SyntaxNode| {
         if let Some(record_expr) = syn.ancestors().nth(2).and_then(ast::RecordExpr::cast) {
             find_node_in_file_compensated(sema, original_file, &record_expr)
                 .and_then(|expr| expr.index())
                 .is_some_and(|expr| expr.syntax() == it)
     };
-
     // We do not want to generate path completions when we are sandwiched between an item decl signature and its body.
     // ex. trait Foo $0 {}
     // in these cases parser recovery usually kicks in for our inserted identifier, causing it
         }
         None
     };
-
     let generic_arg_location = |arg: ast::GenericArg| {
         let mut override_location = None;
         let location = find_opt_node_in_file_compensated(
             corresponding_param,
         })
     };
-
     let type_location = |node: &SyntaxNode| {
         let parent = node.parent()?;
         let res = match_ast! {
         };
         Some(res)
     };
-
     let make_path_kind_expr = |expr: ast::Expr| {
         let it = expr.syntax();
         let in_block_expr = is_in_block(it);
         let location = type_location(ty.syntax());
         PathKind::Type { location: location.unwrap_or(TypeLocation::Other) }
     };
-
     let kind_item = |it: &SyntaxNode| {
         let parent = it.parent()?;
         let kind = match_ast! {
         };
         Some(kind)
     };
-
     let mut kind_macro_call = |it: ast::MacroCall| {
         path_ctx.has_macro_bang = it.excl_token().is_some();
         let parent = it.syntax().parent()?;
             .unwrap_or_default();
         Some(PathKind::Attr { attr_ctx: AttrCtx { kind, annotated_item_kind, derive_helpers } })
     };
-
     // Infer the path kind
     let parent = path.syntax().parent()?;
     let kind = 'find_kind: {
             }
         }
     };
-
     path_ctx.kind = kind;
     path_ctx.has_type_args = segment.generic_arg_list().is_some();
-
     // calculate the qualifier context
     if let Some((qualifier, use_tree_parent)) = path_or_use_tree_qualifier(&path) {
         path_ctx.use_tree_parent = use_tree_parent;
     {
         path_ctx.qualified = Qualified::Absolute;
     }
-
     let mut qualifier_ctx = QualifierCtx::default();
     if path_ctx.is_trivial_path() {
         // fetch the full expression that may have qualifiers attached to it
     pat: ast::Pat,
 ) -> PatternContext {
     let mut param_ctx = None;
-
     let mut missing_variants = vec![];
-
     let (refutability, has_type_ascription) =
     pat
         .syntax()
         ast::Pat::IdentPat(it) => (it.ref_token(), it.mut_token()),
         _ => (None, None),
     };
-
     // Only suggest name in let-stmt or fn param
     let should_suggest_name = matches!(
             &pat,
                     ast::LetStmt::can_cast(kind) || ast::Param::can_cast(kind)
                 })
     );
-
     PatternContext {
         refutability,
         param_ctx,
     let mut ancestors = ancestors_in_file_compensated(sema, original_file, node)?
         .filter_map(ast::Item::cast)
         .filter(|it| !matches!(it, ast::Item::MacroCall(_)));
-
     match ancestors.next()? {
         ast::Item::Const(_) | ast::Item::Fn(_) | ast::Item::TypeAlias(_) => (),
         ast::Item::Impl(it) => return Some(Either::Left(it)),
 
 /// Attempts to find `node` inside `syntax` via `node`'s text range.
 /// If the fake identifier has been inserted after this node or inside of this node use the `_compensated` version instead.
-fn find_opt_node_in_file<N: AstNode>(syntax: &SyntaxNode, node: Option<N>) -> Option<N> {
+fn find_opt_node_in_file<N: AstNode>(
+    syntax: &SyntaxNode,
+    node: Option<N>,
+) -> Option<N> {
     find_node_in_file(syntax, &node?)
 }
 
 /// Attempts to find `node` inside `syntax` via `node`'s text range.
 /// If the fake identifier has been inserted after this node or inside of this node use the `_compensated` version instead.
-fn find_node_in_file<N: AstNode>(syntax: &SyntaxNode, node: &N) -> Option<N> {
+fn find_node_in_file<N: AstNode>(
+    syntax: &SyntaxNode,
+    node: &N,
+) -> Option<N> {
     let syntax_range = syntax.text_range();
     let range = node.syntax().text_range();
     let intersection = range.intersect(syntax_range)?;